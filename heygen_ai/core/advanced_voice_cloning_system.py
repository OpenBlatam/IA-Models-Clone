"""
üé§ Advanced Voice Cloning System - HeyGen AI
============================================

Sistema avanzado de clonaci√≥n de voz con m√∫ltiples t√©cnicas:
- Clonaci√≥n de voz en tiempo real
- M√∫ltiples idiomas y acentos
- Preservaci√≥n de caracter√≠sticas emocionales
- Optimizaci√≥n de calidad de audio
- API REST completa
"""

import asyncio
import base64
import io
import json
import logging
import os
import time
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
from pathlib import Path

import numpy as np
import torch
import torchaudio
import librosa
from scipy import signal
import soundfile as sf
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.responses import StreamingResponse
import uvicorn

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class VoiceConfig:
    """Configuraci√≥n de voz"""
    sample_rate: int = 22050
    hop_length: int = 256
    win_length: int = 1024
    n_mels: int = 80
    n_fft: int = 1024
    fmin: int = 0
    fmax: int = 8000
    preemphasis: float = 0.97
    min_level_db: float = -100
    ref_level_db: float = 20

@dataclass
class VoiceProfile:
    """Perfil de voz"""
    name: str
    language: str
    accent: str
    gender: str
    age_range: str
    emotion_style: str
    pitch_range: Tuple[float, float]
    speaking_rate: float
    voice_characteristics: Dict

class AdvancedVoiceCloningSystem:
    """Sistema avanzado de clonaci√≥n de voz"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config_path = config_path or "config/voice_cloning_config.yaml"
        self.voice_config = VoiceConfig()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # Modelos de clonaci√≥n de voz
        self.voice_encoder = None
        self.voice_synthesizer = None
        self.emotion_analyzer = None
        self.accent_detector = None
        
        # Perfiles de voz predefinidos
        self.voice_profiles: Dict[str, VoiceProfile] = {}
        
        self._load_models()
        self._load_voice_profiles()
    
    def _load_models(self):
        """Cargar modelos de clonaci√≥n de voz"""
        try:
            # En implementaci√≥n real, cargar modelos preentrenados
            # self.voice_encoder = load_voice_encoder_model()
            # self.voice_synthesizer = load_voice_synthesizer_model()
            # self.emotion_analyzer = load_emotion_analyzer_model()
            # self.accent_detector = load_accent_detector_model()
            
            logger.info("‚úÖ Modelos de clonaci√≥n de voz cargados")
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando modelos: {e}")
    
    def _load_voice_profiles(self):
        """Cargar perfiles de voz predefinidos"""
        default_profiles = [
            VoiceProfile(
                name="Professional Male",
                language="english",
                accent="american",
                gender="male",
                age_range="30-40",
                emotion_style="professional",
                pitch_range=(85, 180),
                speaking_rate=1.0,
                voice_characteristics={
                    "clarity": 0.9,
                    "warmth": 0.7,
                    "authority": 0.8,
                    "friendliness": 0.6
                }
            ),
            VoiceProfile(
                name="Friendly Female",
                language="english",
                accent="american",
                gender="female",
                age_range="25-35",
                emotion_style="friendly",
                pitch_range=(165, 265),
                speaking_rate=1.1,
                voice_characteristics={
                    "clarity": 0.8,
                    "warmth": 0.9,
                    "authority": 0.5,
                    "friendliness": 0.9
                }
            ),
            VoiceProfile(
                name="British Male",
                language="english",
                accent="british",
                gender="male",
                age_range="35-45",
                emotion_style="sophisticated",
                pitch_range=(80, 170),
                speaking_rate=0.9,
                voice_characteristics={
                    "clarity": 0.95,
                    "warmth": 0.6,
                    "authority": 0.9,
                    "friendliness": 0.5
                }
            ),
            VoiceProfile(
                name="Spanish Female",
                language="spanish",
                accent="mexican",
                gender="female",
                age_range="25-35",
                emotion_style="warm",
                pitch_range=(170, 270),
                speaking_rate=1.2,
                voice_characteristics={
                    "clarity": 0.85,
                    "warmth": 0.95,
                    "authority": 0.6,
                    "friendliness": 0.8
                }
            )
        ]
        
        for profile in default_profiles:
            self.voice_profiles[profile.name] = profile
        
        logger.info(f"‚úÖ {len(self.voice_profiles)} perfiles de voz cargados")
    
    async def clone_voice(
        self,
        source_audio: bytes,
        target_text: str,
        voice_profile: Optional[str] = None,
        preserve_emotion: bool = True,
        adjust_pitch: bool = True,
        adjust_speed: bool = True
    ) -> bytes:
        """Clonar voz de audio fuente"""
        try:
            # Procesar audio fuente
            source_features = await self._extract_voice_features(source_audio)
            
            # Seleccionar perfil de voz
            if voice_profile and voice_profile in self.voice_profiles:
                profile = self.voice_profiles[voice_profile]
            else:
                profile = self._detect_voice_profile(source_features)
            
            # Generar audio clonado
            cloned_audio = await self._synthesize_voice(
                target_text, source_features, profile,
                preserve_emotion, adjust_pitch, adjust_speed
            )
            
            return cloned_audio
            
        except Exception as e:
            logger.error(f"‚ùå Error clonando voz: {e}")
            raise
    
    async def _extract_voice_features(self, audio_data: bytes) -> Dict:
        """Extraer caracter√≠sticas de voz del audio fuente"""
        try:
            # Convertir bytes a array numpy
            audio_array, sr = librosa.load(io.BytesIO(audio_data), sr=self.voice_config.sample_rate)
            
            # Extraer caracter√≠sticas
            features = {
                "audio": audio_array,
                "sample_rate": sr,
                "duration": len(audio_array) / sr,
                "pitch": self._extract_pitch(audio_array, sr),
                "spectral_centroid": self._extract_spectral_centroid(audio_array, sr),
                "mfcc": self._extract_mfcc(audio_array, sr),
                "spectral_rolloff": self._extract_spectral_rolloff(audio_array, sr),
                "zero_crossing_rate": self._extract_zero_crossing_rate(audio_array, sr),
                "emotion": self._analyze_emotion(audio_array, sr),
                "accent": self._detect_accent(audio_array, sr)
            }
            
            logger.info("‚úÖ Caracter√≠sticas de voz extra√≠das")
            return features
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo caracter√≠sticas: {e}")
            raise
    
    def _extract_pitch(self, audio: np.ndarray, sr: int) -> float:
        """Extraer pitch promedio"""
        try:
            pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)
            pitch_values = []
            
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    pitch_values.append(pitch)
            
            return np.mean(pitch_values) if pitch_values else 0.0
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo pitch: {e}")
            return 0.0
    
    def _extract_spectral_centroid(self, audio: np.ndarray, sr: int) -> float:
        """Extraer centroide espectral"""
        try:
            spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
            return np.mean(spectral_centroids)
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo centroide espectral: {e}")
            return 0.0
    
    def _extract_mfcc(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """Extraer coeficientes MFCC"""
        try:
            mfccs = librosa.feature.mfcc(
                y=audio, sr=sr, n_mfcc=self.voice_config.n_mels
            )
            return np.mean(mfccs, axis=1)
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo MFCC: {e}")
            return np.zeros(self.voice_config.n_mels)
    
    def _extract_spectral_rolloff(self, audio: np.ndarray, sr: int) -> float:
        """Extraer rolloff espectral"""
        try:
            rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]
            return np.mean(rolloff)
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo rolloff espectral: {e}")
            return 0.0
    
    def _extract_zero_crossing_rate(self, audio: np.ndarray, sr: int) -> float:
        """Extraer tasa de cruce por cero"""
        try:
            zcr = librosa.feature.zero_crossing_rate(audio)[0]
            return np.mean(zcr)
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo ZCR: {e}")
            return 0.0
    
    def _analyze_emotion(self, audio: np.ndarray, sr: int) -> str:
        """Analizar emoci√≥n en el audio"""
        try:
            # An√°lisis b√°sico de emoci√≥n basado en caracter√≠sticas ac√∫sticas
            pitch = self._extract_pitch(audio, sr)
            energy = np.mean(librosa.feature.rms(y=audio)[0])
            tempo = librosa.beat.tempo(y=audio, sr=sr)[0]
            
            # Clasificaci√≥n simple de emoci√≥n
            if pitch > 200 and energy > 0.1:
                return "excited"
            elif pitch < 150 and energy < 0.05:
                return "sad"
            elif tempo > 120:
                return "happy"
            else:
                return "neutral"
                
        except Exception as e:
            logger.error(f"‚ùå Error analizando emoci√≥n: {e}")
            return "neutral"
    
    def _detect_accent(self, audio: np.ndarray, sr: int) -> str:
        """Detectar acento en el audio"""
        try:
            # Detecci√≥n b√°sica de acento basada en caracter√≠sticas espectrales
            mfcc = self._extract_mfcc(audio, sr)
            
            # Clasificaci√≥n simple (en implementaci√≥n real usar modelo entrenado)
            if np.mean(mfcc[:5]) > 0:
                return "american"
            elif np.mean(mfcc[5:10]) > 0:
                return "british"
            else:
                return "neutral"
                
        except Exception as e:
            logger.error(f"‚ùå Error detectando acento: {e}")
            return "neutral"
    
    def _detect_voice_profile(self, features: Dict) -> VoiceProfile:
        """Detectar perfil de voz basado en caracter√≠sticas"""
        try:
            pitch = features["pitch"]
            emotion = features["emotion"]
            accent = features["accent"]
            
            # Seleccionar perfil m√°s similar
            best_profile = None
            best_score = 0
            
            for profile in self.voice_profiles.values():
                score = 0
                
                # Comparar pitch
                if profile.pitch_range[0] <= pitch <= profile.pitch_range[1]:
                    score += 0.4
                
                # Comparar emoci√≥n
                if profile.emotion_style == emotion:
                    score += 0.3
                
                # Comparar acento
                if profile.accent == accent:
                    score += 0.3
                
                if score > best_score:
                    best_score = score
                    best_profile = profile
            
            return best_profile or list(self.voice_profiles.values())[0]
            
        except Exception as e:
            logger.error(f"‚ùå Error detectando perfil: {e}")
            return list(self.voice_profiles.values())[0]
    
    async def _synthesize_voice(
        self,
        text: str,
        source_features: Dict,
        profile: VoiceProfile,
        preserve_emotion: bool,
        adjust_pitch: bool,
        adjust_speed: bool
    ) -> bytes:
        """Sintetizar voz clonada"""
        try:
            # Generar audio base
            duration = len(text) * 0.1  # Aproximaci√≥n
            sample_rate = self.voice_config.sample_rate
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # Ajustar pitch basado en perfil
            if adjust_pitch:
                target_pitch = np.mean(profile.pitch_range)
                frequency = target_pitch
            else:
                frequency = source_features["pitch"]
            
            # Generar audio sint√©tico
            audio = np.sin(2 * np.pi * frequency * t)
            
            # Aplicar modulaci√≥n de emoci√≥n
            if preserve_emotion:
                emotion_modulation = self._apply_emotion_modulation(
                    audio, source_features["emotion"]
                )
                audio = audio * emotion_modulation
            
            # Ajustar velocidad
            if adjust_speed:
                audio = self._adjust_speaking_rate(audio, profile.speaking_rate)
            
            # Aplicar caracter√≠sticas de voz
            audio = self._apply_voice_characteristics(audio, profile)
            
            # Normalizar audio
            audio = audio / np.max(np.abs(audio)) * 0.8
            
            # Convertir a formato de audio
            audio_int16 = (audio * 32767).astype(np.int16)
            
            # Convertir a bytes
            audio_bytes = audio_int16.tobytes()
            
            logger.info("‚úÖ Voz clonada sintetizada")
            return audio_bytes
            
        except Exception as e:
            logger.error(f"‚ùå Error sintetizando voz: {e}")
            raise
    
    def _apply_emotion_modulation(self, audio: np.ndarray, emotion: str) -> np.ndarray:
        """Aplicar modulaci√≥n de emoci√≥n"""
        try:
            t = np.linspace(0, len(audio) / self.voice_config.sample_rate, len(audio))
            
            if emotion == "excited":
                # Modulaci√≥n r√°pida y alta amplitud
                modulation = 1 + 0.3 * np.sin(2 * np.pi * 5 * t)
            elif emotion == "sad":
                # Modulaci√≥n lenta y baja amplitud
                modulation = 0.7 + 0.2 * np.sin(2 * np.pi * 1 * t)
            elif emotion == "happy":
                # Modulaci√≥n media y variada
                modulation = 1 + 0.2 * np.sin(2 * np.pi * 3 * t)
            else:  # neutral
                modulation = np.ones_like(t)
            
            return modulation
            
        except Exception as e:
            logger.error(f"‚ùå Error aplicando modulaci√≥n de emoci√≥n: {e}")
            return np.ones_like(audio)
    
    def _adjust_speaking_rate(self, audio: np.ndarray, rate: float) -> np.ndarray:
        """Ajustar velocidad de habla"""
        try:
            if rate == 1.0:
                return audio
            
            # Interpolaci√≥n para cambiar velocidad
            original_length = len(audio)
            new_length = int(original_length / rate)
            
            # Crear nuevo array con longitud ajustada
            t_original = np.linspace(0, 1, original_length)
            t_new = np.linspace(0, 1, new_length)
            
            # Interpolar audio
            adjusted_audio = np.interp(t_new, t_original, audio)
            
            return adjusted_audio
            
        except Exception as e:
            logger.error(f"‚ùå Error ajustando velocidad: {e}")
            return audio
    
    def _apply_voice_characteristics(self, audio: np.ndarray, profile: VoiceProfile) -> np.ndarray:
        """Aplicar caracter√≠sticas de voz del perfil"""
        try:
            # Aplicar filtros basados en caracter√≠sticas
            characteristics = profile.voice_characteristics
            
            # Filtro de claridad
            if characteristics["clarity"] > 0.8:
                # Aplicar filtro pasa-altos para mayor claridad
                b, a = signal.butter(4, 0.1, btype='high')
                audio = signal.filtfilt(b, a, audio)
            
            # Filtro de calidez
            if characteristics["warmth"] > 0.8:
                # Aplicar filtro pasa-bajos para mayor calidez
                b, a = signal.butter(4, 0.3, btype='low')
                audio = signal.filtfilt(b, a, audio)
            
            return audio
            
        except Exception as e:
            logger.error(f"‚ùå Error aplicando caracter√≠sticas: {e}")
            return audio
    
    def get_voice_profiles(self) -> List[Dict]:
        """Obtener perfiles de voz disponibles"""
        return [
            {
                "name": profile.name,
                "language": profile.language,
                "accent": profile.accent,
                "gender": profile.gender,
                "age_range": profile.age_range,
                "emotion_style": profile.emotion_style,
                "pitch_range": profile.pitch_range,
                "speaking_rate": profile.speaking_rate,
                "voice_characteristics": profile.voice_characteristics
            }
            for profile in self.voice_profiles.values()
        ]
    
    def add_voice_profile(self, profile: VoiceProfile):
        """A√±adir perfil de voz personalizado"""
        self.voice_profiles[profile.name] = profile
        logger.info(f"‚úÖ Perfil de voz '{profile.name}' a√±adido")

class VoiceCloningAPI:
    """API REST para el sistema de clonaci√≥n de voz"""
    
    def __init__(self, voice_system: AdvancedVoiceCloningSystem):
        self.voice_system = voice_system
        self.app = FastAPI(title="HeyGen AI Voice Cloning System", version="1.0.0")
        self._setup_routes()
    
    def _setup_routes(self):
        """Configurar rutas de la API"""
        
        @self.app.get("/voice-profiles")
        async def get_voice_profiles():
            """Obtener perfiles de voz disponibles"""
            return {"profiles": self.voice_system.get_voice_profiles()}
        
        @self.app.post("/clone-voice")
        async def clone_voice(
            source_audio: UploadFile = File(...),
            target_text: str = "",
            voice_profile: Optional[str] = None,
            preserve_emotion: bool = True,
            adjust_pitch: bool = True,
            adjust_speed: bool = True
        ):
            """Clonar voz"""
            try:
                source_data = await source_audio.read()
                
                cloned_audio = await self.voice_system.clone_voice(
                    source_data, target_text, voice_profile,
                    preserve_emotion, adjust_pitch, adjust_speed
                )
                
                return StreamingResponse(
                    io.BytesIO(cloned_audio),
                    media_type="audio/wav",
                    headers={"Content-Disposition": "attachment; filename=cloned_voice.wav"}
                )
                
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.post("/add-voice-profile")
        async def add_voice_profile(profile_data: dict):
            """A√±adir perfil de voz personalizado"""
            try:
                profile = VoiceProfile(**profile_data)
                self.voice_system.add_voice_profile(profile)
                return {"message": f"Perfil '{profile.name}' a√±adido exitosamente"}
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))

async def main():
    """Funci√≥n principal"""
    try:
        # Crear sistema de clonaci√≥n de voz
        voice_system = AdvancedVoiceCloningSystem()
        
        # Crear API
        api = VoiceCloningAPI(voice_system)
        
        print("üé§ HeyGen AI Voice Cloning System iniciado")
        print("üîó API disponible en: http://localhost:8001")
        
        # Iniciar servidor API
        await uvicorn.run(api.app, host="0.0.0.0", port=8001)
        
    except Exception as e:
        logger.error(f"‚ùå Error en main: {e}")

if __name__ == "__main__":
    asyncio.run(main())
