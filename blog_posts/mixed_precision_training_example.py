from typing_extensions import Literal, TypedDict
from typing import Any, List, Dict, Optional, Union, Tuple
# Constants
MAX_CONNECTIONS = 1000

# Constants
MAX_RETRIES = 100

# Constants
TIMEOUT_SECONDS = 60

# Constants
BUFFER_SIZE = 1024

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import json
import time
from typing import Dict, List, Any
import logging
from mixed_precision_training import (
from typing import Any, List, Dict, Optional
import asyncio
"""
üöÄ Mixed Precision Training Example
==================================

This example demonstrates comprehensive mixed precision training using
torch.cuda.amp with various models and configurations.
"""


# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import the mixed precision training system
    MixedPrecisionConfig, MixedPrecisionTrainer, AdaptiveMixedPrecisionTrainer,
    create_mixed_precision_config, should_use_mixed_precision,
    optimize_mixed_precision_settings, benchmark_mixed_precision,
    train_with_mixed_precision, mixed_precision_context
)


class SimpleNeuralNetwork(nn.Module):
    """Simple neural network for demonstration."""
    
    def __init__(self, input_size: int = 10, hidden_size: int = 64, num_classes: int = 2):
        
    """__init__ function."""
super(SimpleNeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)
        self.fc3 = nn.Linear(hidden_size // 2, num_classes)
        
    def forward(self, x) -> Any:
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        return x


class ConvNeuralNetwork(nn.Module):
    """Convolutional neural network for demonstration."""
    
    def __init__(self, num_classes: int = 2):
        
    """__init__ function."""
super(ConvNeuralNetwork, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
        self.fc1 = nn.Linear(128 * 4 * 4, 256)
        self.fc2 = nn.Linear(256, num_classes)
        
    def forward(self, x) -> Any:
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))
        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x


class DummyDataset:
    """Dummy dataset for demonstration."""
    
    def __init__(self, num_samples: int = 1000, input_size: int = 10, num_classes: int = 2):
        
    """__init__ function."""
self.num_samples = num_samples
        self.input_size = input_size
        self.num_classes = num_classes
        
        # Generate random data
        self.X = torch.randn(num_samples, input_size)
        self.y = torch.randint(0, num_classes, (num_samples,))
        
    def __len__(self) -> Any:
        return self.num_samples
    
    def __getitem__(self, idx) -> Optional[Dict[str, Any]]:
        return self.X[idx], self.y[idx]


class ConvDummyDataset:
    """Dummy dataset for convolutional models."""
    
    def __init__(self, num_samples: int = 1000, num_classes: int = 2):
        
    """__init__ function."""
self.num_samples = num_samples
        self.num_classes = num_classes
        
        # Generate random image data
        self.X = torch.randn(num_samples, 3, 32, 32)  # 3-channel 32x32 images
        self.y = torch.randint(0, num_classes, (num_samples,))
        
    def __len__(self) -> Any:
        return self.num_samples
    
    def __getitem__(self, idx) -> Optional[Dict[str, Any]]:
        return self.X[idx], self.y[idx]


def demonstrate_basic_mixed_precision():
    """Demonstrate basic mixed precision training."""
    print("=" * 60)
    print("üîß BASIC MIXED PRECISION TRAINING DEMONSTRATION")
    print("=" * 60)
    
    # Check CUDA availability
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available, skipping mixed precision demonstration")
        return
    
    # Create model and dataset
    model = SimpleNeuralNetwork()
    dataset = DummyDataset(num_samples=1000)
    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    # Setup optimizer and loss
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()
    
    # Create mixed precision config
    config = MixedPrecisionConfig(
        enabled=True,
        init_scale=2**16,
        growth_factor=2.0,
        memory_efficient=True
    )
    
    print("üöÄ Starting basic mixed precision training...")
    start_time = time.time()
    
    # Train with mixed precision
    training_metrics = train_with_mixed_precision(
        model=model,
        train_loader=train_loader,
        optimizer=optimizer,
        criterion=criterion,
        num_epochs=5,
        config=config,
        adaptive=False
    )
    
    training_time = time.time() - start_time
    
    print(f"‚úÖ Basic mixed precision training completed in {training_time:.2f}s")
    print(f"Final Loss: {training_metrics['final_loss']:.4f}")
    print(f"Total Training Time: {training_metrics['total_training_time']:.2f}s")
    
    if 'mixed_precision_summary' in training_metrics:
        summary = training_metrics['mixed_precision_summary']
        print(f"Mixed Precision Enabled: {summary['config']['enabled']}")
        print(f"Memory Savings: {summary.get('estimated_memory_savings', 'N/A')}")
    
    return training_metrics


def demonstrate_adaptive_mixed_precision():
    """Demonstrate adaptive mixed precision training."""
    print("\n" + "=" * 60)
    print("ü§ñ ADAPTIVE MIXED PRECISION TRAINING DEMONSTRATION")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available, skipping adaptive mixed precision demonstration")
        return
    
    # Create model and dataset
    model = SimpleNeuralNetwork()
    dataset = DummyDataset(num_samples=1000)
    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    # Setup optimizer and loss
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()
    
    # Create adaptive mixed precision config
    config = MixedPrecisionConfig(
        enabled=True,
        init_scale=2**16,
        growth_factor=2.0,
        memory_efficient=True
    )
    
    print("üöÄ Starting adaptive mixed precision training...")
    start_time = time.time()
    
    # Train with adaptive mixed precision
    training_metrics = train_with_mixed_precision(
        model=model,
        train_loader=train_loader,
        optimizer=optimizer,
        criterion=criterion,
        num_epochs=5,
        config=config,
        adaptive=True
    )
    
    training_time = time.time() - start_time
    
    print(f"‚úÖ Adaptive mixed precision training completed in {training_time:.2f}s")
    print(f"Final Loss: {training_metrics['final_loss']:.4f}")
    print(f"Total Training Time: {training_metrics['total_training_time']:.2f}s")
    
    if 'adaptation_summary' in training_metrics:
        adaptation = training_metrics['adaptation_summary']
        print(f"Total Adaptations: {adaptation['total_adaptations']}")
        print(f"Current Config: {adaptation['current_config']}")
    
    return training_metrics


def demonstrate_convolutional_mixed_precision():
    """Demonstrate mixed precision training with convolutional models."""
    print("\n" + "=" * 60)
    print("üñºÔ∏è CONVOLUTIONAL MIXED PRECISION TRAINING DEMONSTRATION")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available, skipping convolutional mixed precision demonstration")
        return
    
    # Create convolutional model and dataset
    model = ConvNeuralNetwork()
    dataset = ConvDummyDataset(num_samples=1000)
    train_loader = DataLoader(dataset, batch_size=16, shuffle=True)  # Smaller batch size for conv model
    
    # Setup optimizer and loss
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()
    
    # Create optimized mixed precision config for convolutional model
    available_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    config = optimize_mixed_precision_settings(model, 16, available_memory)
    
    print(f"üöÄ Starting convolutional mixed precision training (GPU Memory: {available_memory:.1f}GB)...")
    start_time = time.time()
    
    # Train with mixed precision
    training_metrics = train_with_mixed_precision(
        model=model,
        train_loader=train_loader,
        optimizer=optimizer,
        criterion=criterion,
        num_epochs=3,  # Shorter for conv model
        config=config,
        adaptive=True
    )
    
    training_time = time.time() - start_time
    
    print(f"‚úÖ Convolutional mixed precision training completed in {training_time:.2f}s")
    print(f"Final Loss: {training_metrics['final_loss']:.4f}")
    print(f"Total Training Time: {training_metrics['total_training_time']:.2f}s")
    
    return training_metrics


def demonstrate_mixed_precision_benchmark():
    """Demonstrate mixed precision benchmarking."""
    print("\n" + "=" * 60)
    print("üìä MIXED PRECISION BENCHMARKING DEMONSTRATION")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available, skipping benchmark demonstration")
        return
    
    # Test different model types
    models_to_test = [
        ("Simple Neural Network", SimpleNeuralNetwork()),
        ("Convolutional Neural Network", ConvNeuralNetwork())
    ]
    
    benchmark_results = {}
    
    for model_name, model in models_to_test:
        print(f"\nüß™ Benchmarking {model_name}...")
        
        # Move model to GPU
        model = model.cuda()
        
        # Create sample data
        if isinstance(model, ConvNeuralNetwork):
            data = torch.randn(32, 3, 32, 32).cuda()
        else:
            data = torch.randn(32, 10).cuda()
        
        # Run benchmark
        results = benchmark_mixed_precision(model, data, num_iterations=50)
        
        if results:
            benchmark_results[model_name] = results
            print(f"  ‚úÖ {model_name} benchmark completed")
            print(f"     Speed improvement: {results['speed_improvement_percent']:.1f}%")
            print(f"     Memory improvement: {results['memory_improvement_percent']:.1f}%")
        else:
            print(f"  ‚ùå {model_name} benchmark failed")
    
    return benchmark_results


def demonstrate_mixed_precision_recommendations():
    """Demonstrate mixed precision recommendations."""
    print("\n" + "=" * 60)
    print("üí° MIXED PRECISION RECOMMENDATIONS DEMONSTRATION")
    print("=" * 60)
    
    # Test different scenarios
    scenarios = [
        ("Small Model", SimpleNeuralNetwork(), 8, 4.0),
        ("Medium Model", SimpleNeuralNetwork(10, 128, 2), 32, 8.0),
        ("Large Model", SimpleNeuralNetwork(10, 512, 2), 64, 16.0),
        ("Convolutional Model", ConvNeuralNetwork(), 16, 8.0)
    ]
    
    recommendations = {}
    
    for scenario_name, model, batch_size, available_memory in scenarios:
        print(f"\nüîç Analyzing {scenario_name}...")
        
        # Check if mixed precision should be used
        should_use = should_use_mixed_precision(model, batch_size, available_memory)
        
        # Get optimized settings
        config = optimize_mixed_precision_settings(model, batch_size, available_memory)
        
        recommendations[scenario_name] = {
            'should_use_mixed_precision': should_use,
            'config': {
                'enabled': config.enabled,
                'init_scale': config.init_scale,
                'growth_factor': config.growth_factor,
                'memory_efficient': config.memory_efficient
            },
            'model_params': sum(p.numel() for p in model.parameters()),
            'batch_size': batch_size,
            'available_memory': available_memory
        }
        
        print(f"  ‚úÖ {scenario_name} analysis completed")
        print(f"     Should use mixed precision: {should_use}")
        print(f"     Model parameters: {recommendations[scenario_name]['model_params']:,}")
        print(f"     Recommended config: {config.enabled}, scale={config.init_scale}")
    
    return recommendations


def demonstrate_mixed_precision_context():
    """Demonstrate mixed precision context manager."""
    print("\n" + "=" * 60)
    print("üîß MIXED PRECISION CONTEXT MANAGER DEMONSTRATION")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available, skipping context manager demonstration")
        return
    
    # Create model and data
    model = SimpleNeuralNetwork().cuda()
    data = torch.randn(32, 10).cuda()
    
    print("üß™ Testing mixed precision context manager...")
    
    # Test with mixed precision enabled
    with mixed_precision_context(enabled=True):
        output1 = model(data)
        print(f"  ‚úÖ Mixed precision forward pass completed")
        print(f"     Output dtype: {output1.dtype}")
    
    # Test with mixed precision disabled
    with mixed_precision_context(enabled=False):
        output2 = model(data)
        print(f"  ‚úÖ Regular precision forward pass completed")
        print(f"     Output dtype: {output2.dtype}")
    
    # Compare outputs
    output_diff = torch.abs(output1 - output2).mean().item()
    print(f"  üìä Output difference (mixed vs regular): {output_diff:.6f}")
    
    return {
        'mixed_precision_output_dtype': str(output1.dtype),
        'regular_output_dtype': str(output2.dtype),
        'output_difference': output_diff
    }


def demonstrate_scaler_management():
    """Demonstrate GradScaler state management."""
    print("\n" + "=" * 60)
    print("üíæ GRADSCALER STATE MANAGEMENT DEMONSTRATION")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available, skipping scaler management demonstration")
        return
    
    # Create trainer
    config = MixedPrecisionConfig(enabled=True)
    trainer = MixedPrecisionTrainer(config)
    
    print("üß™ Testing GradScaler state management...")
    
    # Get initial state
    initial_scale = trainer.scaler.get_scale() if trainer.scaler else 1.0
    print(f"  üìä Initial scale: {initial_scale}")
    
    # Simulate some training steps to change the scale
    model = SimpleNeuralNetwork().cuda()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()
    
    for i in range(5):
        data = torch.randn(8, 10).cuda()
        target = torch.randint(0, 2, (8,)).cuda()
        
        step_result = trainer.train_step(model, optimizer, criterion, data, target)
        current_scale = trainer.scaler.get_scale() if trainer.scaler else 1.0
        
        print(f"  Step {i+1}: Loss = {step_result['loss']:.4f}, Scale = {current_scale:.0f}")
    
    # Save scaler state
    scaler_path = "scaler_state.pt"
    trainer.save_scaler_state(scaler_path)
    print(f"  üíæ Scaler state saved to {scaler_path}")
    
    # Create new trainer and load state
    new_trainer = MixedPrecisionTrainer(config)
    new_trainer.load_scaler_state(scaler_path)
    
    loaded_scale = new_trainer.scaler.get_scale() if new_trainer.scaler else 1.0
    print(f"  üì• Scaler state loaded, scale: {loaded_scale}")
    
    return {
        'initial_scale': initial_scale,
        'final_scale': current_scale,
        'loaded_scale': loaded_scale,
        'scaler_path': scaler_path
    }


def demonstrate_performance_comparison():
    """Demonstrate performance comparison between mixed and regular precision."""
    print("\n" + "=" * 60)
    print("‚ö° PERFORMANCE COMPARISON DEMONSTRATION")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available, skipping performance comparison")
        return
    
    # Create model and data
    model = SimpleNeuralNetwork().cuda()
    data = torch.randn(64, 10).cuda()
    target = torch.randint(0, 2, (64,)).cuda()
    
    # Setup training components
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()
    
    print("üß™ Comparing mixed precision vs regular precision performance...")
    
    # Test regular precision
    model.train()
    start_time = time.time()
    memory_before = torch.cuda.memory_allocated()
    
    for _ in range(100):
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
    
    torch.cuda.synchronize()
    regular_time = time.time() - start_time
    regular_memory = torch.cuda.memory_allocated() - memory_before
    
    # Test mixed precision
    config = MixedPrecisionConfig(enabled=True)
    trainer = MixedPrecisionTrainer(config)
    
    model.train()
    start_time = time.time()
    memory_before = torch.cuda.memory_allocated()
    
    for _ in range(100):
        step_result = trainer.train_step(model, optimizer, criterion, data, target)
    
    torch.cuda.synchronize()
    mixed_time = time.time() - start_time
    mixed_memory = torch.cuda.memory_allocated() - memory_before
    
    # Calculate improvements
    speed_improvement = (regular_time - mixed_time) / regular_time * 100
    memory_improvement = (regular_memory - mixed_memory) / regular_memory * 100
    
    print(f"  üìä Performance Results:")
    print(f"     Regular precision: {regular_time:.3f}s, {regular_memory/1024**3:.2f}GB")
    print(f"     Mixed precision: {mixed_time:.3f}s, {mixed_memory/1024**3:.2f}GB")
    print(f"     Speed improvement: {speed_improvement:.1f}%")
    print(f"     Memory improvement: {memory_improvement:.1f}%")
    
    return {
        'regular_time': regular_time,
        'mixed_time': mixed_time,
        'regular_memory_gb': regular_memory / (1024**3),
        'mixed_memory_gb': mixed_memory / (1024**3),
        'speed_improvement_percent': speed_improvement,
        'memory_improvement_percent': memory_improvement
    }


def main():
    """Run all mixed precision demonstrations."""
    print("üöÄ MIXED PRECISION TRAINING DEMONSTRATION SUITE")
    print("=" * 80)
    
    # Check CUDA availability
    print(f"CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f}GB")
    
    print("\n" + "=" * 80)
    
    # Run demonstrations
    demonstrations = [
        ("Basic Mixed Precision", demonstrate_basic_mixed_precision),
        ("Adaptive Mixed Precision", demonstrate_adaptive_mixed_precision),
        ("Convolutional Mixed Precision", demonstrate_convolutional_mixed_precision),
        ("Mixed Precision Benchmark", demonstrate_mixed_precision_benchmark),
        ("Mixed Precision Recommendations", demonstrate_mixed_precision_recommendations),
        ("Mixed Precision Context", demonstrate_mixed_precision_context),
        ("Scaler Management", demonstrate_scaler_management),
        ("Performance Comparison", demonstrate_performance_comparison),
    ]
    
    results = {}
    
    for name, demo_func in demonstrations:
        try:
            print(f"\nüéØ Running: {name}")
            result = demo_func()
            results[name] = {"success": True, "result": result}
            print(f"‚úÖ {name} completed successfully")
        except Exception as e:
            print(f"‚ùå {name} failed: {e}")
            results[name] = {"success": False, "error": str(e)}
    
    # Summary
    print("\n" + "=" * 80)
    print("üìã DEMONSTRATION SUMMARY")
    print("=" * 80)
    
    successful = sum(1 for r in results.values() if r["success"])
    total = len(results)
    
    print(f"Successful Demonstrations: {successful}/{total}")
    
    for name, result in results.items():
        status = "‚úÖ" if result["success"] else "‚ùå"
        print(f"{status} {name}")
    
    print(f"\nüéâ Mixed precision training demonstration completed!")
    print(f"   Success Rate: {successful/total*100:.1f}%")
    
    return results


match __name__:
    case "__main__":
    main() 