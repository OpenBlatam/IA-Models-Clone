#!/usr/bin/env python3
"""
Enhanced Libraries Startup Script - Optimized Launch
==================================================

Optimized startup script for the AI Document Processor with enhanced libraries.
"""

import os
import sys
import asyncio
import logging
import time
from pathlib import Path
from typing import Dict, Any, Optional
import signal
import subprocess
import psutil

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('enhanced_startup.log')
    ]
)
logger = logging.getLogger(__name__)


class EnhancedStartupManager:
    """Enhanced startup manager with optimizations."""
    
    def __init__(self):
        self.processes: Dict[str, subprocess.Popen] = {}
        self.startup_time = time.time()
        self.config = self._load_config()
        self.system_info = self._get_system_info()
        
    def _load_config(self) -> Dict[str, Any]:
        """Load startup configuration."""
        return {
            'host': '0.0.0.0',
            'port': 8001,
            'workers': 1,
            'reload': False,
            'log_level': 'info',
            'enable_gpu': True,
            'enable_monitoring': True,
            'enable_caching': True,
            'max_memory_gb': 8,
            'cache_size_mb': 1024
        }
    
    def _get_system_info(self) -> Dict[str, Any]:
        """Get system information."""
        try:
            return {
                'cpu_count': psutil.cpu_count(),
                'memory_gb': round(psutil.virtual_memory().total / (1024**3), 2),
                'disk_free_gb': round(psutil.disk_usage('/').free / (1024**3), 2) if os.name != 'nt' else round(psutil.disk_usage('C:').free / (1024**3), 2),
                'platform': os.name
            }
        except Exception as e:
            logger.warning(f"Could not get system info: {e}")
            return {'cpu_count': 1, 'memory_gb': 4.0, 'platform': 'unknown'}
    
    def print_enhanced_banner(self):
        """Print enhanced startup banner."""
        print("\n" + "="*80)
        print("ğŸš€ AI DOCUMENT PROCESSOR - ENHANCED STARTUP")
        print("="*80)
        print("Starting with enhanced libraries and optimizations")
        print("="*80)
        
        print(f"System: {self.system_info['platform']}")
        print(f"CPU Cores: {self.system_info['cpu_count']}")
        print(f"Memory: {self.system_info['memory_gb']} GB")
        print(f"Host: {self.config['host']}")
        print(f"Port: {self.config['port']}")
        print(f"Workers: {self.config['workers']}")
        print(f"GPU Enabled: {'âœ…' if self.config['enable_gpu'] else 'âŒ'}")
        print(f"Monitoring: {'âœ…' if self.config['enable_monitoring'] else 'âŒ'}")
        print(f"Caching: {'âœ…' if self.config['enable_caching'] else 'âŒ'}")
        
        print("="*80 + "\n")
    
    def apply_system_optimizations(self):
        """Apply system optimizations."""
        logger.info("ğŸ”§ Applying system optimizations...")
        
        # Set environment variables for performance
        os.environ['PYTHONHASHSEED'] = '0'
        os.environ['PYTHONUNBUFFERED'] = '1'
        os.environ['PYTHONIOENCODING'] = 'utf-8'
        
        # CPU optimizations
        if self.system_info['cpu_count'] > 1:
            os.environ['OMP_NUM_THREADS'] = str(self.system_info['cpu_count'])
            os.environ['MKL_NUM_THREADS'] = str(self.system_info['cpu_count'])
            os.environ['NUMEXPR_NUM_THREADS'] = str(self.system_info['cpu_count'])
            os.environ['OPENBLAS_NUM_THREADS'] = str(self.system_info['cpu_count'])
        
        # Memory optimizations
        if self.config['max_memory_gb'] > 0:
            os.environ['PYTHONMALLOC'] = 'malloc'
        
        # GPU optimizations
        if self.config['enable_gpu']:
            os.environ['CUDA_VISIBLE_DEVICES'] = '0'
            os.environ['TORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
        
        # Async optimizations
        if os.name != 'nt':  # Not Windows
            os.environ['UVLOOP'] = '1'
        
        logger.info("âœ… System optimizations applied")
    
    def check_dependencies(self) -> bool:
        """Check if all dependencies are available."""
        logger.info("ğŸ” Checking dependencies...")
        
        required_modules = [
            'fastapi',
            'uvicorn',
            'pydantic',
            'redis',
            'numpy',
            'pandas',
            'torch',
            'transformers',
            'openai',
            'chromadb',
            'spacy',
            'nltk',
            'orjson',
            'lz4',
            'prometheus_client'
        ]
        
        missing_modules = []
        
        for module in required_modules:
            try:
                __import__(module)
                logger.info(f"âœ… {module}")
            except ImportError:
                missing_modules.append(module)
                logger.error(f"âŒ {module} - MISSING")
        
        if missing_modules:
            logger.error(f"Missing modules: {missing_modules}")
            logger.error("Please run: python install_enhanced_libraries.py")
            return False
        
        logger.info("âœ… All dependencies available")
        return True
    
    def start_redis(self) -> bool:
        """Start Redis server if not running."""
        try:
            import redis
            r = redis.Redis(host='localhost', port=6379, db=0)
            r.ping()
            logger.info("âœ… Redis already running")
            return True
        except:
            logger.info("ğŸ”„ Starting Redis server...")
            try:
                if os.name == 'nt':  # Windows
                    redis_cmd = ['redis-server', '--port', '6379']
                else:  # Linux/Mac
                    redis_cmd = ['redis-server', '--port', '6379', '--daemonize', 'yes']
                
                process = subprocess.Popen(redis_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                self.processes['redis'] = process
                
                # Wait for Redis to start
                time.sleep(2)
                
                # Test connection
                import redis
                r = redis.Redis(host='localhost', port=6379, db=0)
                r.ping()
                
                logger.info("âœ… Redis started successfully")
                return True
                
            except Exception as e:
                logger.error(f"âŒ Failed to start Redis: {e}")
                return False
    
    def start_monitoring(self):
        """Start monitoring services."""
        if not self.config['enable_monitoring']:
            return
        
        logger.info("ğŸ“Š Starting monitoring services...")
        
        try:
            # Start Prometheus metrics server
            from prometheus_client import start_http_server
            start_http_server(9090)
            logger.info("âœ… Prometheus metrics server started on port 9090")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Could not start monitoring: {e}")
    
    def initialize_ai_models(self):
        """Initialize AI models."""
        logger.info("ğŸ¤– Initializing AI models...")
        
        try:
            # Initialize OpenAI
            import openai
            if os.getenv('OPENAI_API_KEY'):
                logger.info("âœ… OpenAI initialized")
            else:
                logger.warning("âš ï¸ OpenAI API key not set")
            
            # Initialize Transformers
            from transformers import pipeline
            logger.info("âœ… Transformers initialized")
            
            # Initialize spaCy
            import spacy
            try:
                nlp = spacy.load("en_core_web_sm")
                logger.info("âœ… spaCy model loaded")
            except OSError:
                logger.warning("âš ï¸ spaCy model not found, run: python -m spacy download en_core_web_sm")
            
            # Initialize ChromaDB
            import chromadb
            client = chromadb.Client()
            logger.info("âœ… ChromaDB initialized")
            
        except Exception as e:
            logger.warning(f"âš ï¸ AI model initialization warning: {e}")
    
    def start_fastapi_server(self):
        """Start FastAPI server."""
        logger.info("ğŸš€ Starting FastAPI server...")
        
        try:
            # Import and configure FastAPI app
            from main import app
            
            # Configure Uvicorn
            uvicorn_config = {
                'app': app,
                'host': self.config['host'],
                'port': self.config['port'],
                'workers': self.config['workers'],
                'reload': self.config['reload'],
                'log_level': self.config['log_level'],
                'access_log': True
            }
            
            # Add performance optimizations
            if os.name != 'nt':  # Not Windows
                uvicorn_config['loop'] = 'uvloop'
            
            # Start server
            import uvicorn
            uvicorn.run(**uvicorn_config)
            
        except Exception as e:
            logger.error(f"âŒ Failed to start FastAPI server: {e}")
            raise
    
    def setup_signal_handlers(self):
        """Setup signal handlers for graceful shutdown."""
        def signal_handler(signum, frame):
            logger.info(f"ğŸ›‘ Received signal {signum}, shutting down gracefully...")
            self.shutdown()
            sys.exit(0)
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    def shutdown(self):
        """Graceful shutdown."""
        logger.info("ğŸ›‘ Shutting down services...")
        
        # Stop all processes
        for name, process in self.processes.items():
            try:
                process.terminate()
                process.wait(timeout=5)
                logger.info(f"âœ… Stopped {name}")
            except subprocess.TimeoutExpired:
                process.kill()
                logger.warning(f"âš ï¸ Force killed {name}")
            except Exception as e:
                logger.error(f"âŒ Error stopping {name}: {e}")
        
        # Calculate uptime
        uptime = time.time() - self.startup_time
        logger.info(f"ğŸ“Š Total uptime: {uptime:.2f} seconds")
    
    def run_health_check(self) -> bool:
        """Run health check."""
        logger.info("ğŸ¥ Running health check...")
        
        try:
            import requests
            response = requests.get(f"http://{self.config['host']}:{self.config['port']}/health", timeout=5)
            
            if response.status_code == 200:
                logger.info("âœ… Health check passed")
                return True
            else:
                logger.error(f"âŒ Health check failed: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Health check error: {e}")
            return False
    
    def print_startup_summary(self):
        """Print startup summary."""
        print("\n" + "="*80)
        print("ğŸ‰ ENHANCED STARTUP COMPLETE")
        print("="*80)
        
        print("ğŸš€ Services Started:")
        print("   âœ… FastAPI Server")
        print("   âœ… Redis Cache")
        print("   âœ… Monitoring")
        print("   âœ… AI Models")
        
        print(f"\nğŸŒ Access Points:")
        print(f"   ğŸ“– API Documentation: http://{self.config['host']}:{self.config['port']}/docs")
        print(f"   ğŸ”§ ReDoc: http://{self.config['host']}:{self.config['port']}/redoc")
        print(f"   ğŸ¥ Health Check: http://{self.config['host']}:{self.config['port']}/health")
        print(f"   ğŸ“Š Metrics: http://{self.config['host']}:9090/metrics")
        
        print(f"\nâš¡ Performance Features:")
        print("   ğŸš€ Ultra-fast JSON serialization (OrJSON)")
        print("   ğŸ—œï¸ Advanced compression (LZ4, Zstandard)")
        print("   ğŸ¤– GPU-accelerated AI processing")
        print("   ğŸ“Š Real-time monitoring")
        print("   ğŸ’¾ Intelligent caching")
        print("   ğŸ”„ Async operations")
        
        print(f"\nğŸ› ï¸ Enhanced Libraries:")
        print("   ğŸ“š 500+ optimized libraries")
        print("   ğŸ¯ System-specific optimizations")
        print("   ğŸ”§ Automatic configuration")
        print("   ğŸ“ˆ Performance monitoring")
        print("   ğŸš€ Maximum speed and efficiency")
        
        print("="*80 + "\n")
    
    def start(self):
        """Start all services."""
        try:
            # Print banner
            self.print_enhanced_banner()
            
            # Setup signal handlers
            self.setup_signal_handlers()
            
            # Apply optimizations
            self.apply_system_optimizations()
            
            # Check dependencies
            if not self.check_dependencies():
                logger.error("âŒ Dependency check failed")
                return False
            
            # Start Redis
            if not self.start_redis():
                logger.warning("âš ï¸ Redis not available, some features may be limited")
            
            # Start monitoring
            self.start_monitoring()
            
            # Initialize AI models
            self.initialize_ai_models()
            
            # Print summary
            self.print_startup_summary()
            
            # Start FastAPI server
            self.start_fastapi_server()
            
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ Startup interrupted by user")
        except Exception as e:
            logger.error(f"âŒ Startup failed: {e}")
            raise
        finally:
            self.shutdown()


def main():
    """Main startup function."""
    startup_manager = EnhancedStartupManager()
    startup_manager.start()


if __name__ == "__main__":
    main()

















