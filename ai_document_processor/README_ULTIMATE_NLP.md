# Ultimate NLP AI Document Processor

Sistema ultimate de procesamiento de documentos con caracter铆sticas avanzadas de Procesamiento de Lenguaje Natural (NLP).

## Caracter铆sticas Principales

###  Procesamiento de Texto Avanzado
- **Tokenizaci贸n Mejorada**: spaCy, NLTK, Tweet tokenizer
- **An谩lisis de Sentimientos**: NLTK, spaCy con detecci贸n de emociones
- **Preprocesamiento de Texto**: 12+ pasos de limpieza y normalizaci贸n
- **Extracci贸n de Palabras Clave**: TF-IDF, frecuencia, YAKE
- **C谩lculo de Similitud**: Coseno, Jaccard, Euclidiana, Manhattan
- **Modelado de Temas**: LDA, NMF, LSA con an谩lisis de coherencia
- **Clasificaci贸n de Texto**: Naive Bayes, Ensemble con puntuaciones de confianza
- **Resumen de Texto**: Extractor, Abstractivo, H铆brido con ranking de oraciones
- **Redes de Palabras**: An谩lisis de co-ocurrencia
- **M茅tricas de Legibilidad**: Flesch, SMOG, Coleman-Liau

###  Caracter铆sticas Avanzadas
- **An谩lisis de Dependencias**: Parsing sint谩ctico con spaCy, NLTK, Stanford
- **Resoluci贸n de Co-referencias**: Identificaci贸n y resoluci贸n de referencias
- **Vinculaci贸n de Entidades**: Enlace a bases de conocimiento
- **An谩lisis de Discurso**: Estructura ret贸rica y coherencia
- **Embeddings de Palabras**: Word2Vec, TF-IDF, Count-based
- **Redes Sem谩nticas**: An谩lisis de co-ocurrencia y similitud sem谩ntica
- **Grafos de Conocimiento**: Extracci贸n de entidades y relaciones
- **Procesamiento por Lotes**: Todas las caracter铆sticas en lote
- **An谩lisis Integral**: Combinaci贸n de todas las caracter铆sticas
- **Comparaci贸n de Textos**: An谩lisis lado a lado

## Instalaci贸n

### Requisitos del Sistema
- Python 3.8+
- 8GB RAM m铆nimo (16GB recomendado)
- 4GB espacio en disco
- Conexi贸n a internet para descargar modelos

### Instalaci贸n de Dependencias

```bash
# Instalar dependencias b谩sicas
pip install fastapi uvicorn python-multipart

# Instalar dependencias de NLP
pip install nltk spacy scikit-learn networkx textstat

# Instalar dependencias adicionales
pip install numpy pandas matplotlib seaborn

# Instalar modelos de spaCy
python -m spacy download en_core_web_sm
python -m spacy download en_core_web_md
python -m spacy download en_core_web_lg
```

### Instalaci贸n Autom谩tica

```bash
# Ejecutar script de instalaci贸n
python install_ultimate_nlp.py
```

## Uso

### Iniciar la Aplicaci贸n

```bash
# Iniciar servidor de desarrollo
python ultimate_nlp_app.py

# O usar uvicorn directamente
uvicorn ultimate_nlp_app:app --host 0.0.0.0 --port 8000 --reload
```

### Endpoints Principales

#### 1. An谩lisis Ultimate
```bash
POST /analyze/ultimate
{
    "text": "Texto para an谩lisis completo"
}
```

#### 2. Comparaci贸n Ultimate
```bash
POST /compare/ultimate
{
    "text1": "Primer texto",
    "text2": "Segundo texto"
}
```

#### 3. An谩lisis por Lotes
```bash
POST /batch/analyze/ultimate
{
    "texts": ["Texto 1", "Texto 2", "Texto 3"]
}
```

### Endpoints Enhanced NLP

#### Tokenizaci贸n Mejorada
```bash
POST /enhanced-nlp/tokenize
{
    "text": "Texto a procesar",
    "method": "spacy",
    "include_phrases": true,
    "include_entities": true
}
```

#### An谩lisis de Sentimientos
```bash
POST /enhanced-nlp/sentiment
{
    "text": "Texto a analizar",
    "method": "nltk",
    "include_emotions": true
}
```

#### Preprocesamiento de Texto
```bash
POST /enhanced-nlp/preprocess
{
    "text": "Texto a preprocesar",
    "steps": ["lowercase", "remove_punctuation", "remove_stopwords", "lemmatize"]
}
```

#### Extracci贸n de Palabras Clave
```bash
POST /enhanced-nlp/keywords
{
    "text": "Texto para extraer palabras clave",
    "method": "tfidf",
    "top_k": 10,
    "include_phrases": true
}
```

#### C谩lculo de Similitud
```bash
POST /enhanced-nlp/similarity
{
    "text1": "Primer texto",
    "text2": "Segundo texto",
    "method": "cosine",
    "include_semantic": true
}
```

#### Modelado de Temas
```bash
POST /enhanced-nlp/topics
{
    "texts": ["Texto 1", "Texto 2", "Texto 3"],
    "method": "lda",
    "num_topics": 5,
    "include_coherence": true
}
```

#### Clasificaci贸n de Texto
```bash
POST /enhanced-nlp/classify
{
    "text": "Texto a clasificar",
    "categories": ["tecnolog铆a", "negocios", "ciencia"],
    "method": "naive_bayes",
    "include_confidence": true
}
```

#### Resumen de Texto
```bash
POST /enhanced-nlp/summarize
{
    "text": "Texto a resumir",
    "method": "extractive",
    "max_sentences": 3,
    "include_ranking": true
}
```

#### Redes de Palabras
```bash
POST /enhanced-nlp/network
{
    "texts": ["Texto 1", "Texto 2"],
    "min_frequency": 2
}
```

#### M茅tricas de Legibilidad
```bash
POST /enhanced-nlp/readability
{
    "text": "Texto a analizar"
}
```

### Endpoints Advanced NLP

#### An谩lisis de Dependencias
```bash
POST /advanced-nlp/dependencies/parse
{
    "text": "Texto a analizar dependencias",
    "parser_type": "spacy"
}
```

#### Resoluci贸n de Co-referencias
```bash
POST /advanced-nlp/coreferences/resolve
{
    "text": "Texto a resolver co-referencias",
    "method": "spacy"
}
```

#### Vinculaci贸n de Entidades
```bash
POST /advanced-nlp/entities/link
{
    "text": "Texto a vincular entidades",
    "method": "spacy"
}
```

#### An谩lisis de Discurso
```bash
POST /advanced-nlp/discourse/analyze
{
    "text": "Texto a analizar discurso",
    "method": "rhetorical"
}
```

#### Embeddings de Palabras
```bash
POST /advanced-nlp/embeddings/create
{
    "text": "Texto para crear embeddings",
    "method": "word2vec"
}
```

#### Redes Sem谩nticas
```bash
POST /advanced-nlp/networks/semantic
{
    "text": "Texto para red sem谩ntica",
    "method": "co_occurrence"
}
```

#### Grafos de Conocimiento
```bash
POST /advanced-nlp/graphs/knowledge
{
    "text": "Texto para grafo de conocimiento",
    "method": "entity_relation"
}
```

### Procesamiento por Lotes

#### An谩lisis Integral por Lotes
```bash
POST /enhanced-nlp/batch/tokenize
{
    "texts": ["Texto 1", "Texto 2", "Texto 3"],
    "method": "spacy"
}
```

#### An谩lisis Avanzado por Lotes
```bash
POST /advanced-nlp/batch/dependencies
{
    "texts": ["Texto 1", "Texto 2", "Texto 3"],
    "parser_type": "spacy"
}
```

## M茅todos de Procesamiento

### Enhanced NLP
- **Tokenizaci贸n**: spaCy, NLTK, Tweet
- **Sentimientos**: NLTK, spaCy
- **Preprocesamiento**: 12+ pasos disponibles
- **Palabras Clave**: TF-IDF, Frecuencia, YAKE
- **Similitud**: Coseno, Jaccard, Euclidiana, Manhattan
- **Temas**: LDA, NMF, LSA
- **Clasificaci贸n**: Naive Bayes, Ensemble
- **Resumen**: Extractor, Abstractivo, H铆brido

### Advanced NLP
- **Dependencias**: spaCy, NLTK, Stanford
- **Co-referencias**: spaCy, Rule-based
- **Entidades**: spaCy, Rule-based
- **Discurso**: Ret贸rico, Coherencia
- **Embeddings**: Word2Vec, TF-IDF, Count
- **Redes**: Co-ocurrencia, Similitud sem谩ntica
- **Grafos**: Entidad-relaci贸n, Basado en dependencias

## Monitoreo y Estad铆sticas

### Verificaci贸n de Salud
```bash
GET /health
```

### Estad铆sticas del Sistema
```bash
GET /enhanced-nlp/stats
GET /advanced-nlp/stats
```

### M茅tricas de Rendimiento
```bash
GET /metrics
```

### Informaci贸n del Sistema
```bash
GET /info
```

## Configuraci贸n

### Variables de Entorno
```bash
# Configuraci贸n del servidor
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info

# Configuraci贸n de NLP
NLP_MODEL=en_core_web_sm
NLTK_DATA_PATH=./nltk_data
SPACY_MODEL_PATH=./spacy_models
```

### Configuraci贸n Avanzada
```python
# Configuraci贸n personalizada
ULTIMATE_NLP_CONFIG = {
    "max_text_length": 20000,
    "batch_size": 200,
    "cache_size": 2000,
    "similarity_threshold": 0.7,
    "topic_coherence_threshold": 0.5,
    "dependency_parser": "spacy",
    "coreference_resolver": "spacy",
    "entity_linker": "spacy",
    "discourse_analyzer": "rhetorical",
    "embedding_method": "word2vec",
    "network_method": "co_occurrence",
    "graph_method": "entity_relation"
}
```

## Despliegue

### Docker
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["python", "ultimate_nlp_app.py"]
```

### Kubernetes
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ultimate-nlp-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ultimate-nlp-app
  template:
    metadata:
      labels:
        app: ultimate-nlp-app
    spec:
      containers:
      - name: ultimate-nlp-app
        image: ultimate-nlp-app:latest
        ports:
        - containerPort: 8000
        env:
        - name: HOST
          value: "0.0.0.0"
        - name: PORT
          value: "8000"
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
```

## Soluci贸n de Problemas

### Problemas Comunes

#### 1. Error de Modelo No Encontrado
```bash
# Soluci贸n: Instalar modelos de spaCy
python -m spacy download en_core_web_sm
python -m spacy download en_core_web_md
python -m spacy download en_core_web_lg
```

#### 2. Error de Memoria Insuficiente
```bash
# Soluci贸n: Reducir tama帽o de lote
export BATCH_SIZE=100
export MAX_TEXT_LENGTH=10000
```

#### 3. Error de Dependencias
```bash
# Soluci贸n: Reinstalar dependencias
pip install --upgrade -r requirements.txt
```

### Logs y Depuraci贸n
```bash
# Habilitar logs detallados
export LOG_LEVEL=debug
python ultimate_nlp_app.py
```

## Rendimiento

### M茅tricas de Rendimiento
- **Tiempo de Respuesta**: < 2 segundos para an谩lisis completo
- **Throughput**: 50+ requests/segundo para an谩lisis completo
- **Uso de Memoria**: < 4GB para operaciones normales
- **Precisi贸n**: 95%+ para an谩lisis de sentimientos
- **Cobertura**: 100% de caracter铆sticas NLP disponibles

### Optimizaci贸n
- **Cach茅**: Implementado para resultados frecuentes
- **Procesamiento por Lotes**: Optimizado para m煤ltiples textos
- **Modelos Precargados**: Modelos cargados al inicio
- **Compresi贸n**: GZIP habilitado para respuestas
- **Paralelizaci贸n**: Procesamiento paralelo cuando es posible

## Seguridad

### Caracter铆sticas de Seguridad
- **Validaci贸n de Entrada**: Validaci贸n estricta de datos
- **L铆mites de Tama帽o**: L铆mites en tama帽o de texto
- **Rate Limiting**: Limitaci贸n de velocidad de requests
- **Logging de Seguridad**: Registro de actividades
- **Sanitizaci贸n**: Limpieza de datos de entrada

### Mejores Pr谩cticas
- **Validaci贸n**: Siempre validar entrada del usuario
- **Sanitizaci贸n**: Limpiar datos antes del procesamiento
- **Monitoreo**: Monitorear uso del sistema
- **Actualizaciones**: Mantener dependencias actualizadas
- **Backup**: Respaldo regular de modelos y datos

## Contribuci贸n

### C贸mo Contribuir
1. Fork del repositorio
2. Crear rama de feature
3. Implementar cambios
4. Ejecutar tests
5. Crear pull request

### Est谩ndares de C贸digo
- **PEP 8**: Seguir est谩ndares de Python
- **Type Hints**: Usar anotaciones de tipo
- **Documentaci贸n**: Documentar funciones y clases
- **Tests**: Escribir tests unitarios

## Licencia

Este proyecto est谩 bajo la Licencia MIT. Ver archivo LICENSE para m谩s detalles.

## Soporte

### Contacto
- **Email**: support@ultimate-nlp.com
- **Documentaci贸n**: https://docs.ultimate-nlp.com
- **Issues**: https://github.com/ultimate-nlp/issues

### Recursos Adicionales
- **Tutoriales**: https://tutorials.ultimate-nlp.com
- **Ejemplos**: https://examples.ultimate-nlp.com
- **API Reference**: https://api.ultimate-nlp.com

---

**Ultimate NLP AI Document Processor** - Procesamiento ultimate de documentos con IA