# AI Document Processor - Refactored Architecture

## ğŸš€ Modern, Clean Architecture

A completely refactored AI document processing system with modern architecture, clean separation of concerns, and comprehensive error handling.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Documentation](#api-documentation)
- [Development](#development)
- [Testing](#testing)
- [Deployment](#deployment)
- [Contributing](#contributing)

## âœ¨ Features

### Core Features
- **Ultra-fast document processing** with parallel processing
- **Multiple document formats** support (PDF, Word, Markdown, HTML, XML)
- **AI-powered classification** and transformation
- **Streaming processing** for large files
- **Batch processing** capabilities
- **Real-time monitoring** and metrics

### Architecture Features
- **Clean Architecture** with separation of concerns
- **Dependency Injection** for better testability
- **Comprehensive Error Handling** with custom exceptions
- **Type Safety** with full type hints
- **Configuration Management** with validation
- **Async/Await** throughout the application
- **Modern FastAPI** with automatic documentation

### Performance Features
- **Memory optimization** with memory pools
- **Zero-copy operations** where possible
- **Intelligent caching** with multiple backends
- **Compression** for better performance
- **Connection pooling** for databases
- **Rate limiting** and security

## ğŸ—ï¸ Architecture

### Directory Structure
```
src/
â”œâ”€â”€ core/                 # Core business logic
â”‚   â”œâ”€â”€ config.py        # Configuration management
â”‚   â”œâ”€â”€ exceptions.py    # Custom exceptions
â”‚   â”œâ”€â”€ processor.py     # Main processor
â”‚   â””â”€â”€ monitor.py       # Performance monitoring
â”œâ”€â”€ models/              # Data models
â”‚   â”œâ”€â”€ document.py      # Document models
â”‚   â”œâ”€â”€ processing.py    # Processing models
â”‚   â””â”€â”€ errors.py        # Error models
â”œâ”€â”€ services/            # Business services
â”‚   â”œâ”€â”€ document_service.py
â”‚   â”œâ”€â”€ ai_service.py
â”‚   â”œâ”€â”€ transform_service.py
â”‚   â””â”€â”€ validation_service.py
â”œâ”€â”€ api/                 # API layer
â”‚   â”œâ”€â”€ app.py          # FastAPI application
â”‚   â”œâ”€â”€ routes/         # API routes
â”‚   â”œâ”€â”€ middleware/     # Custom middleware
â”‚   â””â”€â”€ dependencies.py # Dependency injection
â””â”€â”€ utils/              # Utility functions
    â”œâ”€â”€ file_handler.py
    â”œâ”€â”€ text_extractor.py
    â””â”€â”€ format_converter.py
```

### Design Patterns
- **Repository Pattern** for data access
- **Service Layer Pattern** for business logic
- **Dependency Injection** for loose coupling
- **Factory Pattern** for object creation
- **Observer Pattern** for event handling
- **Strategy Pattern** for processing algorithms

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- pip or poetry
- Redis (optional, for caching)
- PostgreSQL (optional, for persistence)

### Quick Start
```bash
# Clone the repository
git clone <repository-url>
cd ai-document-processor

# Install dependencies
pip install -r requirements.txt

# Run the application
python main_refactored.py
```

### Development Installation
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install

# Run tests
pytest

# Run linting
flake8 src/
black src/
mypy src/
```

## âš™ï¸ Configuration

### Environment Variables
```bash
# Server Configuration
HOST=0.0.0.0
PORT=8001
WORKERS=1

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost/dbname

# Cache Configuration
REDIS_URL=redis://localhost:6379/0
CACHE_MAX_MEMORY_MB=1024

# AI Configuration
AI_API_KEY=your-api-key
AI_PROVIDER=openai
AI_MODEL=gpt-3.5-turbo

# Security Configuration
SECRET_KEY=your-secret-key
ENABLE_RATE_LIMITING=true
```

### Configuration File
```yaml
# config_refactored.yaml
server:
  host: "0.0.0.0"
  port: 8001
  workers: 1

database:
  url: "postgresql://user:password@localhost/dbname"
  pool_size: 10

cache:
  enabled: true
  backend: "redis"
  redis_url: "redis://localhost:6379/0"

ai:
  provider: "openai"
  api_key: "your-api-key"
  model: "gpt-3.5-turbo"
```

## ğŸš€ Usage

### Basic Usage
```python
from src.services.document_service import DocumentService
from src.models.document import Document
from src.models.processing import ProcessingConfig

# Create document service
service = DocumentService()

# Create document
document = await service.create_document("path/to/document.pdf")

# Process document
result = await service.process_document(
    document.id,
    ProcessingConfig(enable_ai_classification=True)
)

# Get results
print(f"Extracted text: {result.extracted_text}")
print(f"Classified type: {result.classified_type}")
```

### Batch Processing
```python
# Process multiple documents
document_ids = ["doc1", "doc2", "doc3"]
batch_result = await service.process_batch(document_ids)

print(f"Success rate: {batch_result.get_success_rate():.1f}%")
```

### API Usage
```bash
# Upload and process document
curl -X POST "http://localhost:8001/api/v1/documents" \
  -F "file=@document.pdf" \
  -F "filename=document.pdf"

# Get processing status
curl "http://localhost:8001/api/v1/processing/{result_id}"

# Get document
curl "http://localhost:8001/api/v1/documents/{document_id}"
```

## ğŸ“š API Documentation

### Endpoints

#### Documents
- `POST /api/v1/documents` - Upload document
- `GET /api/v1/documents` - List documents
- `GET /api/v1/documents/{id}` - Get document
- `DELETE /api/v1/documents/{id}` - Delete document

#### Processing
- `POST /api/v1/processing` - Process document
- `POST /api/v1/processing/batch` - Batch process
- `GET /api/v1/processing/{id}` - Get processing result
- `GET /api/v1/processing/{id}/status` - Get processing status

#### Health & Metrics
- `GET /api/v1/health` - Health check
- `GET /api/v1/metrics` - Performance metrics
- `GET /api/v1/health/detailed` - Detailed health check

### Interactive Documentation
- **Swagger UI**: http://localhost:8001/docs
- **ReDoc**: http://localhost:8001/redoc
- **OpenAPI Schema**: http://localhost:8001/openapi.json

## ğŸ§ª Testing

### Running Tests
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_document_service.py

# Run with verbose output
pytest -v
```

### Test Structure
```
tests/
â”œâ”€â”€ unit/              # Unit tests
â”‚   â”œâ”€â”€ test_models/
â”‚   â”œâ”€â”€ test_services/
â”‚   â””â”€â”€ test_utils/
â”œâ”€â”€ integration/       # Integration tests
â”‚   â”œâ”€â”€ test_api/
â”‚   â””â”€â”€ test_processing/
â””â”€â”€ fixtures/          # Test fixtures
    â”œâ”€â”€ documents/
    â””â”€â”€ configs/
```

## ğŸš€ Deployment

### Docker Deployment
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY src/ ./src/
COPY config_refactored.yaml .

CMD ["python", "main_refactored.py"]
```

### Docker Compose
```yaml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/dbname
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis

  db:
    image: postgres:13
    environment:
      POSTGRES_DB: dbname
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password

  redis:
    image: redis:6-alpine
```

### Production Deployment
```bash
# Install production dependencies
pip install -r requirements-prod.txt

# Run with gunicorn
gunicorn src.api.app:app -w 4 -k uvicorn.workers.UvicornWorker

# Run with uvicorn
uvicorn src.api.app:app --host 0.0.0.0 --port 8001 --workers 4
```

## ğŸ“Š Monitoring

### Health Checks
```bash
# Basic health check
curl http://localhost:8001/api/v1/health

# Detailed health check
curl http://localhost:8001/api/v1/health/detailed
```

### Metrics
```bash
# Get performance metrics
curl http://localhost:8001/api/v1/metrics

# Prometheus metrics
curl http://localhost:8001/metrics
```

### Logging
- **Structured logging** with JSON format
- **Request/response logging** with timing
- **Error tracking** with stack traces
- **Performance metrics** collection

## ğŸ”§ Development

### Code Quality
```bash
# Format code
black src/
isort src/

# Lint code
flake8 src/
mypy src/

# Security check
bandit -r src/
```

### Pre-commit Hooks
```bash
# Install pre-commit
pip install pre-commit

# Install hooks
pre-commit install

# Run hooks manually
pre-commit run --all-files
```

### Adding New Features
1. Create feature branch
2. Add tests for new functionality
3. Implement feature with type hints
4. Update documentation
5. Run quality checks
6. Submit pull request

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

### Development Guidelines
- Follow PEP 8 style guide
- Add type hints to all functions
- Write comprehensive tests
- Update documentation
- Use meaningful commit messages

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- FastAPI for the excellent web framework
- Pydantic for data validation
- OpenAI for AI capabilities
- All contributors and users

## ğŸ“ Support

- **Documentation**: [docs.example.com](https://docs.example.com)
- **Issues**: [GitHub Issues](https://github.com/example/issues)
- **Discussions**: [GitHub Discussions](https://github.com/example/discussions)
- **Email**: support@example.com

---

**Made with â¤ï¸ by the AI Document Processor Team**

















