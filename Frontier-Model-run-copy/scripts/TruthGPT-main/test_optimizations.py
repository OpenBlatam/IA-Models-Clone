"""
Comprehensive test suite for TruthGPT optimizations.
"""

import torch
import torch.nn as nn
import numpy as np
from optimization_core import (
    OptimizedLayerNorm, CUDAOptimizations, TritonOptimizations,
    EnhancedGRPOTrainer, EnhancedGRPOArgs, apply_optimizations,
    get_optimization_config
)
from optimization_core.benchmarks import (
    benchmark_optimization_impact, create_text_input_generator,
    create_multimodal_input_generator, BenchmarkConfig, PerformanceBenchmark
)

def test_optimized_layer_norm():
    """Test OptimizedLayerNorm functionality."""
    print("üß™ Testing OptimizedLayerNorm...")
    
    batch_size, seq_len, hidden_size = 2, 128, 512
    
    original_norm = nn.LayerNorm(hidden_size)
    try:
        from optimization_core import OptimizedLayerNorm
        optimized_norm = OptimizedLayerNorm(hidden_size)
    except ImportError:
        optimized_norm = nn.LayerNorm(hidden_size)
    
    optimized_norm.weight.data.copy_(original_norm.weight.data)
    optimized_norm.bias.data.copy_(original_norm.bias.data)
    
    x = torch.randn(batch_size, seq_len, hidden_size)
    
    if torch.cuda.is_available():
        x = x.cuda()
        original_norm = original_norm.cuda()
        optimized_norm = optimized_norm.cuda()
    
    with torch.no_grad():
        original_output = original_norm(x)
        optimized_output = optimized_norm(x)
    
    diff = torch.abs(original_output - optimized_output).max().item()
    
    print(f"‚úÖ OptimizedLayerNorm test passed")
    print(f"   Max difference: {diff:.6f}")
    print(f"   CUDA available: {torch.cuda.is_available()}")
    
    return diff < 1e-4

def test_cuda_optimizations():
    """Test CUDA optimization utilities."""
    print("\nüß™ Testing CUDA Optimizations...")
    
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            try:
                from optimization_core import OptimizedLayerNorm
                self.norm1 = OptimizedLayerNorm(512)
                self.norm2 = OptimizedLayerNorm(256)
            except ImportError:
                self.norm1 = nn.LayerNorm(512)
                self.norm2 = nn.LayerNorm(256)
            try:
                from optimization_core.enhanced_mlp import EnhancedLinear
                self.linear = EnhancedLinear(512, 256)
            except ImportError:
                self.linear = nn.Linear(512, 256)
        
        def forward(self, x):
            x = self.norm1(x)
            x = self.linear(x)
            x = self.norm2(x)
            return x
    
    model = SimpleModel()
    
    report_before = CUDAOptimizations.get_optimization_report(model)
    optimized_model = CUDAOptimizations.replace_layer_norm(model)
    report_after = CUDAOptimizations.get_optimization_report(optimized_model)
    
    print(f"‚úÖ CUDA optimizations test passed")
    print(f"   LayerNorm modules before: {report_before['layer_norm_modules']}")
    print(f"   Optimized modules after: {report_after['optimized_modules']}")
    print(f"   Optimization ratio: {report_after['optimization_ratio']:.2f}")
    
    return report_after['optimized_modules'] > 0

def test_enhanced_grpo():
    """Test Enhanced GRPO trainer."""
    print("\nüß™ Testing Enhanced GRPO...")
    
    class DummyModel(nn.Module):
        def __init__(self):
            super().__init__()
            try:
                from optimization_core.enhanced_mlp import EnhancedLinear
                self.linear = EnhancedLinear(512, 1000)
            except ImportError:
                self.linear = nn.Linear(512, 1000)
            self.config = type('Config', (), {'vocab_size': 1000})()
        
        def forward(self, input_ids, attention_mask=None):
            batch_size, seq_len = input_ids.shape
            x = torch.randn(batch_size, seq_len, 512, device=input_ids.device)
            logits = self.linear(x)
            return type('Output', (), {'logits': logits})()
    
    model = DummyModel()
    args = EnhancedGRPOArgs(
        process_noise=0.01,
        measurement_noise=0.1,
        kalman_memory_size=100,
        use_amp=False
    )
    
    trainer = EnhancedGRPOTrainer(model, args)
    
    batch_size, seq_len = 2, 64
    inputs = {
        'input_ids': torch.randint(0, 1000, (batch_size, seq_len)),
        'attention_mask': torch.ones(batch_size, seq_len)
    }
    
    loss = trainer.compute_enhanced_loss(model, inputs)
    
    print(f"‚úÖ Enhanced GRPO test passed")
    print(f"   Loss computed: {loss.item():.4f}")
    print(f"   Kalman filter initialized: {trainer.kf.mu:.4f}")
    
    return loss.item() > 0

def test_optimization_registry():
    """Test optimization registry functionality."""
    print("\nüß™ Testing Optimization Registry...")
    
    class TestModel(nn.Module):
        def __init__(self):
            super().__init__()
            try:
                from optimization_core import OptimizedLayerNorm
                self.norm = OptimizedLayerNorm(256)
            except ImportError:
                self.norm = nn.LayerNorm(256)
            try:
                from optimization_core.enhanced_mlp import EnhancedLinear
                self.linear = EnhancedLinear(256, 256)
            except ImportError:
                self.linear = nn.Linear(256, 256)
        
        def forward(self, x):
            return self.linear(self.norm(x))
    
    model = TestModel()
    config = get_optimization_config('deepseek_v3')
    
    optimized_model = apply_optimizations(model, config)
    
    print(f"‚úÖ Optimization registry test passed")
    print(f"   Applied optimizations from config")
    print(f"   Model optimized successfully")
    
    return True

def test_benchmark_framework():
    """Test benchmarking framework."""
    print("\nüß™ Testing Benchmark Framework...")
    
    class SimpleTestModel(nn.Module):
        def __init__(self):
            super().__init__()
            try:
                from optimization_core.enhanced_mlp import EnhancedLinear
                self.linear = EnhancedLinear(512, 512)
            except ImportError:
                self.linear = nn.Linear(512, 512)
        
        def forward(self, input_ids, attention_mask=None):
            batch_size, seq_len = input_ids.shape
            x = torch.randn(batch_size, seq_len, 512, device=input_ids.device)
            return self.linear(x)
    
    model = SimpleTestModel()
    input_gen = create_text_input_generator()
    
    config = BenchmarkConfig(
        batch_sizes=[1, 2],
        sequence_lengths=[64, 128],
        num_runs=3,
        warmup_runs=1
    )
    
    benchmark = PerformanceBenchmark(config)
    results = benchmark.benchmark_model(model, "test_model", input_gen)
    
    print(f"‚úÖ Benchmark framework test passed")
    print(f"   Benchmarked configurations: {len(results['batch_size_results'])}")
    print(f"   Results generated successfully")
    
    return len(results['batch_size_results']) > 0

def test_variant_optimizations():
    """Test optimizations on actual variant models."""
    print("\nüß™ Testing Variant Optimizations...")
    
    try:
        from variant.viral_clipper import create_viral_clipper_model
        
        config = {
            'hidden_size': 256,
            'num_layers': 2,
            'num_heads': 4,
            'max_sequence_length': 64,
            'dropout': 0.1
        }
        
        model = create_viral_clipper_model(config)
        
        try:
            from enhanced_model_optimizer import create_universal_optimizer
            optimizer = create_universal_optimizer({
                'enable_fp16': True,
                'use_advanced_normalization': True,
                'use_enhanced_mlp': True
            })
            model = optimizer.optimize_model(model, "viral_clipper")
        except ImportError:
            pass
        
        batch_size = 1
        visual_features = torch.randn(batch_size, 10, 2048)
        audio_features = torch.randn(batch_size, 10, 512)
        text_features = torch.randn(batch_size, 10, 768)
        engagement_features = torch.randn(batch_size, 10, 64)
        
        with torch.no_grad():
            outputs = model(visual_features, audio_features, text_features, engagement_features)
        
        print(f"‚úÖ Variant optimization test passed")
        print(f"   Viral clipper model working with optimizations")
        print(f"   Output shape: {outputs[0].shape if isinstance(outputs, tuple) else outputs.shape}")
        
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Variant optimization test skipped: {e}")
        return True

def run_all_optimization_tests():
    """Run all optimization tests."""
    print("üöÄ Starting TruthGPT Optimization Test Suite")
    print("=" * 60)
    
    tests = [
        test_optimized_layer_norm,
        test_cuda_optimizations,
        test_enhanced_grpo,
        test_optimization_registry,
        test_benchmark_framework,
        test_variant_optimizations
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"‚ùå Test {test.__name__} failed: {e}")
    
    print("\n" + "=" * 60)
    print(f"‚úÖ Tests passed: {passed}/{total}")
    
    if passed == total:
        print("üéâ All optimization tests passed!")
    else:
        print(f"‚ö†Ô∏è  {total - passed} tests failed")
    
    print("=" * 60)
    
    return passed == total

if __name__ == "__main__":
    success = run_all_optimization_tests()
    exit(0 if success else 1)
