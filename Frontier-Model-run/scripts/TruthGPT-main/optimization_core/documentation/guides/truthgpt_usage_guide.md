# Gu铆a de Uso de TruthGPT

Esta gu铆a te ense帽ar谩 c贸mo usar TruthGPT de manera efectiva, desde la instalaci贸n hasta el uso avanzado.

##  Tabla de Contenidos

1. [Instalaci贸n y Configuraci贸n](#instalaci贸n-y-configuraci贸n)
2. [Uso B谩sico](#uso-b谩sico)
3. [Configuraci贸n Avanzada](#configuraci贸n-avanzada)
4. [Optimizaciones](#optimizaciones)
5. [Troubleshooting](#troubleshooting)

##  Instalaci贸n y Configuraci贸n

### Requisitos Previos

```bash
# Verificar Python
python --version  # Debe ser 3.8+

# Verificar PyTorch
python -c "import torch; print(torch.__version__)"
```

### Instalaci贸n Paso a Paso

```bash
# 1. Clonar el repositorio
git clone <repository-url>
cd optimization_core

# 2. Crear entorno virtual
python -m venv truthgpt_env
source truthgpt_env/bin/activate  # Linux/Mac
# truthgpt_env\Scripts\activate   # Windows

# 3. Instalar dependencias
pip install -r requirements_modern.txt

# 4. Verificar instalaci贸n
python -c "from optimization_core import *; print('TruthGPT instalado correctamente')"
```

### Configuraci贸n Inicial

```python
# config/initial_config.yaml
model:
  name: "microsoft/DialoGPT-medium"
  max_length: 512
  temperature: 0.7

optimization:
  use_mixed_precision: true
  use_gradient_checkpointing: true
  use_flash_attention: true

training:
  batch_size: 4
  learning_rate: 5e-5
  num_epochs: 3
```

##  Uso B谩sico

### 1. Importaci贸n y Configuraci贸n

```python
from optimization_core import (
    ModernTruthGPTOptimizer, 
    TruthGPTConfig,
    create_ultra_optimization_core
)

# Configuraci贸n b谩sica
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True,
    use_gradient_checkpointing=True,
    use_flash_attention=True
)

# Inicializar optimizador
optimizer = ModernTruthGPTOptimizer(config)
```

### 2. Generaci贸n de Texto

```python
# Generaci贸n simple
text = optimizer.generate(
    input_text="Hola, 驴c贸mo est谩s?",
    max_length=100,
    temperature=0.7
)
print(text)

# Generaci贸n con par谩metros personalizados
text = optimizer.generate(
    input_text="Explica la inteligencia artificial",
    max_length=200,
    temperature=0.5,
    top_p=0.9,
    repetition_penalty=1.1
)
```

### 3. Entrenamiento B谩sico

```python
from optimization_core import create_training_pipeline

# Crear pipeline de entrenamiento
pipeline = create_training_pipeline(
    model_name="microsoft/DialoGPT-medium",
    experiment_name="mi_experimento",
    use_wandb=True
)

# Preparar datos
train_data = [...]  # Tu dataset
val_data = [...]    # Datos de validaci贸n

# Entrenar
results = pipeline.train(train_data, val_data)
```

## 锔 Configuraci贸n Avanzada

### Configuraci贸n de Optimizaciones

```python
from optimization_core import (
    UltraOptimizationCore,
    create_ultra_optimization_core
)

# Configuraci贸n ultra optimizada
ultra_config = {
    "use_quantization": True,
    "use_kernel_fusion": True,
    "use_memory_pooling": True,
    "use_adaptive_precision": True
}

# Crear optimizador ultra
ultra_optimizer = create_ultra_optimization_core(ultra_config)
```

### Configuraci贸n de GPU

```python
from optimization_core import GPUAccelerator, create_gpu_accelerator

# Configurar aceleraci贸n GPU
gpu_config = {
    "cuda_device": 0,
    "memory_fraction": 0.8,
    "use_tensor_cores": True,
    "use_mixed_precision": True
}

# Crear acelerador GPU
gpu_accelerator = create_gpu_accelerator(gpu_config)
```

### Configuraci贸n de Memoria

```python
from optimization_core import MemoryOptimizer, create_memory_optimizer

# Configurar optimizaci贸n de memoria
memory_config = {
    "use_gradient_checkpointing": True,
    "use_activation_checkpointing": True,
    "memory_efficient_attention": True,
    "use_offload": True
}

# Crear optimizador de memoria
memory_optimizer = create_memory_optimizer(memory_config)
```

##  Optimizaciones

### 1. Optimizaci贸n de Velocidad

```python
from optimization_core import (
    UltraFastOptimizer,
    create_ultra_fast_optimizer
)

# Configuraci贸n de velocidad ultra
speed_config = {
    "use_parallel_processing": True,
    "use_batch_optimization": True,
    "use_kernel_fusion": True,
    "use_quantization": True
}

# Crear optimizador ultra r谩pido
speed_optimizer = create_ultra_fast_optimizer(speed_config)
```

### 2. Optimizaci贸n de Memoria

```python
from optimization_core import (
    MemoryPoolingOptimizer,
    create_memory_pooling_optimizer
)

# Configuraci贸n de pooling de memoria
pooling_config = {
    "pool_size": 1024,
    "use_activation_cache": True,
    "use_gradient_cache": True,
    "compression_ratio": 0.5
}

# Crear optimizador de pooling
pooling_optimizer = create_memory_pooling_optimizer(pooling_config)
```

### 3. Optimizaci贸n de Compilaci贸n

```python
from optimization_core import (
    CompilerCore,
    create_compiler_core
)

# Configuraci贸n de compilaci贸n
compiler_config = {
    "target": "cuda",
    "optimization_level": "O3",
    "use_jit": True,
    "use_aot": True
}

# Crear compilador
compiler = create_compiler_core(compiler_config)
```

##  Casos de Uso Avanzados

### 1. Entrenamiento Distribuido

```python
from optimization_core import (
    DistributedOptimizer,
    create_distributed_optimizer
)

# Configuraci贸n distribuida
distributed_config = {
    "num_nodes": 4,
    "gpus_per_node": 8,
    "strategy": "ddp",
    "use_gradient_accumulation": True
}

# Crear optimizador distribuido
distributed_optimizer = create_distributed_optimizer(distributed_config)
```

### 2. Fine-tuning con LoRA

```python
from optimization_core import (
    LoRAConfig,
    create_lora_optimizer
)

# Configuraci贸n LoRA
lora_config = {
    "rank": 16,
    "alpha": 32,
    "target_modules": ["q_proj", "v_proj"],
    "use_peft": True
}

# Crear optimizador LoRA
lora_optimizer = create_lora_optimizer(lora_config)
```

### 3. Quantizaci贸n Avanzada

```python
from optimization_core import (
    AdvancedQuantizationOptimizer,
    create_quantization_optimizer
)

# Configuraci贸n de quantizaci贸n
quantization_config = {
    "quantization_type": "int8",
    "use_dynamic_quantization": True,
    "use_static_quantization": True,
    "calibration_dataset": calibration_data
}

# Crear optimizador de quantizaci贸n
quantization_optimizer = create_quantization_optimizer(quantization_config)
```

##  Monitoreo y Logging

### 1. Configuraci贸n de WandB

```python
import wandb
from optimization_core import create_training_pipeline

# Inicializar WandB
wandb.init(
    project="truthgpt-experiments",
    config={
        "model_name": "microsoft/DialoGPT-medium",
        "learning_rate": 5e-5,
        "batch_size": 4
    }
)

# Crear pipeline con logging
pipeline = create_training_pipeline(
    model_name="microsoft/DialoGPT-medium",
    use_wandb=True,
    experiment_name="mi_experimento"
)
```

### 2. Configuraci贸n de TensorBoard

```python
from optimization_core import create_training_pipeline

# Crear pipeline con TensorBoard
pipeline = create_training_pipeline(
    model_name="microsoft/DialoGPT-medium",
    use_tensorboard=True,
    log_dir="./logs"
)
```

##  Troubleshooting

### Problemas Comunes

#### 1. Error de Memoria GPU

```python
# Soluci贸n: Reducir batch size y usar gradient checkpointing
config = TruthGPTConfig(
    batch_size=1,  # Reducir batch size
    use_gradient_checkpointing=True,
    use_mixed_precision=True
)
```

#### 2. Error de CUDA

```python
# Verificar disponibilidad de CUDA
import torch
print(f"CUDA disponible: {torch.cuda.is_available()}")
print(f"Versi贸n CUDA: {torch.version.cuda}")

# Configurar dispositivo
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

#### 3. Error de Dependencias

```bash
# Reinstalar dependencias
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Logs y Debugging

```python
# Habilitar logging detallado
import logging
logging.basicConfig(level=logging.DEBUG)

# Configurar optimizador con debugging
config = TruthGPTConfig(
    debug_mode=True,
    verbose_logging=True,
    save_intermediate_results=True
)
```

##  Mejores Pr谩cticas

### 1. Configuraci贸n de Hardware

- **GPU**: Usar GPU con al menos 8GB VRAM
- **RAM**: M铆nimo 16GB RAM
- **CPU**: Procesador multi-core recomendado

### 2. Configuraci贸n de Software

- **Python**: Usar Python 3.8+
- **PyTorch**: Usar PyTorch 2.0+
- **CUDA**: Usar CUDA 11.8+

### 3. Optimizaci贸n de Rendimiento

- Usar mixed precision training
- Habilitar gradient checkpointing
- Usar flash attention
- Configurar batch size apropiado

##  Pr贸ximos Pasos

1. **Experimenta** con diferentes configuraciones
2. **Optimiza** seg煤n tu hardware
3. **Monitorea** el rendimiento
4. **Escala** seg煤n tus necesidades

---

*隆Ahora est谩s listo para usar TruthGPT de manera efectiva! Consulta los tutoriales y ejemplos para casos de uso m谩s espec铆ficos.*


