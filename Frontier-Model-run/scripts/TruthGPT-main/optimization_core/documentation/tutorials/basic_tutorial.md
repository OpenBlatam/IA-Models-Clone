# Tutorial B√°sico de TruthGPT

Este tutorial te guiar√° paso a paso para empezar con TruthGPT desde cero.

## üìã Tabla de Contenidos

1. [Preparaci√≥n del Entorno](#preparaci√≥n-del-entorno)
2. [Primera Configuraci√≥n](#primera-configuraci√≥n)
3. [Primer Uso](#primer-uso)
4. [Generaci√≥n de Texto](#generaci√≥n-de-texto)
5. [Entrenamiento B√°sico](#entrenamiento-b√°sico)
6. [Optimizaciones Iniciales](#optimizaciones-iniciales)

## üöÄ Preparaci√≥n del Entorno

### Paso 1: Verificar Requisitos

```bash
# Verificar Python
python --version
# Debe ser 3.8 o superior

# Verificar PyTorch
python -c "import torch; print(f'PyTorch: {torch.__version__}')"

# Verificar CUDA (opcional pero recomendado)
python -c "import torch; print(f'CUDA disponible: {torch.cuda.is_available()}')"
```

### Paso 2: Instalar Dependencias

```bash
# Crear entorno virtual
python -m venv truthgpt_env

# Activar entorno virtual
# En Windows:
truthgpt_env\Scripts\activate
# En Linux/Mac:
source truthgpt_env/bin/activate

# Instalar dependencias
pip install torch torchvision torchaudio
pip install transformers accelerate
pip install -r requirements_modern.txt
```

### Paso 3: Verificar Instalaci√≥n

```python
# test_installation.py
try:
    from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig
    print("‚úÖ TruthGPT instalado correctamente")
except ImportError as e:
    print(f"‚ùå Error de instalaci√≥n: {e}")
    exit(1)

# Verificar PyTorch
import torch
print(f"‚úÖ PyTorch: {torch.__version__}")
print(f"‚úÖ CUDA disponible: {torch.cuda.is_available()}")
```

## ‚öôÔ∏è Primera Configuraci√≥n

### Paso 1: Crear Configuraci√≥n B√°sica

```python
# config_basic.py
from optimization_core import TruthGPTConfig, ModernTruthGPTOptimizer

# Configuraci√≥n b√°sica
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",  # Modelo base
    use_mixed_precision=True,                # Usar precisi√≥n mixta
    use_gradient_checkpointing=True,        # Ahorrar memoria
    use_flash_attention=True                # Atenci√≥n optimizada
)

print("Configuraci√≥n creada:")
print(f"Modelo: {config.model_name}")
print(f"Precisi√≥n mixta: {config.use_mixed_precision}")
print(f"Gradient checkpointing: {config.use_gradient_checkpointing}")
print(f"Flash attention: {config.use_flash_attention}")
```

### Paso 2: Inicializar Optimizador

```python
# initialize_optimizer.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

# Crear configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True,
    use_gradient_checkpointing=True,
    use_flash_attention=True
)

# Inicializar optimizador
try:
    optimizer = ModernTruthGPTOptimizer(config)
    print("‚úÖ Optimizador TruthGPT inicializado correctamente")
except Exception as e:
    print(f"‚ùå Error al inicializar: {e}")
    exit(1)
```

### Paso 3: Verificar Funcionamiento

```python
# test_basic_functionality.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

# Configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True
)

# Inicializar
optimizer = ModernTruthGPTOptimizer(config)

# Probar generaci√≥n b√°sica
try:
    test_text = optimizer.generate(
        input_text="Hola",
        max_length=50,
        temperature=0.7
    )
    print(f"‚úÖ Generaci√≥n exitosa: {test_text}")
except Exception as e:
    print(f"‚ùå Error en generaci√≥n: {e}")
```

## üéØ Primer Uso

### Paso 1: Generaci√≥n Simple

```python
# first_generation.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

# Configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True
)

# Inicializar
optimizer = ModernTruthGPTOptimizer(config)

# Generar texto
input_text = "Hola, ¬øc√≥mo est√°s?"
generated_text = optimizer.generate(
    input_text=input_text,
    max_length=100,
    temperature=0.7
)

print(f"Input: {input_text}")
print(f"Generated: {generated_text}")
```

### Paso 2: Experimentar con Par√°metros

```python
# experiment_parameters.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

# Configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True
)

# Inicializar
optimizer = ModernTruthGPTOptimizer(config)

# Probar diferentes temperaturas
input_text = "Explica la inteligencia artificial"
temperatures = [0.3, 0.7, 1.0]

for temp in temperatures:
    generated = optimizer.generate(
        input_text=input_text,
        max_length=150,
        temperature=temp
    )
    print(f"Temperatura {temp}: {generated}\n")
```

### Paso 3: Generaci√≥n en Lote

```python
# batch_generation.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

# Configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True
)

# Inicializar
optimizer = ModernTruthGPTOptimizer(config)

# Lista de inputs
inputs = [
    "¬øQu√© es la inteligencia artificial?",
    "Explica el machine learning",
    "¬øC√≥mo funciona un transformer?",
    "Describe el deep learning"
]

# Generar para cada input
for i, input_text in enumerate(inputs):
    generated = optimizer.generate(
        input_text=input_text,
        max_length=200,
        temperature=0.7
    )
    print(f"Input {i+1}: {input_text}")
    print(f"Generated: {generated}\n")
```

## üìù Generaci√≥n de Texto

### Paso 1: Chat Simple

```python
# simple_chat.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

class SimpleChat:
    def __init__(self):
        # Configuraci√≥n
        config = TruthGPTConfig(
            model_name="microsoft/DialoGPT-medium",
            use_mixed_precision=True
        )
        
        # Inicializar optimizador
        self.optimizer = ModernTruthGPTOptimizer(config)
        self.conversation_history = []
    
    def chat(self, user_input):
        # Agregar input del usuario
        self.conversation_history.append(f"Usuario: {user_input}")
        
        # Crear contexto (√∫ltimos 3 mensajes)
        context = "\n".join(self.conversation_history[-3:])
        
        # Generar respuesta
        response = self.optimizer.generate(
            input_text=context,
            max_length=200,
            temperature=0.7
        )
        
        # Extraer respuesta del bot
        bot_response = response.split("Usuario:")[-1].strip()
        if "Bot:" in bot_response:
            bot_response = bot_response.split("Bot:")[-1].strip()
        
        # Agregar respuesta a la historia
        self.conversation_history.append(f"Bot: {bot_response}")
        
        return bot_response

# Usar el chat
chat = SimpleChat()

# Conversaci√≥n
print("=== Chat con TruthGPT ===")
print("Escribe 'salir' para terminar\n")

while True:
    user_input = input("T√∫: ")
    if user_input.lower() == 'salir':
        break
    
    response = chat.chat(user_input)
    print(f"Bot: {response}\n")
```

### Paso 2: Generador de C√≥digo

```python
# code_generator.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

class CodeGenerator:
    def __init__(self):
        # Configuraci√≥n
        config = TruthGPTConfig(
            model_name="microsoft/DialoGPT-medium",
            use_mixed_precision=True
        )
        
        # Inicializar optimizador
        self.optimizer = ModernTruthGPTOptimizer(config)
    
    def generate_function(self, description):
        prompt = f"""
        Escribe una funci√≥n Python que:
        {description}
        
        C√≥digo:
        """
        
        code = self.optimizer.generate(
            input_text=prompt,
            max_length=300,
            temperature=0.3  # Baja temperatura para c√≥digo
        )
        
        return code
    
    def explain_code(self, code):
        prompt = f"""
        Explica este c√≥digo Python:
        
        {code}
        
        Explicaci√≥n:
        """
        
        explanation = self.optimizer.generate(
            input_text=prompt,
            max_length=300,
            temperature=0.3
        )
        
        return explanation

# Usar generador de c√≥digo
generator = CodeGenerator()

# Generar funci√≥n
description = "calcule el factorial de un n√∫mero"
function_code = generator.generate_function(description)
print(f"Descripci√≥n: {description}")
print(f"C√≥digo generado:\n{function_code}")

# Explicar c√≥digo
code = "def factorial(n): return 1 if n <= 1 else n * factorial(n-1)"
explanation = generator.explain_code(code)
print(f"\nC√≥digo: {code}")
print(f"Explicaci√≥n: {explanation}")
```

### Paso 3: Generador de Contenido

```python
# content_generator.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

class ContentGenerator:
    def __init__(self):
        # Configuraci√≥n
        config = TruthGPTConfig(
            model_name="microsoft/DialoGPT-medium",
            use_mixed_precision=True
        )
        
        # Inicializar optimizador
        self.optimizer = ModernTruthGPTOptimizer(config)
    
    def generate_blog_post(self, topic):
        prompt = f"""
        Escribe un blog post sobre: {topic}
        
        T√≠tulo:
        """
        
        blog_post = self.optimizer.generate(
            input_text=prompt,
            max_length=500,
            temperature=0.7
        )
        
        return blog_post
    
    def generate_social_media_post(self, topic):
        prompt = f"""
        Escribe un post para redes sociales sobre: {topic}
        
        Post:
        """
        
        social_post = self.optimizer.generate(
            input_text=prompt,
            max_length=200,
            temperature=0.8
        )
        
        return social_post

# Usar generador de contenido
generator = ContentGenerator()

# Generar blog post
blog_post = generator.generate_blog_post("inteligencia artificial")
print("Blog post:")
print(blog_post)

# Generar post de redes sociales
social_post = generator.generate_social_media_post("machine learning")
print("\nPost de redes sociales:")
print(social_post)
```

## üéì Entrenamiento B√°sico

### Paso 1: Preparar Datos

```python
# prepare_training_data.py
import torch
from torch.utils.data import Dataset, DataLoader

class SimpleDataset(Dataset):
    def __init__(self, texts):
        self.texts = texts
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        return {"text": self.texts[idx]}

# Datos de ejemplo
train_texts = [
    "La inteligencia artificial es el futuro",
    "El machine learning es fascinante",
    "Los transformers son incre√≠bles",
    "La tecnolog√≠a avanza r√°pidamente",
    "Los algoritmos son inteligentes",
    "El deep learning es poderoso"
]

# Crear dataset
train_dataset = SimpleDataset(train_texts)
train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)

print(f"Dataset creado con {len(train_dataset)} ejemplos")
print(f"Batch size: {train_loader.batch_size}")
```

### Paso 2: Configurar Entrenamiento

```python
# setup_training.py
from optimization_core import create_training_pipeline, TruthGPTConfig

# Configuraci√≥n de entrenamiento
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True,
    use_gradient_checkpointing=True
)

# Crear pipeline de entrenamiento
pipeline = create_training_pipeline(
    model_name="microsoft/DialoGPT-medium",
    experiment_name="mi_primer_entrenamiento",
    use_wandb=False  # Desactivar WandB para simplicidad
)

print("Pipeline de entrenamiento creado")
print(f"Modelo: {config.model_name}")
print(f"Experimento: mi_primer_entrenamiento")
```

### Paso 3: Ejecutar Entrenamiento

```python
# run_training.py
from optimization_core import create_training_pipeline, TruthGPTConfig
import torch
from torch.utils.data import Dataset, DataLoader

class SimpleDataset(Dataset):
    def __init__(self, texts):
        self.texts = texts
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        return {"text": self.texts[idx]}

# Datos de entrenamiento
train_texts = [
    "La inteligencia artificial es el futuro",
    "El machine learning es fascinante",
    "Los transformers son incre√≠bles",
    "La tecnolog√≠a avanza r√°pidamente"
]

# Crear dataset y dataloader
train_dataset = SimpleDataset(train_texts)
train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)

# Crear pipeline
pipeline = create_training_pipeline(
    model_name="microsoft/DialoGPT-medium",
    experiment_name="mi_primer_entrenamiento",
    use_wandb=False
)

# Entrenar
print("Iniciando entrenamiento...")
try:
    results = pipeline.train(train_loader, None)
    print("‚úÖ Entrenamiento completado")
    print(f"Resultados: {results}")
except Exception as e:
    print(f"‚ùå Error en entrenamiento: {e}")
```

## ‚ö° Optimizaciones Iniciales

### Paso 1: Optimizaci√≥n de Memoria

```python
# memory_optimization.py
from optimization_core import (
    ModernTruthGPTOptimizer, 
    TruthGPTConfig,
    create_memory_optimizer
)

# Configuraci√≥n con optimizaciones de memoria
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True,
    use_gradient_checkpointing=True,
    use_flash_attention=True
)

# Inicializar optimizador
optimizer = ModernTruthGPTOptimizer(config)

# Configuraci√≥n de optimizaci√≥n de memoria
memory_config = {
    "use_gradient_checkpointing": True,
    "use_activation_checkpointing": True,
    "use_memory_efficient_attention": True
}

# Crear optimizador de memoria
memory_optimizer = create_memory_optimizer(memory_config)

# Aplicar optimizaciones
optimized_optimizer = memory_optimizer.optimize(optimizer)

# Probar generaci√≥n optimizada
generated_text = optimized_optimizer.generate(
    input_text="Hola, ¬øc√≥mo est√°s?",
    max_length=100,
    temperature=0.7
)

print(f"Texto generado con optimizaci√≥n de memoria: {generated_text}")
```

### Paso 2: Optimizaci√≥n de Velocidad

```python
# speed_optimization.py
from optimization_core import (
    ModernTruthGPTOptimizer, 
    TruthGPTConfig,
    create_ultra_fast_optimizer
)

# Configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True
)

# Inicializar optimizador
optimizer = ModernTruthGPTOptimizer(config)

# Configuraci√≥n de optimizaci√≥n de velocidad
speed_config = {
    "use_parallel_processing": True,
    "use_batch_optimization": True,
    "use_kernel_fusion": True
}

# Crear optimizador ultra r√°pido
speed_optimizer = create_ultra_fast_optimizer(speed_config)

# Aplicar optimizaciones
fast_optimizer = speed_optimizer.optimize(optimizer)

# Probar velocidad
import time

start_time = time.time()
generated_text = fast_optimizer.generate(
    input_text="Explica la inteligencia artificial",
    max_length=200,
    temperature=0.7
)
end_time = time.time()

print(f"Tiempo de generaci√≥n: {end_time - start_time:.2f} segundos")
print(f"Texto generado: {generated_text}")
```

### Paso 3: Optimizaci√≥n de GPU

```python
# gpu_optimization.py
from optimization_core import (
    ModernTruthGPTOptimizer, 
    TruthGPTConfig,
    create_gpu_accelerator
)

# Verificar CUDA
import torch
if not torch.cuda.is_available():
    print("CUDA no disponible, usando CPU")
    device = "cpu"
else:
    print(f"CUDA disponible: {torch.cuda.get_device_name(0)}")
    device = "cuda"

# Configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True
)

# Inicializar optimizador
optimizer = ModernTruthGPTOptimizer(config)

# Configuraci√≥n de aceleraci√≥n GPU
gpu_config = {
    "cuda_device": 0,
    "use_mixed_precision": True,
    "use_tensor_cores": True,
    "memory_fraction": 0.8
}

# Crear acelerador GPU
gpu_accelerator = create_gpu_accelerator(gpu_config)

# Aplicar aceleraci√≥n GPU
gpu_optimizer = gpu_accelerator.optimize(optimizer)

# Probar generaci√≥n con GPU
generated_text = gpu_optimizer.generate(
    input_text="Hola, ¬øc√≥mo est√°s?",
    max_length=100,
    temperature=0.7
)

print(f"Texto generado con GPU: {generated_text}")
```

## üéØ Pr√≥ximos Pasos

### Paso 1: Experimentar con Diferentes Modelos

```python
# experiment_models.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

# Lista de modelos para probar
models = [
    "microsoft/DialoGPT-small",
    "microsoft/DialoGPT-medium",
    "microsoft/DialoGPT-large"
]

input_text = "Explica la inteligencia artificial"

for model_name in models:
    print(f"\n=== Probando {model_name} ===")
    
    try:
        config = TruthGPTConfig(
            model_name=model_name,
            use_mixed_precision=True
        )
        
        optimizer = ModernTruthGPTOptimizer(config)
        
        generated = optimizer.generate(
            input_text=input_text,
            max_length=150,
            temperature=0.7
        )
        
        print(f"Generated: {generated}")
        
    except Exception as e:
        print(f"Error con {model_name}: {e}")
```

### Paso 2: Crear Tu Propio Caso de Uso

```python
# custom_use_case.py
from optimization_core import ModernTruthGPTOptimizer, TruthGPTConfig

class MyCustomUseCase:
    def __init__(self):
        # Configuraci√≥n
        config = TruthGPTConfig(
            model_name="microsoft/DialoGPT-medium",
            use_mixed_precision=True
        )
        
        # Inicializar optimizador
        self.optimizer = ModernTruthGPTOptimizer(config)
    
    def my_custom_function(self, input_text):
        # Implementar tu l√≥gica personalizada
        prompt = f"""
        Procesa este texto: {input_text}
        
        Resultado:
        """
        
        result = self.optimizer.generate(
            input_text=prompt,
            max_length=200,
            temperature=0.7
        )
        
        return result

# Usar tu caso de uso personalizado
my_use_case = MyCustomUseCase()

# Probar
input_text = "Hola, ¬øc√≥mo est√°s?"
result = my_use_case.my_custom_function(input_text)
print(f"Input: {input_text}")
print(f"Result: {result}")
```

### Paso 3: Explorar Optimizaciones Avanzadas

```python
# explore_advanced_optimizations.py
from optimization_core import (
    ModernTruthGPTOptimizer, 
    TruthGPTConfig,
    create_ultra_optimization_core,
    create_memory_optimizer,
    create_gpu_accelerator
)

# Configuraci√≥n
config = TruthGPTConfig(
    model_name="microsoft/DialoGPT-medium",
    use_mixed_precision=True
)

# Inicializar optimizador
optimizer = ModernTruthGPTOptimizer(config)

# Configuraci√≥n de optimizaciones avanzadas
ultra_config = {
    "use_quantization": True,
    "use_kernel_fusion": True,
    "use_memory_pooling": True,
    "use_adaptive_precision": True
}

# Crear optimizador ultra
ultra_optimizer = create_ultra_optimization_core(ultra_config)

# Aplicar optimizaciones
optimized_optimizer = ultra_optimizer.optimize(optimizer)

# Probar generaci√≥n optimizada
generated_text = optimized_optimizer.generate(
    input_text="Hola, ¬øc√≥mo est√°s?",
    max_length=100,
    temperature=0.7
)

print(f"Texto generado con optimizaciones avanzadas: {generated_text}")
```

## üéâ ¬°Felicidades!

Has completado el tutorial b√°sico de TruthGPT. Ahora tienes:

- ‚úÖ Entorno configurado
- ‚úÖ Primer uso funcionando
- ‚úÖ Generaci√≥n de texto
- ‚úÖ Entrenamiento b√°sico
- ‚úÖ Optimizaciones iniciales

### Pr√≥ximos Pasos Recomendados:

1. **Explora** los ejemplos avanzados
2. **Experimenta** con diferentes modelos
3. **Crea** tus propios casos de uso
4. **Optimiza** seg√∫n tu hardware
5. **Entrena** modelos personalizados

---

*¬°Ahora est√°s listo para usar TruthGPT de manera efectiva! Consulta la documentaci√≥n avanzada para casos de uso m√°s complejos.*


