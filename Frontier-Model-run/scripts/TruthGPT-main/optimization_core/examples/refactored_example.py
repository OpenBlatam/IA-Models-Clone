"""
Refactored Example - Comprehensive example of the refactored optimization system
Demonstrates the new modular architecture and improved functionality
"""

import torch
import torch.nn as nn
import logging
from pathlib import Path

# Import refactored modules
from ..core import (
    OptimizationLevel, OptimizationResult, ConfigManager, Environment,
    SystemMonitor, ModelValidator, CacheManager, PerformanceUtils
)
from ..optimizers import (
    ProductionOptimizer, create_production_optimizer, production_optimization_context
)

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_example_model() -> nn.Module:
    """Create an example neural network model."""
    return nn.Sequential(
        nn.Linear(100, 50),
        nn.ReLU(),
        nn.Dropout(0.2),
        nn.Linear(50, 25),
        nn.ReLU(),
        nn.Dropout(0.2),
        nn.Linear(25, 10),
        nn.Softmax(dim=-1)
    )

def create_large_model() -> nn.Module:
    """Create a larger model for performance testing."""
    return nn.Sequential(
        nn.Linear(1000, 500),
        nn.ReLU(),
        nn.Linear(500, 250),
        nn.ReLU(),
        nn.Linear(250, 100),
        nn.ReLU(),
        nn.Linear(100, 50),
        nn.ReLU(),
        nn.Linear(50, 10)
    )

def example_basic_optimization():
    """Example of basic production optimization with refactored system."""
    print("ğŸš€ Refactored Production Optimization Example")
    print("=" * 60)
    
    # Create model
    model = create_example_model()
    print(f"ğŸ“ Created model with {sum(p.numel() for p in model.parameters())} parameters")
    
    # Create optimizer with refactored configuration
    config = {
        'level': OptimizationLevel.AGGRESSIVE.value,
        'enable_quantization': True,
        'enable_pruning': True,
        'enable_mixed_precision': True,
        'max_memory_gb': 16.0,
        'enable_gpu_acceleration': torch.cuda.is_available()
    }
    
    with production_optimization_context(config) as optimizer:
        print("âœ… Refactored production optimizer created")
        
        # Optimize model
        result = optimizer.optimize(model)
        
        if result.success:
            print(f"âš¡ Model optimized successfully in {result.optimization_time:.2f}s")
            print(f"ğŸ“Š Memory usage: {result.memory_usage:.2f} MB")
            print(f"ğŸ“ˆ Parameter reduction: {result.parameter_reduction:.1f}%")
            print(f"ğŸ”§ Optimizations applied: {', '.join(result.optimizations_applied)}")
        else:
            print(f"âŒ Optimization failed: {result.error_message}")

def example_configuration_management():
    """Example of refactored configuration management."""
    print("\nğŸ”§ Refactored Configuration Management Example")
    print("=" * 60)
    
    # Create configuration manager
    config_manager = ConfigManager(Environment.PRODUCTION)
    
    # Load configuration from file
    config_file = Path("example_config.json")
    if config_file.exists():
        config_manager.load_from_file(str(config_file))
        print("ğŸ“ Configuration loaded from file")
    
    # Load from environment variables
    config_manager.load_from_environment("OPTIMIZATION_")
    print("ğŸŒ Configuration loaded from environment")
    
    # Get specific configurations
    opt_config = config_manager.get_optimization_config()
    print(f"âš™ï¸ Optimization level: {opt_config.level}")
    print(f"ğŸ’¾ Max memory: {opt_config.max_memory_gb} GB")
    print(f"ğŸ”§ Quantization enabled: {opt_config.enable_quantization}")
    
    # Validate configuration
    errors = config_manager.validate_config()
    if errors:
        print(f"âŒ Configuration errors: {errors}")
    else:
        print("âœ… Configuration is valid")
    
    # Export configuration
    config_manager.export_config("exported_config.json")
    print("ğŸ“¤ Configuration exported")

def example_monitoring_system():
    """Example of refactored monitoring system."""
    print("\nğŸ” Refactored Monitoring System Example")
    print("=" * 60)
    
    # Create monitoring configuration
    monitor_config = {
        'thresholds': {
            'cpu_usage': 70.0,
            'memory_usage': 80.0,
            'gpu_memory_usage': 85.0
        }
    }
    
    # Create system monitor
    monitor = SystemMonitor(monitor_config)
    
    # Start monitoring
    monitor.start_monitoring(interval=0.5)
    print("ğŸ” Monitoring started")
    
    # Record custom metrics
    monitor.metrics_collector.record_metric("optimization_requests", 1)
    monitor.metrics_collector.record_metric("model_size_mb", 15.5)
    monitor.metrics_collector.record_metric("optimization_duration", 2.3)
    
    # Simulate some work
    print("ğŸ”„ Simulating optimization work...")
    import time
    time.sleep(2)
    
    # Get health status
    health = monitor.get_health_status()
    print(f"ğŸ¥ System health: {health['status']} - {health['message']}")
    
    # Get performance summary
    summary = monitor.get_performance_summary(hours=1)
    print(f"ğŸ“Š Performance summary: {summary.get('snapshot_count', 0)} snapshots collected")
    
    # Export metrics
    monitor.export_metrics("refactored_metrics.json", hours=1)
    print("ğŸ“¤ Metrics exported")
    
    # Stop monitoring
    monitor.stop_monitoring()
    print("ğŸ›‘ Monitoring stopped")

def example_validation_system():
    """Example of refactored validation system."""
    print("\nâœ… Refactored Validation System Example")
    print("=" * 60)
    
    # Create model validator
    validator = ModelValidator()
    
    # Create test models
    model = create_example_model()
    optimized_model = create_example_model()  # In real scenario, this would be optimized
    
    # Validate original model
    print("ğŸ” Validating original model...")
    reports = validator.validate_model(model)
    for report in reports:
        status_emoji = "âœ…" if report.result.value == "passed" else "âŒ"
        print(f"{status_emoji} {report.test_name}: {report.message}")
    
    # Validate model compatibility
    print("\nğŸ” Validating model compatibility...")
    compatibility_report = validator.validate_model_compatibility(model, optimized_model)
    status_emoji = "âœ…" if compatibility_report.result.value == "passed" else "âŒ"
    print(f"{status_emoji} {compatibility_report.test_name}: {compatibility_report.message}")
    
    # Validate performance
    print("\nğŸ” Validating model performance...")
    test_inputs = [torch.randn(1, 100) for _ in range(5)]
    performance_report = validator.validate_model_performance(model, test_inputs)
    status_emoji = "âœ…" if performance_report.result.value == "passed" else "âŒ"
    print(f"{status_emoji} {performance_report.test_name}: {performance_report.message}")

def example_caching_system():
    """Example of refactored caching system."""
    print("\nğŸ’¾ Refactored Caching System Example")
    print("=" * 60)
    
    # Create cache manager
    cache_manager = CacheManager("./refactored_cache")
    
    # Get model cache
    model_cache = cache_manager.get_cache("models", max_size=50, max_memory_mb=512)
    
    # Create test model
    model = create_example_model()
    config = {'level': 'standard', 'enable_quantization': True}
    
    # Cache model
    cache_key = model_cache._generate_key(model, config)
    model_cache.put(cache_key, model, ttl_seconds=3600)
    print(f"ğŸ’¾ Model cached with key: {cache_key[:8]}...")
    
    # Retrieve from cache
    cached_model = model_cache.get(cache_key)
    if cached_model is not None:
        print("âœ… Model retrieved from cache")
    else:
        print("âŒ Model not found in cache")
    
    # Get cache statistics
    stats = model_cache.get_stats()
    print(f"ğŸ“Š Cache stats: {stats['size']} entries, {stats['hit_rate']:.2%} hit rate")
    
    # Cleanup
    cache_manager.cleanup_all()
    print("ğŸ§¹ Cache cleaned up")

def example_performance_utilities():
    """Example of refactored performance utilities."""
    print("\nâš¡ Refactored Performance Utilities Example")
    print("=" * 60)
    
    # Create performance utilities
    perf_utils = PerformanceUtils()
    memory_utils = MemoryUtils()
    gpu_utils = GPUUtils()
    
    # Create test model
    model = create_large_model()
    
    # Get system metrics
    metrics = perf_utils.get_system_metrics()
    print(f"ğŸ–¥ï¸ CPU usage: {metrics.cpu_usage:.1f}%")
    print(f"ğŸ’¾ Memory usage: {metrics.memory_usage:.1f}%")
    print(f"ğŸ® GPU memory usage: {metrics.gpu_memory_usage:.1f}%")
    
    # Get model memory usage
    memory_info = memory_utils.get_model_memory_usage(model)
    print(f"ğŸ“Š Model memory: {memory_info['total_mb']:.2f} MB")
    
    # Get parameter count
    param_info = memory_utils.get_parameter_count(model)
    print(f"ğŸ”¢ Total parameters: {param_info['total_parameters']:,}")
    print(f"ğŸ”¢ Trainable parameters: {param_info['trainable_parameters']:,}")
    
    # Get GPU information
    if torch.cuda.is_available():
        gpu_info = gpu_utils.get_device_properties()
        print(f"ğŸ® GPU: {gpu_info['name']}")
        print(f"ğŸ® Total memory: {gpu_info['total_memory_mb']:.0f} MB")
    else:
        print("ğŸ® No GPU available")
    
    # Benchmark model
    test_input = torch.randn(32, 1000)
    benchmark_results = perf_utils.benchmark_model_forward(model, test_input, iterations=10)
    print(f"âš¡ Model throughput: {benchmark_results['throughput']:.2f} ops/s")

def example_integrated_system():
    """Example of integrated refactored system."""
    print("\nğŸ­ Integrated Refactored System Example")
    print("=" * 60)
    
    # Create comprehensive configuration
    config_manager = ConfigManager(Environment.PRODUCTION)
    
    # Setup configuration
    optimization_config = {
        'level': OptimizationLevel.AGGRESSIVE.value,
        'enable_quantization': True,
        'enable_pruning': True,
        'enable_mixed_precision': True,
        'max_memory_gb': 16.0,
        'enable_gpu_acceleration': torch.cuda.is_available()
    }
    
    monitoring_config = {
        'enable_profiling': True,
        'profiling_interval': 50,
        'thresholds': {
            'cpu_usage': 80.0,
            'memory_usage': 85.0,
            'gpu_memory_usage': 90.0
        }
    }
    
    config_manager.update_section('optimization', optimization_config)
    config_manager.update_section('monitoring', monitoring_config)
    
    print("ğŸ”§ Configuration system ready")
    
    # Create models
    models = [create_example_model() for _ in range(3)]
    print(f"ğŸ“ Created {len(models)} models for optimization")
    
    # Setup monitoring
    monitor = SystemMonitor(monitoring_config)
    monitor.start_monitoring()
    print("ğŸ” Monitoring system started")
    
    # Setup optimization
    with production_optimization_context(optimization_config) as optimizer:
        print("ğŸš€ Optimization system ready")
        
        # Optimize models
        results = []
        for i, model in enumerate(models):
            print(f"âš¡ Optimizing model {i+1}/{len(models)}...")
            
            result = optimizer.optimize(model)
            results.append(result)
            
            if result.success:
                print(f"âœ… Model {i+1} optimized successfully")
            else:
                print(f"âŒ Model {i+1} optimization failed: {result.error_message}")
        
        # Get final metrics
        health = monitor.get_health_status()
        print(f"ğŸ¥ Final system health: {health['status']}")
        
        # Get optimization summary
        summary = optimizer.get_optimization_summary()
        print(f"ğŸ“Š Optimization summary: {summary['successful']}/{summary['total_optimizations']} successful")
        
        # Export all data
        monitor.export_metrics("integrated_refactored_metrics.json")
        config_manager.export_config("integrated_refactored_config.json")
        
        print("ğŸ“¤ All data exported successfully")
    
    # Stop monitoring
    monitor.stop_monitoring()
    print("ğŸ›‘ Monitoring stopped")

def main():
    """Main example function."""
    print("ğŸ­ Refactored Production-Grade Optimization System")
    print("=" * 70)
    print("Demonstrating the new modular architecture with improved functionality")
    print("=" * 70)
    
    try:
        # Run all examples
        example_basic_optimization()
        example_configuration_management()
        example_monitoring_system()
        example_validation_system()
        example_caching_system()
        example_performance_utilities()
        example_integrated_system()
        
        print("\nâœ… All refactored examples completed successfully!")
        print("ğŸ‰ Refactored system is ready for production deployment!")
        print("\nğŸ“ˆ Key Improvements:")
        print("  â€¢ Modular architecture with clear separation of concerns")
        print("  â€¢ Improved error handling and validation")
        print("  â€¢ Better performance monitoring and metrics")
        print("  â€¢ Enhanced configuration management")
        print("  â€¢ Robust caching system")
        print("  â€¢ Comprehensive testing and validation")
        
    except Exception as e:
        logger.error(f"Example failed: {e}")
        print(f"âŒ Example failed: {e}")

if __name__ == "__main__":
    main()



