# ğŸ—ï¸ Arquitectura Modular del Optimization Core

## ğŸ“ VisiÃ³n General

El cÃ³digo ha sido refactorizado siguiendo principios de **separaciÃ³n de responsabilidades** y **composiciÃ³n sobre herencia** para lograr una arquitectura mÃ¡s modular, testeable y mantenible.

## ğŸ¯ Principios de DiseÃ±o

1. **Single Responsibility**: Cada clase tiene una responsabilidad Ãºnica y bien definida
2. **Composition over Inheritance**: Uso de composiciÃ³n en lugar de herencia cuando es posible
3. **Dependency Injection**: Las dependencias se inyectan en lugar de crearse internamente
4. **Interface Segregation**: Interfaces pequeÃ±as y especÃ­ficas
5. **Open/Closed Principle**: Abierto para extensiÃ³n, cerrado para modificaciÃ³n

## ğŸ“¦ Estructura Modular

### 1. **Config Module** (`trainers/config.py`)

ConfiguraciÃ³n separada en dataclasses especializadas:

- `ModelConfig`: ConfiguraciÃ³n del modelo (LoRA, gradient checkpointing)
- `TrainingConfig`: HiperparÃ¡metros de entrenamiento
- `HardwareConfig`: ConfiguraciÃ³n de hardware (GPU, compilaciÃ³n)
- `CheckpointConfig`: ConfiguraciÃ³n de checkpoints
- `EMAConfig`: ConfiguraciÃ³n de Exponential Moving Average
- `TrainerConfig`: ConfiguraciÃ³n completa usando composiciÃ³n

**Beneficios**:
- Type safety con dataclasses
- ValidaciÃ³n de configuraciÃ³n
- SerializaciÃ³n/deserializaciÃ³n fÃ¡cil
- ConfiguraciÃ³n por capas (composiciÃ³n)

### 2. **Model Manager** (`trainers/model_manager.py`)

Maneja toda la lÃ³gica relacionada con modelos:

- Carga de tokenizer y modelo
- ConfiguraciÃ³n de LoRA
- DetecciÃ³n automÃ¡tica de mÃ³dulos LoRA por arquitectura
- AplicaciÃ³n de torch.compile
- InicializaciÃ³n de pesos
- Setup de multi-GPU (DataParallel/DDP)

**Beneficios**:
- LÃ³gica de modelo aislada
- FÃ¡cil de testear independientemente
- Reutilizable en otros contextos

### 3. **Optimizer Manager** (`trainers/optimizer_manager.py`)

Maneja optimizaciÃ³n y scheduling:

- CreaciÃ³n de optimizers via registry
- Setup de learning rate schedulers
- GestiÃ³n de GradScaler para mixed precision
- Operaciones de optimizaciÃ³n (step, zero_grad)

**Beneficios**:
- LÃ³gica de optimizaciÃ³n encapsulada
- FÃ¡cil intercambio de optimizers
- Testing independiente

### 4. **Data Manager** (`trainers/data_manager.py`)

Maneja todo lo relacionado con datos:

- CreaciÃ³n de DataLoaders
- Dynamic padding y bucketing
- ConfiguraciÃ³n de workers y prefetching
- Manejo de datasets

**Beneficios**:
- LÃ³gica de datos aislada
- FÃ¡cil cambiar estrategias de padding/bucketing
- Testing de pipelines de datos

### 5. **EMA Manager** (`trainers/ema_manager.py`)

Maneja Exponential Moving Average:

- InicializaciÃ³n de shadow parameters
- ActualizaciÃ³n de EMA
- AplicaciÃ³n/restauraciÃ³n de pesos EMA

**Beneficios**:
- LÃ³gica EMA encapsulada
- Reutilizable
- Testing independiente

### 6. **Evaluator** (`trainers/evaluator.py`)

Maneja evaluaciÃ³n del modelo:

- EvaluaciÃ³n en validation set
- CÃ¡lculo de mÃ©tricas (loss, perplexity)
- Soporte para EMA weights durante evaluaciÃ³n

**Beneficios**:
- LÃ³gica de evaluaciÃ³n separada
- FÃ¡cil agregar nuevas mÃ©tricas
- Testing independiente

### 7. **Checkpoint Manager** (`trainers/checkpoint_manager.py`)

Maneja checkpoints:

- Guardado de checkpoints (best, last, periodic)
- Carga de checkpoints para resume
- Pruning de checkpoints antiguos
- Manejo de estado completo

**Beneficios**:
- LÃ³gica de checkpointing encapsulada
- FÃ¡cil cambiar formato de checkpoint
- Testing independiente

## ğŸ”„ Flujo de Datos Modular

```
TrainerConfig (composiciÃ³n de configs especializadas)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GenericTrainer (Orquestador)      â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ ModelManager â”‚  â”‚ DataManager â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚OptimizerMgr  â”‚  â”‚ Evaluator   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  EMAManager  â”‚  â”‚CheckpointMgrâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ… Ventajas de la Arquitectura Modular

### 1. **Testabilidad**
- Cada mÃ³dulo puede testearse independientemente
- Mocking de dependencias mÃ¡s fÃ¡cil
- Tests unitarios mÃ¡s simples

### 2. **Mantenibilidad**
- CÃ³digo mÃ¡s fÃ¡cil de entender (menos lÃ­neas por archivo)
- Cambios localizados (no afectan otros mÃ³dulos)
- Debugging mÃ¡s simple

### 3. **Extensibilidad**
- Agregar nuevas funcionalidades sin modificar cÃ³digo existente
- Intercambiar implementaciones fÃ¡cilmente
- Plugins/extensions mÃ¡s simples

### 4. **ReutilizaciÃ³n**
- Los managers pueden usarse en otros contextos
- ComposiciÃ³n flexible de componentes
- Compartir lÃ³gica entre proyectos

### 5. **ColaboraciÃ³n**
- MÃºltiples desarrolladores pueden trabajar en paralelo
- Conflictos de merge reducidos
- CÃ³digo mÃ¡s organizado

## ğŸ“ Ejemplo de Uso

```python
from trainers.config import TrainerConfig
from trainers.model_manager import ModelManager
from trainers.optimizer_manager import OptimizerManager
from trainers.data_manager import DataManager
from trainers.ema_manager import EMAManager
from trainers.evaluator import Evaluator
from trainers.checkpoint_manager import CheckpointManager

# ConfiguraciÃ³n
config = TrainerConfig.from_dict(yaml_config)

# Model Manager
model_mgr = ModelManager(
    config.model,
    config.hardware,
    config.training,
    device,
)
tokenizer = model_mgr.load_tokenizer()
model = model_mgr.load_model()

# Optimizer Manager
optimizer_mgr = OptimizerManager(
    config.training,
    model,
    use_amp=True,
)
optimizer = optimizer_mgr.create_optimizer()
scheduler = optimizer_mgr.create_scheduler(num_steps)
scaler = optimizer_mgr.create_scaler()

# Data Manager
data_mgr = DataManager(
    config.training,
    config.hardware,
    tokenizer,
    text_field_max_len=512,
)
train_loader, val_loader = data_mgr.create_loaders(train_texts, val_texts)

# EMA Manager
ema_mgr = EMAManager(config.ema, model)

# Evaluator
evaluator = Evaluator(
    config.training,
    model,
    val_loader,
    device,
    use_amp=True,
    ema_manager=ema_mgr,
)

# Checkpoint Manager
checkpoint_mgr = CheckpointManager(
    config.checkpoint,
    config.output_dir,
    model,
    optimizer,
    scheduler,
    scaler,
    tokenizer,
)
```

## ğŸ”§ ExtensiÃ³n Futura

Esta arquitectura facilita:

1. **Nuevos tipos de optimizers**: Agregar al registry
2. **Nuevas mÃ©tricas**: Extender Evaluator
3. **Nuevas estrategias de checkpointing**: Intercambiar CheckpointManager
4. **Nuevos data loaders**: Intercambiar DataManager
5. **Nuevos schedulers**: Extender OptimizerManager

## ğŸ“Š ComparaciÃ³n

### Antes (MonolÃ­tico)
- `trainer.py`: 975 lÃ­neas
- Todas las responsabilidades mezcladas
- DifÃ­cil de testear
- DifÃ­cil de mantener

### DespuÃ©s (Modular)
- `trainer.py`: ~300 lÃ­neas (orquestador)
- 7 mÃ³dulos especializados (~100-200 lÃ­neas cada uno)
- FÃ¡cil de testear cada componente
- FÃ¡cil de mantener y extender

## ğŸ¯ PrÃ³ximos Pasos

1. Actualizar `GenericTrainer` para usar los managers
2. Crear tests unitarios para cada manager
3. Documentar APIs de cada manager
4. Agregar mÃ¡s managers si es necesario (e.g., MetricManager, ProfilerManager)

---

**Fecha**: 2024  
**VersiÃ³n**: 2.1.0 (Modular Architecture)
