# ğŸ§ª TruthGPT Optimization Core Test Suite

[![Test Status](https://img.shields.io/badge/tests-passing-brightgreen)]()
[![Coverage](https://img.shields.io/badge/coverage-95%25-brightgreen)]()
[![Python](https://img.shields.io/badge/python-3.8%2B-blue)]()
[![Platform](https://img.shields.io/badge/platform-multi--OS-lightgrey)]()

> **World-class, production-ready test framework** for TruthGPT Optimization Core with comprehensive testing, advanced analytics, beautiful HTML reports, and seamless CI/CD integration.

## ğŸš€ Quick Start

```bash
# Run all tests
python tests/run_all_tests.py

# Run specific categories
python tests/run_all_tests.py --unit
python tests/run_all_tests.py --integration  
python tests/run_all_tests.py --performance

# With options
python tests/run_all_tests.py --verbose --save-results

# Generate HTML report
python tests/demo_framework.py
```

## ğŸ“Š Features

### âœ¨ Core Features

- **26 Comprehensive Test Files** covering all optimization features
- **Advanced Test Utilities** with retry, timeout, and performance checks
- **Parallel Execution** for faster test runs (up to 4x speedup)
- **Beautiful HTML Reports** with visualizations and metrics
- **Trend Analysis** to track improvements over time
- **Full CI/CD Integration** for GitHub Actions, GitLab CI, Jenkins, and more
- **Production-Ready** with comprehensive documentation

### ğŸ¯ Test Categories

#### Unit Tests (22 files)
```python
âœ… Attention optimizations (KV cache, efficient attention)
âœ… Optimizer core (Adam, SGD, AdaGrad, etc.)
âœ… Transformer components (blocks, normalization)
âœ… Quantization (INT8, FP16, dynamic)
âœ… Memory optimization (pooling, management)
âœ… CUDA optimizations (GPU kernels)
âœ… Advanced techniques (meta-learning, federated)
âœ… AI-driven optimization
âœ… Neural Architecture Search (NAS)
âœ… AutoML pipelines
âœ… Hyperparameter optimization
âœ… Quantum-inspired optimization
```

#### Integration Tests (2 files)
```python
âœ… End-to-end workflows
âœ… Advanced multi-stage optimization
```

#### Performance Tests (2 files)
```python
âœ… Benchmarks and metrics
âœ… Scalability testing
```

## ğŸ¨ Advanced Features

### 1. Test Coverage Tracking

```python
from tests.fixtures.test_utils import TestCoverageTracker

tracker = TestCoverageTracker()
tracker.record_test("test_attention", True, duration=0.5, coverage=85.0)

summary = tracker.calculate_total_coverage()
print(f"Coverage: {summary['total_coverage']:.1f}%")
print(f"Success Rate: {summary['success_rate']:.1f}%")
```

### 2. Advanced Decorators

```python
from tests.fixtures.test_utils import AdvancedTestDecorators

@AdvancedTestDecorators.retry(max_attempts=3)
def test_flaky_connection():
    """Auto-retry on failure"""
    pass

@AdvancedTestDecorators.timeout(seconds=60)
def test_with_timeout():
    """Prevent hanging tests"""
    pass

@AdvancedTestDecorators.performance_test(baseline_time=1.0)
def test_performance():
    """Detect performance regressions"""
    pass
```

### 3. Parallel Execution

```python
from tests.fixtures.test_utils import ParallelTestRunner

runner = ParallelTestRunner(max_workers=4)
results = runner.run_tests_parallel([test1, test2, test3, test4])
```

### 4. Visual Results

```python
from tests.fixtures.test_utils import TestVisualizer

summary = TestVisualizer.create_results_summary(results)
graph = TestVisualizer.create_performance_graph(profiles)
print(summary, graph)
```

### 5. HTML Reports

```python
from tests.report_generator import HTMLReportGenerator
import json

with open('test_results.json') as f:
    results = json.load(f)

generator = HTMLReportGenerator()
generator.generate_report(results, 'test_report.html')
```

## ğŸ“ˆ Reporting

### Console Output
```
ğŸ§ª Running TruthGPT Optimization Core Tests
============================================================

ğŸ“ Running tests from: test_optimizer_core.py
   âœ… PASSED - 15 tests, 0 failures, 0 errors

ğŸ“Š Test Summary:
  Total Tests: 250
  Failures: 0
  Errors: 0
  Success Rate: 100.0%
  Total Time: 15.23s

ğŸ‰ Excellent! All tests are passing with high success rate.
```

### HTML Reports
Beautiful, professional HTML reports with:
- ğŸ“Š Visual statistics dashboard
- ğŸ“ˆ Progress bars and success rates
- ğŸ¨ Professional design with gradients
- ğŸ“± Responsive layout
- ğŸ“ Detailed test breakdown

## ğŸ”§ Configuration

### Environment Variables

```bash
# Customize test execution
export TRUTHGPT_TEST_PARALLEL=true
export TRUTHGPT_TEST_WORKERS=4
export TRUTHGPT_TEST_TIMEOUT=300
export TRUTHGPT_TEST_PATTERN=unit
```

### Custom Test Runner

```python
from tests.run_all_tests import TruthGPTTestRunner

runner = TruthGPTTestRunner(
    verbose=True,
    parallel=True,
    coverage=True,
    performance=True
)

results = runner.run_all_tests()
```

## ğŸš€ CI/CD Integration

### GitHub Actions (Included)

The framework includes a complete GitHub Actions workflow:

```yaml
# .github/workflows/tests.yml
- Automatic testing on push/PR
- Multi-platform (Linux, Windows, macOS)
- Multiple Python versions (3.8-3.11)
- Artifact storage
- PR comments with results
- Codecov integration
```

### Supported Platforms

- âœ… GitHub Actions
- âœ… GitLab CI
- âœ… Jenkins
- âœ… CircleCI
- âœ… Azure DevOps
- âœ… Bitbucket Pipelines

See `CICD_GUIDE.md` for detailed integration instructions.

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| `RUN_TESTS.md` | How to run tests |
| `TEST_FIXES_SUMMARY.md` | What was fixed |
| `ADVANCED_FEATURES.md` | Advanced features guide |
| `CICD_GUIDE.md` | CI/CD integration guide |
| `FRAMEWORK_SUMMARY.md` | Complete framework summary |

## ğŸ¯ Usage Examples

### Basic Usage

```bash
# Run all tests
python tests/run_all_tests.py

# Run with verbose output
python tests/run_all_tests.py --verbose

# Save results to JSON
python tests/run_all_tests.py --save-results

# Run specific categories
python tests/run_all_tests.py --unit
python tests/run_all_tests.py --integration
python tests/run_all_tests.py --performance
```

### Advanced Usage

```python
# Import all utilities
from tests.fixtures.test_utils import (
    TestCoverageTracker,
    AdvancedTestDecorators,
    ParallelTestRunner,
    TestVisualizer
)

# Track coverage
tracker = TestCoverageTracker()
tracker.record_test("test_name", True, 0.5, coverage=90.0)

# Run in parallel
runner = ParallelTestRunner(max_workers=4)
results = runner.run_tests_parallel([test1, test2, test3])

# Visualize results
visualizer = TestVisualizer()
summary = visualizer.create_results_summary(results)
```

### Generate Reports

```bash
# Generate HTML report
python tests/demo_framework.py

# Or manually
python -c "
import json
from tests.report_generator import HTMLReportGenerator

with open('test_results.json') as f:
    results = json.load(f)

generator = HTMLReportGenerator()
generator.generate_report(results, 'test_report.html')
"
```

## ğŸ¨ Visual Examples

### Test Results Dashboard

```
TruthGPT Optimization Core Test Results
================================================================================

Total Tests: 250          Passed: 242          Failed: 8          Success: 96.8%

Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ (96.8%)

Performance Metrics:
  Execution Time: 125.50s
  Memory Used: 1024.00MB

Individual Results:
  âœ… test_attention_optimizations.py: 25 tests, 0 failures
  âœ… test_optimizer_core.py: 30 tests, 0 failures
  âœ… test_transformer_components.py: 20 tests, 0 failures
  âŒ test_cuda_optimizations.py: 15 tests, 2 failures
```

### Performance Graph

```
Performance Profile (Execution Time in seconds)

test_attention               0.500s â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
test_optimizer               1.200s â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
test_transformer             2.800s â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

## ğŸ“Š Metrics Tracked

### Test Metrics
- Total tests
- Passed/Failed/Errors
- Success rate
- Execution time
- Coverage percentage

### Performance Metrics
- Total execution time
- Average execution time
- Memory usage
- CPU usage
- Performance trends

### Coverage Metrics
- Test coverage percentage
- Coverage by category
- Coverage trends over time

## ğŸ¯ Best Practices

### 1. Test Organization
```python
# Use descriptive names
def test_attention_with_kv_cache():
    pass

def test_optimizer_adam_convergence():
    pass
```

### 2. Use Fixtures
```python
from tests.fixtures.test_data import TestDataFactory
from tests.fixtures.mock_components import MockModel

factory = TestDataFactory()
data = factory.create_attention_data()
model = MockModel()
```

### 3. Add Decorators
```python
from tests.fixtures.test_utils import AdvancedTestDecorators

@AdvancedTestDecorators.retry(max_attempts=3)
def test_network_operation():
    pass
```

### 4. Track Coverage
```python
from tests.fixtures.test_utils import TestCoverageTracker

tracker = TestCoverageTracker()
tracker.record_test("test_name", True, 0.5, coverage=90.0)
```

## ğŸ” Debugging

### Enable Verbose Output
```bash
python tests/run_all_tests.py --verbose
```

### Run Specific Tests
```bash
python tests/run_all_tests.py --pattern attention
```

### Check Memory Usage
```python
from tests.fixtures.test_utils import MemoryTracker

tracker = MemoryTracker()
tracker.take_snapshot("start")
# ... operations ...
tracker.take_snapshot("end")
summary = tracker.get_memory_summary()
```

## ğŸš€ Getting Started

### Prerequisites

```bash
# Install Python 3.8+
python --version

# Install dependencies
pip install torch numpy psutil pytest pytest-cov pytest-xdist
```

### Quick Start

```bash
# 1. Navigate to optimization_core
cd agents/backend/onyx/server/features/Frontier-Model-run/scripts/TruthGPT-main/optimization_core

# 2. Run tests
python tests/run_all_tests.py

# 3. View results
cat test_results.json

# 4. Generate HTML report
python tests/demo_framework.py

# 5. View report
# Open test_report.html in browser
```

## ğŸ“ˆ Monitoring & Trends

### Track Performance Over Time

```python
from tests.report_generator import TrendAnalyzer

analyzer = TrendAnalyzer()
analyzer.save_result(results)
analyzer.print_trends()
```

### Monitor Test Health

- âœ… Success rates
- âœ… Execution times
- âœ… Memory usage
- âœ… Coverage trends
- âœ… Performance regressions

## ğŸ‰ Features Summary

### What You Get

- âœ… **26 comprehensive test files**
- âœ… **Advanced test utilities** (4 new classes)
- âœ… **Beautiful HTML reports**
- âœ… **Trend analysis**
- âœ… **Full CI/CD integration**
- âœ… **Production-ready** documentation
- âœ… **Parallel execution** for speed
- âœ… **Visual dashboards** for insights

### Key Benefits

1. **Reliability**: Auto-retry, timeouts, performance checks
2. **Speed**: Parallel execution (up to 4x faster)
3. **Insight**: Visual summaries and coverage tracking
4. **Automation**: Full CI/CD pipeline integration
5. **Quality**: Professional, maintainable test suite

## ğŸ¤ Contributing

When adding new tests:

1. Create test file in appropriate category (unit/integration/performance)
2. Use fixtures from `tests/fixtures/` for consistency
3. Add proper docstrings and assertions
4. Update documentation if adding new test categories

## ğŸ“ License

Part of the TruthGPT Optimization Core test suite.

## ğŸ”— Quick Links

- [How to Run Tests](RUN_TESTS.md)
- [Advanced Features](ADVANCED_FEATURES.md)
- [CI/CD Guide](CICD_GUIDE.md)
- [Framework Summary](FRAMEWORK_SUMMARY.md)

---

**Made with â¤ï¸ for the TruthGPT Optimization Core**

*Professional. Comprehensive. Production-Ready.*