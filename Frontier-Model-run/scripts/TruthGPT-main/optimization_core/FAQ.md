# â“ FAQ - Preguntas Frecuentes

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### Â¿QuÃ© versiÃ³n de Python necesito?
Python 3.8 o superior. Verifica con:
```bash
python --version
# o
make health
```

### Â¿CÃ³mo instalo dependencias opcionales?
```bash
# Para W&B logging
pip install wandb

# Para TensorBoard
pip install tensorboard

# Para monitoring avanzado
pip install psutil

# Para aceleraciÃ³n
pip install accelerate peft
```

### Â¿CÃ³mo verifico que todo estÃ¡ instalado correctamente?
```bash
make health
# o
python utils/health_check.py
```

## ğŸš€ Entrenamiento

### Â¿CÃ³mo empiezo rÃ¡pido?
```bash
# OpciÃ³n 1: Preset LoRA (mÃ¡s rÃ¡pido)
make train-lora

# OpciÃ³n 2: ConfiguraciÃ³n por defecto
make train
```

### Â¿CÃ³mo cambio el modelo sin editar cÃ³digo?
Edita `configs/llm_default.yaml`:
```yaml
model:
  name_or_path: gpt2  # Cambia aquÃ­
```

O usa el inicializador:
```bash
python init_project.py mi_proyecto --model microsoft/DialoGPT-small
```

### Â¿CÃ³mo activo LoRA para ahorrar memoria?
```yaml
model:
  lora:
    enabled: true
    r: 16
    alpha: 32
```

### Â¿Mi GPU se queda sin memoria, quÃ© hago?
1. Reduce `train_batch_size` (ej: de 32 a 16)
2. Reduce `max_seq_len` (ej: de 512 a 256)
3. Activa `gradient_checkpointing: true`
4. Usa `mixed_precision: bf16`
5. Aumenta `grad_accum_steps`

### Â¿CÃ³mo entreno mÃ¡s rÃ¡pido?
Activa optimizaciones en YAML:
```yaml
training:
  allow_tf32: true
  torch_compile: true
  fused_adamw: true
data:
  bucket_by_length: true
  num_workers: 8
  prefetch_factor: 4
```

O usa el preset de performance:
```bash
make train-perf
```

## ğŸ“Š Logging y Monitoreo

### Â¿CÃ³mo activo W&B?
1. Instala: `pip install wandb`
2. Login: `wandb login`
3. En YAML:
```yaml
training:
  callbacks: [print, wandb]
logging:
  project: mi-proyecto
  run_name: experimento-1
```

### Â¿CÃ³mo veo mÃ©tricas en tiempo real?
```bash
# Monitorear directorio de run
make monitor

# O monitorear archivo de log
python utils/monitor_training.py logs/training.log --file
```

### Â¿CÃ³mo comparo diferentes runs?
```bash
make compare
# o
python utils/compare_runs.py --runs-dir runs
```

## ğŸ’¾ Checkpoints y Resume

### Â¿CÃ³mo activo auto-resume?
```yaml
resume:
  enabled: true
  checkpoint_dir: null  # Usa output_dir si null
```

### Â¿DÃ³nde se guardan los checkpoints?
En `output_dir` configurado en YAML (default: `runs/<run_name>/`).

### Â¿CÃ³mo exporto configuraciÃ³n desde un checkpoint?
```bash
python utils/export_config.py runs/mi_run/best.pt --output configs/reproduce.yaml
```

## ğŸ§¹ Limpieza y Mantenimiento

### Â¿CÃ³mo limpio runs antiguos?
```bash
# Ver quÃ© se eliminarÃ­a (dry run)
make cleanup-dry

# Ejecutar limpieza
make cleanup

# Personalizado
python utils/cleanup_runs.py --days 30 --old-runs --execute
```

### Â¿CÃ³mo limpio checkpoints antiguos pero mantengo los Ãºltimos N?
```bash
python utils/cleanup_runs.py --keep-checkpoints 3 --checkpoints --execute
```

## ğŸ› Troubleshooting

### Error: "CUDA out of memory"
- Reduce `train_batch_size`
- Reduce `max_seq_len`
- Activa `gradient_checkpointing: true`
- Usa `mixed_precision: bf16`
- Aumenta `grad_accum_steps`

### Error: "ModuleNotFoundError"
```bash
# Instala dependencias bÃ¡sicas
pip install -r requirements_advanced.txt

# Verifica con health check
make health
```

### El entrenamiento es muy lento
- Activa `allow_tf32: true` (GPUs Ampere+)
- Activa `torch_compile: true`
- Aumenta `num_workers` y `prefetch_factor`
- Activa `bucket_by_length: true`

### W&B/TensorBoard no funciona
1. Verifica instalaciÃ³n: `pip install wandb` o `pip install tensorboard`
2. Verifica que estÃ¡ en `training.callbacks` en YAML
3. Verifica `logging.project` y `logging.run_name`

### NaN en loss
El sistema detecta NaN automÃ¡ticamente y omite el step. Si persiste:
- Reduce `learning_rate`
- Verifica datos (pueden tener valores invÃ¡lidos)
- Activa `detect_anomaly: true` en YAML para debug

## ğŸ”„ ConfiguraciÃ³n Avanzada

### Â¿CÃ³mo cambio el optimizer?
```yaml
optimizer:
  type: adamw  # adamw|lion|adafactor
  fused: true
```

### Â¿CÃ³mo cambio el backend de atenciÃ³n?
```yaml
model:
  attention:
    backend: sdpa  # sdpa|flash|triton
```

### Â¿CÃ³mo uso datasets en streaming?
```yaml
data:
  source: hf
  streaming: true
```

### Â¿CÃ³mo activo EMA para evaluaciÃ³n?
```yaml
ema:
  enabled: true
  decay: 0.999
```

## ğŸ“š Recursos

### Â¿DÃ³nde encuentro ejemplos?
- `examples/benchmark_tokens_per_sec.py` - Benchmark
- `examples/train_with_datasets.py` - Datasets
- `examples/complete_workflow.py` - Workflow completo

### Â¿DÃ³nde estÃ¡ la documentaciÃ³n completa?
- `README.md` - DocumentaciÃ³n principal
- `QUICK_REFERENCE.md` - Referencia rÃ¡pida
- `ARCHITECTURE.md` - Arquitectura del sistema
- `INDEX.md` - Ãndice de documentaciÃ³n

### Â¿CÃ³mo contribuyo?
Ver `CONTRIBUTING.md` para guÃ­a completa.

## ğŸ’¡ Tips y Mejores PrÃ¡cticas

1. **Siempre valida tu config antes de entrenar:**
   ```bash
   make validate
   ```

2. **Usa presets para empezar rÃ¡pido:**
   ```bash
   make train-lora  # Para pruebas rÃ¡pidas
   make train-perf  # Para mÃ¡ximo performance
   ```

3. **Monitorea tu entrenamiento:**
   ```bash
   # En otra terminal
   make monitor
   ```

4. **Usa health check antes de entrenar:**
   ```bash
   make health
   ```

5. **Limpia runs antiguos regularmente:**
   ```bash
   make cleanup-dry  # Ver quÃ© se eliminarÃ­a
   make cleanup      # Ejecutar limpieza
   ```

6. **Exporta configs para reproducibilidad:**
   ```bash
   python utils/export_config.py runs/mi_run --output configs/reproduce.yaml
   ```

---

**Â¿No encuentras tu respuesta?** Abre un issue en el repositorio con:
- Tu pregunta
- ConfiguraciÃ³n relevante
- Logs de error (si aplica)


