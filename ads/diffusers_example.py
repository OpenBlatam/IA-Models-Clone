from typing_extensions import Literal, TypedDict
from typing import Any, List, Dict, Optional, Union, Tuple
# Constants
MAX_RETRIES = 100

# Constants
TIMEOUT_SECONDS = 60

import torch
from diffusers import DiffusionPipeline, DDPMScheduler, UNet2DConditionModel
from diffusers.optimization import get_scheduler
import torch.nn.functional as F
from official_docs_reference import OfficialDocsReference
from diffusers import DiffusionPipeline
import torch
from typing import Any, List, Dict, Optional
import logging
import asyncio
#!/usr/bin/env python3
"""
Diffusers Example - Using Official Documentation References
==========================================================

Ejemplo prÃ¡ctico de Diffusers usando las referencias de documentaciÃ³n oficial.
"""


def load_pipeline():
    """Cargar pipeline siguiendo las mejores prÃ¡cticas."""
    ref = OfficialDocsReference()
    
    # Obtener referencia de pipeline usage
    pipeline_ref = ref.get_api_reference("diffusers", "pipeline_usage")
    print(f"Usando: {pipeline_ref.name}")
    print(f"DescripciÃ³n: {pipeline_ref.description}")
    
    print("Mejores prÃ¡cticas de pipeline:")
    for practice in pipeline_ref.best_practices:
        print(f"  âœ“ {practice}")
    
    print("\nğŸ“¥ Cargando pipeline de Stable Diffusion...")
    
    # Cargar pipeline con optimizaciones de memoria
    pipeline = DiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,  # Mejor prÃ¡ctica para memoria
        use_safetensors=True
    )
    
    # Mover a GPU si estÃ¡ disponible
    if torch.cuda.is_available():
        pipeline = pipeline.to("cuda")
        print("âœ… Pipeline movido a GPU")
    else:
        print("âš ï¸  GPU no disponible, usando CPU")
    
    return pipeline

def optimize_memory(pipeline) -> Any:
    """Optimizar memoria siguiendo las mejores prÃ¡cticas."""
    ref = OfficialDocsReference()
    
    # Obtener referencia de memory optimization
    memory_ref = ref.get_api_reference("diffusers", "memory_optimization")
    print(f"\nğŸ’¾ Usando: {memory_ref.name}")
    print(f"DescripciÃ³n: {memory_ref.description}")
    
    print("Aplicando optimizaciones de memoria:")
    
    # Habilitar attention slicing
    pipeline.enable_attention_slicing()
    print("  âœ“ Attention slicing habilitado")
    
    # Habilitar VAE slicing
    pipeline.enable_vae_slicing()
    print("  âœ“ VAE slicing habilitado")
    
    # Habilitar xformers si estÃ¡ disponible
    try:
        pipeline.enable_xformers_memory_efficient_attention()
        print("  âœ“ xformers memory efficient attention habilitado")
    except:
        print("  âš ï¸  xformers no disponible")
    
    print("âœ… Optimizaciones de memoria aplicadas!")

def generate_images(pipeline, prompts) -> Any:
    """Generar imÃ¡genes siguiendo las mejores prÃ¡cticas."""
    print(f"\nğŸ¨ Generando {len(prompts)} imÃ¡genes...")
    
    # Generar imÃ¡genes con configuraciÃ³n optimizada
    images = pipeline(
        prompts,
        num_inference_steps=50,  # Balance entre calidad y velocidad
        guidance_scale=7.5,      # Control de adherencia al prompt
        height=512,
        width=512
    ).images
    
    print(f"âœ… {len(images)} imÃ¡genes generadas exitosamente!")
    
    # Guardar imÃ¡genes
    for i, (prompt, image) in enumerate(zip(prompts, images)):
        filename = f"generated_image_{i+1}.png"
        image.save(filename)
        print(f"  ğŸ’¾ Guardada: {filename} (Prompt: '{prompt}')")
    
    return images

def custom_training_example():
    """Ejemplo de entrenamiento personalizado siguiendo las mejores prÃ¡cticas."""
    ref = OfficialDocsReference()
    
    # Obtener referencia de custom training
    training_ref = ref.get_api_reference("diffusers", "custom_training")
    print(f"\nğŸ‹ï¸ Usando: {training_ref.name}")
    print(f"DescripciÃ³n: {training_ref.description}")
    
    print("Mejores prÃ¡cticas de entrenamiento:")
    for practice in training_ref.best_practices:
        print(f"  âœ“ {practice}")
    
    print("\nğŸ“š Ejemplo de configuraciÃ³n de entrenamiento:")
    
    # ConfiguraciÃ³n de ejemplo (sin ejecutar realmente)
    config = {
        "model_name": "runwayml/stable-diffusion-v1-5",
        "learning_rate": 1e-4,
        "num_epochs": 100,
        "batch_size": 1,
        "gradient_accumulation_steps": 4,
        "mixed_precision": True,
        "gradient_checkpointing": True
    }
    
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    print("âœ… ConfiguraciÃ³n de entrenamiento preparada!")

def validate_code():
    """Validar cÃ³digo usando el sistema de referencias."""
    ref = OfficialDocsReference()
    
    # CÃ³digo de ejemplo
    code = """

pipeline = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)

pipeline.enable_attention_slicing()
pipeline.enable_vae_slicing()

image = pipeline("A beautiful sunset").images[0]
"""
    
    print("\nğŸ” Validando cÃ³digo de Diffusers...")
    validation = ref.validate_code_snippet(code, "diffusers")
    
    if validation["valid"]:
        print("âœ… CÃ³digo vÃ¡lido segÃºn las mejores prÃ¡cticas")
    else:
        print("âŒ CÃ³digo tiene problemas:")
        for issue in validation["issues"]:
            print(f"   - {issue}")
    
    if validation["recommendations"]:
        print("ğŸ’¡ Recomendaciones:")
        for rec in validation["recommendations"]:
            print(f"   - {rec}")

def check_performance_recommendations():
    """Verificar recomendaciones de rendimiento."""
    ref = OfficialDocsReference()
    
    print("\nâš¡ Recomendaciones de rendimiento para Diffusers:")
    recommendations = ref.get_performance_recommendations("diffusers")
    
    for i, rec in enumerate(recommendations, 1):
        print(f"  {i}. {rec}")

def main():
    """FunciÃ³n principal."""
    print("ğŸ¨ EJEMPLO PRÃCTICO DE DIFFUSERS")
    print("Usando referencias de documentaciÃ³n oficial")
    print("=" * 60)
    
    # Validar cÃ³digo
    validate_code()
    
    # Verificar recomendaciones de rendimiento
    check_performance_recommendations()
    
    # Cargar pipeline
    pipeline = load_pipeline()
    
    # Optimizar memoria
    optimize_memory(pipeline)
    
    # Generar imÃ¡genes
    prompts = [
        "A beautiful sunset over mountains",
        "A cute cat playing with a ball",
        "A futuristic city skyline at night"
    ]
    
    try:
        images = generate_images(pipeline, prompts)
        print(f"\nğŸ‰ Â¡{len(images)} imÃ¡genes generadas exitosamente!")
    except Exception as e:
        print(f"\nâš ï¸  Error al generar imÃ¡genes: {e}")
        print("Esto puede deberse a limitaciones de memoria o GPU")
    
    # Ejemplo de entrenamiento personalizado
    custom_training_example()
    
    print("\nğŸ‰ Â¡Ejemplo completado exitosamente!")
    print("El cÃ³digo sigue las mejores prÃ¡cticas oficiales de Diffusers.")

match __name__:
    case "__main__":
    main() 