# ğŸš€ Ultra-Adaptive KV Cache Engine - Modular Edition

Sistema modular de Key-Value Cache para Transformers y LLMs, completamente refactorizado siguiendo mejores prÃ¡cticas de PyTorch y desarrollo de software.

## ğŸ“¦ Estructura Modular

```
kv_cache/
â”œâ”€â”€ __init__.py              # Package exports
â”œâ”€â”€ config.py                 # Configuration classes
â”œâ”€â”€ quantization.py           # Quantization module
â”œâ”€â”€ compression.py            # Compression module
â”œâ”€â”€ memory_manager.py         # Memory management
â”œâ”€â”€ strategies/               # Eviction strategies
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # Base interface
â”‚   â”œâ”€â”€ lru.py               # LRU strategy
â”‚   â”œâ”€â”€ lfu.py               # LFU strategy
â”‚   â”œâ”€â”€ adaptive.py          # Adaptive strategy
â”‚   â””â”€â”€ factory.py           # Strategy factory
â””â”€â”€ MODULAR_STRUCTURE.md      # Detailed architecture docs
```

## ğŸ¯ Principios de DiseÃ±o

1. **SeparaciÃ³n de Responsabilidades**: Cada mÃ³dulo tiene una Ãºnica responsabilidad
2. **ComposiciÃ³n sobre Herencia**: Uso de composiciÃ³n para flexibilidad
3. **Interfaces Claras**: ABC para estrategias, interfaces bien definidas
4. **Extensibilidad**: FÃ¡cil agregar nuevas funcionalidades sin modificar cÃ³digo existente

## ğŸ”§ MÃ³dulos Principales

### Config (`config.py`)
- `CacheStrategy`: Estrategias de cache (LRU, LFU, Adaptive)
- `CacheMode`: Modos de operaciÃ³n (Training, Inference, etc.)
- `KVCacheConfig`: ConfiguraciÃ³n completa con validaciÃ³n

### Quantization (`quantization.py`)
- `Quantizer`: CuantizaciÃ³n INT8/INT4
- Soporte para mixed precision
- Manejo robusto de errores

### Compression (`compression.py`)
- `Compressor`: CompresiÃ³n SVD/low-rank/sparse
- MÃºltiples mÃ©todos de compresiÃ³n
- Soporte para mixed precision

### Memory Manager (`memory_manager.py`)
- `MemoryManager`: GestiÃ³n de memoria GPU/CPU
- Monitoreo de memoria
- Garbage collection

### Strategies (`strategies/`)
- `BaseEvictionStrategy`: Interface base
- `LRUEvictionStrategy`: Least Recently Used
- `LFUEvictionStrategy`: Least Frequently Used
- `AdaptiveEvictionStrategy`: CombinaciÃ³n adaptativa
- `factory.create_eviction_strategy()`: Factory para crear estrategias

## ğŸ“ Ejemplo de Uso

```python
from kv_cache import KVCacheConfig, CacheStrategy, CacheMode
from kv_cache.quantization import Quantizer
from kv_cache.compression import Compressor
from kv_cache.memory_manager import MemoryManager
from kv_cache.strategies import create_eviction_strategy

# ConfiguraciÃ³n
config = KVCacheConfig(
    max_tokens=4096,
    cache_strategy=CacheStrategy.ADAPTIVE,
    cache_mode=CacheMode.INFERENCE,
    use_quantization=True,
    use_compression=True,
)

# Componentes modulares
quantizer = Quantizer(bits=8, use_amp=True)
compressor = Compressor(ratio=0.3, method="svd")
memory_manager = MemoryManager(config, device)
eviction_strategy = create_eviction_strategy(config.cache_strategy)

# Usar componentes independientemente
key = torch.randn(1, 8, 128, 64)
value = torch.randn(1, 8, 128, 64)

# Quantize
key_q, value_q = quantizer.quantize(key, value)

# Compress
key_c, value_c = compressor.compress(key_q, value_q)

# Check memory
if memory_manager.should_evict(cache_size=1000):
    memory_manager.collect_garbage()
```

## âœ… Beneficios

1. **Modularidad**: CÃ³digo organizado en mÃ³dulos claros
2. **Testabilidad**: Cada mÃ³dulo puede testearse independientemente
3. **Mantenibilidad**: Cambios localizados, debugging mÃ¡s fÃ¡cil
4. **Extensibilidad**: FÃ¡cil agregar nuevas funcionalidades
5. **ReutilizaciÃ³n**: MÃ³dulos pueden usarse en otros contextos

## ğŸ”„ MigraciÃ³n desde VersiÃ³n MonolÃ­tica

El cÃ³digo original sigue funcionando. Los mÃ³dulos modulares estÃ¡n disponibles como una API alternativa mÃ¡s limpia y mantenible.

---

**VersiÃ³n**: 2.1.0 (Modular Architecture)  
**DocumentaciÃ³n**: Ver `MODULAR_STRUCTURE.md` para detalles completos

