from typing_extensions import Literal, TypedDict
from typing import Any, List, Dict, Optional, Union, Tuple
# Constants
MAX_CONNECTIONS = 1000

# Constants
MAX_RETRIES = 100

# Constants
TIMEOUT_SECONDS = 60

# Constants
BUFFER_SIZE = 1024

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any
import warnings
import torch
import torch.nn as nn
from torch.utils.data import Dataset
import pandas as pd
from functional_data_pipeline import DataPoint, ProcessingConfig, DataPipeline
from object_oriented_models import ModelType, TaskType, ModelConfig, ModelFactory
from gpu_optimization import (
from enhanced_unified_system import EnhancedUnifiedTrainingSystem, EnhancedUnifiedConfig
        import traceback
from typing import Any, List, Dict, Optional
#!/usr/bin/env python3
"""
GPU Integration Example
Practical demonstration of GPU optimization and mixed precision training
integration with the unified functional and object-oriented system.
"""



# Import our enhanced components
    GPUConfig, GPUOptimizationConfig, MixedPrecisionTrainer, 
    GPUMemoryManager, GPUMonitoring, setup_gpu_environment
)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore")

class SampleDataset(Dataset):
    """Sample dataset for demonstration"""
    
    def __init__(self, texts: List[str], labels: List[int], tokenizer=None, max_length: int = 512):
        
    """__init__ function."""
self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self) -> Any:
        return len(self.texts)
    
    def __getitem__(self, idx) -> Optional[Dict[str, Any]]:
        text = self.texts[idx]
        label = self.labels[idx]
        
        if self.tokenizer:
            encoding = self.tokenizer(
                text,
                truncation=True,
                padding='max_length',
                max_length=self.max_length,
                return_tensors='pt'
            )
            
            return {
                'input_ids': encoding['input_ids'].flatten(),
                'attention_mask': encoding['attention_mask'].flatten(),
                'labels': torch.tensor(label, dtype=torch.long)
            }
        else:
            return {
                'text': text,
                'labels': torch.tensor(label, dtype=torch.long)
            }

async def demonstrate_gpu_optimization():
    """Demonstrate GPU optimization and mixed precision training"""
    
    print("üöÄ GPU Optimization and Mixed Precision Training Demo")
    print("=" * 60)
    
    # Step 1: Check GPU availability
    print(f"\nüìä GPU Information:")
    print(f"CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU Count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {props.name} ({props.total_memory / 1024**3:.1f} GB)")
    
    # Step 2: Create sample data
    print(f"\nüìù Creating Sample Data...")
    sample_data = {
        'text': [
            "This product is absolutely amazing and exceeded all my expectations!",
            "Terrible quality, would not recommend to anyone.",
            "Great value for money, highly satisfied with the purchase.",
            "Poor customer service and disappointing experience overall.",
            "Excellent performance and outstanding features.",
            "Mediocre product that doesn't live up to the hype.",
            "Fantastic build quality and impressive design.",
            "Subpar materials and construction, avoid this product.",
            "Outstanding reliability and great user experience.",
            "Inferior performance compared to competitors."
        ],
        'label': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1: positive, 0: negative
    }
    
    df = pd.DataFrame(sample_data)
    df.to_csv('gpu_demo_data.csv', index=False)
    print(f"‚úÖ Sample data created with {len(sample_data['text'])} examples")
    
    # Step 3: Configure GPU optimization
    print(f"\n‚öôÔ∏è  Configuring GPU Optimization...")
    
    gpu_config = GPUOptimizationConfig(
        gpu_config=GPUConfig.MIXED_PRECISION,
        use_amp=True,
        use_gradient_accumulation=True,
        gradient_accumulation_steps=2,
        use_memory_efficient_attention=True,
        use_xformers=True,
        profile_memory=True,
        log_memory_usage=True
    )
    
    print(f"‚úÖ Mixed Precision: {gpu_config.use_amp}")
    print(f"‚úÖ Gradient Accumulation: {gpu_config.use_gradient_accumulation}")
    print(f"‚úÖ Memory Efficient Attention: {gpu_config.use_memory_efficient_attention}")
    print(f"‚úÖ XFormers: {gpu_config.use_xformers}")
    
    # Step 4: Setup GPU environment
    print(f"\nüîß Setting up GPU Environment...")
    setup_gpu_environment(gpu_config)
    
    # Step 5: Create enhanced unified configuration
    print(f"\nüéØ Creating Enhanced Unified Configuration...")
    
    enhanced_config = EnhancedUnifiedConfig(
        data_config=ProcessingConfig(
            max_length=128,  # Shorter for demo
            lowercase=True,
            remove_punctuation=True,
            remove_stopwords=False,
            lemmatize=False
        ),
        model_config=ModelConfig(
            model_type=ModelType.TRANSFORMER,
            task_type=TaskType.CLASSIFICATION,
            model_name="distilbert-base-uncased",  # Smaller model for demo
            num_classes=2,
            max_length=128
        ),
        gpu_config=gpu_config,
        batch_size=2,  # Small batch for demo
        num_epochs=2,
        learning_rate=2e-5,
        use_augmentation=True
    )
    
    print(f"‚úÖ Model: {enhanced_config.model_config.model_name}")
    print(f"‚úÖ Batch Size: {enhanced_config.batch_size}")
    print(f"‚úÖ Epochs: {enhanced_config.num_epochs}")
    
    # Step 6: Initialize memory manager and monitoring
    print(f"\nüìà Initializing GPU Monitoring...")
    memory_manager = GPUMemoryManager(gpu_config)
    gpu_monitoring = GPUMonitoring(gpu_config)
    
    # Log initial GPU state
    initial_memory = memory_manager.get_memory_info()
    print(f"‚úÖ Initial GPU Memory: {initial_memory}")
    
    # Step 7: Run enhanced training workflow
    print(f"\nüèÉ‚Äç‚ôÇÔ∏è Running Enhanced Training Workflow...")
    
    try:
        system = EnhancedUnifiedTrainingSystem(enhanced_config)
        result = await system.run_enhanced_workflow(
            data_path='gpu_demo_data.csv',
            text_column='text',
            label_column='label'
        )
        
        print(f"‚úÖ Training completed successfully!")
        
        # Step 8: Display results
        print(f"\nüìä Training Results:")
        print(f"Total Time: {result['workflow_info']['total_time']:.2f} seconds")
        
        if 'training_results' in result and 'training_history' in result['training_results']:
            training_history = result['training_results']['training_history']
            for epoch_result in training_history:
                epoch = epoch_result['epoch']
                train_loss = epoch_result['train_metrics']['loss']
                val_loss = epoch_result['val_metrics']['loss']
                val_acc = epoch_result['val_metrics']['accuracy']
                print(f"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        # Step 9: Display GPU performance metrics
        print(f"\nüéÆ GPU Performance Metrics:")
        if 'evaluation_results' in result and 'gpu_performance_metrics' in result['evaluation_results']:
            gpu_metrics = result['evaluation_results']['gpu_performance_metrics']
            if 'gpu_summary' in gpu_metrics:
                for gpu_id, gpu_info in gpu_metrics['gpu_summary'].items():
                    print(f"{gpu_id}: {gpu_info['name']}")
                    print(f"  Peak Memory: {gpu_info['peak_memory_mb']:.1f} MB")
                    print(f"  Avg Utilization: {gpu_info['average_utilization']:.1f}%")
        
        # Step 10: Display evaluation metrics
        print(f"\nüìà Evaluation Metrics:")
        if 'evaluation_results' in result and 'object_oriented_metrics' in result['evaluation_results']:
            eval_metrics = result['evaluation_results']['object_oriented_metrics']
            print(f"Accuracy: {eval_metrics.get('accuracy', 'N/A')}")
            print(f"Precision: {eval_metrics.get('precision', 'N/A')}")
            print(f"Recall: {eval_metrics.get('recall', 'N/A')}")
            print(f"F1 Score: {eval_metrics.get('f1', 'N/A')}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Training failed: {str(e)}")
        raise

async def demonstrate_mixed_precision_benefits():
    """Demonstrate the benefits of mixed precision training"""
    
    print(f"\nüî¨ Mixed Precision Training Benefits Demo")
    print("=" * 50)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available for mixed precision demo")
        return
    
    # Create a simple model for demonstration
    model = nn.Sequential(
        nn.Linear(100, 200),
        nn.ReLU(),
        nn.Linear(200, 100),
        nn.ReLU(),
        nn.Linear(100, 2)
    ).cuda()
    
    # Create sample data
    x = torch.randn(32, 100).cuda()
    y = torch.randint(0, 2, (32,)).cuda()
    
    # Test with and without mixed precision
    print(f"\nüìä Testing Mixed Precision vs Full Precision:")
    
    # Full precision
    start_time = time.time()
    model.train()
    for _ in range(100):
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        optimizer.zero_grad()
        output = model(x)
        loss = torch.nn.functional.cross_entropy(output, y)
        loss.backward()
        optimizer.step()
    full_precision_time = time.time() - start_time
    
    # Mixed precision
    scaler = torch.cuda.amp.GradScaler()
    start_time = time.time()
    model.train()
    for _ in range(100):
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            output = model(x)
            loss = torch.nn.functional.cross_entropy(output, y)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    mixed_precision_time = time.time() - start_time
    
    print(f"Full Precision Time: {full_precision_time:.3f} seconds")
    print(f"Mixed Precision Time: {mixed_precision_time:.3f} seconds")
    print(f"Speedup: {full_precision_time / mixed_precision_time:.2f}x")
    
    # Memory usage comparison
    full_precision_memory = torch.cuda.memory_allocated() / 1024**2
    torch.cuda.empty_cache()
    
    with torch.cuda.amp.autocast():
        _ = model(x)
    mixed_precision_memory = torch.cuda.memory_allocated() / 1024**2
    
    print(f"Full Precision Memory: {full_precision_memory:.1f} MB")
    print(f"Mixed Precision Memory: {mixed_precision_memory:.1f} MB")
    print(f"Memory Reduction: {full_precision_memory / mixed_precision_memory:.2f}x")

async def demonstrate_gpu_memory_management():
    """Demonstrate GPU memory management techniques"""
    
    print(f"\nüíæ GPU Memory Management Demo")
    print("=" * 40)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA not available for memory management demo")
        return
    
    config = GPUOptimizationConfig(
        profile_memory=True,
        log_memory_usage=True,
        memory_fraction=0.8
    )
    
    memory_manager = GPUMemoryManager(config)
    
    print(f"\nüìä Initial Memory State:")
    initial_memory = memory_manager.get_memory_info()
    print(f"GPU Memory: {initial_memory}")
    
    # Demonstrate memory optimization
    print(f"\nüîß Applying Memory Optimizations:")
    memory_manager.optimize_memory()
    
    # Create some tensors to demonstrate memory usage
    print(f"\nüìà Memory Usage During Operations:")
    tensors = []
    for i in range(5):
        tensor = torch.randn(1000, 1000).cuda()
        tensors.append(tensor)
        memory_info = memory_manager.monitor_memory_usage(f"tensor_creation_{i}")
        print(f"After creating tensor {i+1}: {memory_info}")
    
    # Clear cache
    print(f"\nüßπ Clearing GPU Cache:")
    memory_manager.clear_cache()
    final_memory = memory_manager.get_memory_info()
    print(f"After cache clear: {final_memory}")

async def main():
    """Main demonstration function"""
    
    print("üéØ GPU Optimization and Mixed Precision Training Demonstration")
    print("=" * 70)
    
    try:
        # Run main GPU optimization demo
        await demonstrate_gpu_optimization()
        
        # Run mixed precision benefits demo
        await demonstrate_mixed_precision_benefits()
        
        # Run memory management demo
        await demonstrate_gpu_memory_management()
        
        print(f"\nüéâ All demonstrations completed successfully!")
        print(f"‚úÖ GPU optimization and mixed precision training are working correctly!")
        
    except Exception as e:
        print(f"‚ùå Demonstration failed: {str(e)}")
        traceback.print_exc()

match __name__:
    case "__main__":
    asyncio.run(main()) 