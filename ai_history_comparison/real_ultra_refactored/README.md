# AI History Comparison - Sistema Ultra Refactorizado Real

Sistema ultra refactorizado para comparaciÃ³n y anÃ¡lisis de historial de IA con tecnologÃ­as reales y funcionales.

## ğŸš€ CaracterÃ­sticas

- **API RESTful** con FastAPI
- **Base de datos SQLite** con soporte asÃ­ncrono
- **AnÃ¡lisis de contenido** con scikit-learn y NLTK
- **ComparaciÃ³n semÃ¡ntica** usando TF-IDF y similitud coseno
- **EvaluaciÃ³n de calidad** automatizada
- **Sistema de trabajos** en segundo plano
- **MÃ©tricas del sistema** en tiempo real
- **DocumentaciÃ³n automÃ¡tica** con Swagger/OpenAPI

## ğŸ“‹ Requisitos

- Python 3.8+
- SQLite 3
- NLTK data (se descarga automÃ¡ticamente)

## ğŸ› ï¸ InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone <repository-url>
cd real_ultra_refactored
```

2. **Crear entorno virtual:**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

4. **Descargar datos de NLTK:**
```python
python -c "import nltk; nltk.download('punkt'); nltk.download('vader_lexicon')"
```

## ğŸš€ Uso

### Ejecutar el servidor:

```bash
python -m api.main
```

O usando uvicorn directamente:

```bash
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

### Acceder a la documentaciÃ³n:

- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

## ğŸ“š API Endpoints

### Historial
- `POST /history` - Crear entrada de historial
- `GET /history` - Obtener entradas con filtros
- `GET /history/{id}` - Obtener entrada especÃ­fica
- `DELETE /history/{id}` - Eliminar entrada

### Comparaciones
- `POST /comparisons` - Crear comparaciÃ³n entre entradas
- `GET /comparisons` - Obtener comparaciones
- `GET /comparisons/{id}` - Obtener comparaciÃ³n especÃ­fica

### Calidad
- `POST /quality` - Crear reporte de calidad
- `GET /quality` - Obtener reportes de calidad
- `GET /quality/{id}` - Obtener reporte especÃ­fico

### Trabajos
- `POST /jobs` - Crear trabajo de anÃ¡lisis
- `GET /jobs` - Obtener trabajos
- `GET /jobs/{id}` - Obtener trabajo especÃ­fico

### MÃ©tricas
- `GET /metrics` - Obtener mÃ©tricas del sistema
- `GET /trends` - Obtener anÃ¡lisis de tendencias
- `GET /health` - VerificaciÃ³n de salud

## ğŸ”§ ConfiguraciÃ³n

Crear archivo `.env`:

```env
DEBUG=false
HOST=0.0.0.0
PORT=8000
DATABASE_PATH=ai_history_comparison.db
LOG_LEVEL=INFO
MAX_CONTENT_LENGTH=10000
ANALYSIS_TIMEOUT=30
```

## ğŸ“Š Ejemplos de Uso

### Crear entrada de historial:

```python
import requests

entry_data = {
    "model_type": "gpt-4",
    "model_version": "gpt-4-1106-preview",
    "prompt": "Explain quantum computing",
    "response": "Quantum computing is a type of computation...",
    "response_time_ms": 1500,
    "token_count": 150,
    "cost_usd": 0.002
}

response = requests.post("http://localhost:8000/history", json=entry_data)
print(response.json())
```

### Crear comparaciÃ³n:

```python
comparison_data = {
    "entry_1_id": "entry-id-1",
    "entry_2_id": "entry-id-2"
}

response = requests.post("http://localhost:8000/comparisons", json=comparison_data)
print(response.json())
```

### Obtener mÃ©tricas:

```python
response = requests.get("http://localhost:8000/metrics")
metrics = response.json()
print(f"Total entries: {metrics['total_entries']}")
print(f"Average quality: {metrics['average_quality_score']:.2f}")
```

## ğŸ—ï¸ Arquitectura

```
real_ultra_refactored/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # API principal con FastAPI
â”œâ”€â”€ core/
â”‚   â””â”€â”€ models.py            # Modelos de datos con Pydantic
â”œâ”€â”€ services/
â”‚   â””â”€â”€ analysis_service.py  # Servicios de anÃ¡lisis
â”œâ”€â”€ database/
â”‚   â””â”€â”€ database.py          # Gestor de base de datos
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py          # ConfiguraciÃ³n
â”œâ”€â”€ requirements.txt         # Dependencias
â””â”€â”€ README.md               # DocumentaciÃ³n
```

## ğŸ” AnÃ¡lisis de Contenido

El sistema incluye anÃ¡lisis automÃ¡tico de:

- **MÃ©tricas bÃ¡sicas:** conteo de palabras, oraciones, caracteres
- **Legibilidad:** puntuaciÃ³n Flesch-Kincaid
- **Sentimiento:** anÃ¡lisis de polaridad
- **Complejidad:** longitud promedio de palabras y oraciones
- **Vocabulario:** riqueza y diversidad

## ğŸ“ˆ ComparaciÃ³n de Entradas

- **Similitud semÃ¡ntica:** TF-IDF + similitud coseno
- **Similitud lÃ©xica:** Jaccard index
- **Similitud estructural:** comparaciÃ³n de mÃ©tricas
- **DetecciÃ³n de diferencias:** anÃ¡lisis automÃ¡tico
- **IdentificaciÃ³n de mejoras:** sugerencias automÃ¡ticas

## ğŸ¯ EvaluaciÃ³n de Calidad

- **Coherencia:** estructura y legibilidad
- **Relevancia:** relaciÃ³n con el prompt
- **Creatividad:** riqueza de vocabulario
- **PrecisiÃ³n:** uso apropiado del lenguaje
- **Claridad:** facilidad de comprensiÃ³n

## ğŸ§ª Testing

```bash
# Ejecutar tests
pytest

# Con cobertura
pytest --cov=.

# Tests especÃ­ficos
pytest tests/test_analysis_service.py
```

## ğŸ“ Logging

El sistema incluye logging estructurado:

```python
import logging
logger = logging.getLogger(__name__)
logger.info("Operation completed successfully")
```

## ğŸš€ Despliegue

### Docker:

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Docker Compose:

```yaml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_PATH=/app/data/ai_history.db
    volumes:
      - ./data:/app/data
```

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama para feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ†˜ Soporte

Para soporte, crear un issue en el repositorio o contactar al equipo de desarrollo.

---

**Sistema Ultra Refactorizado Real** - TecnologÃ­as funcionales y prÃ¡cticas para anÃ¡lisis de IA.




