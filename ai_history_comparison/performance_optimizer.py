"""
Performance Optimizer - Mejoras Reales de Performance
Sistema de optimizaci√≥n pr√°ctica para AI History Comparison
"""

import time
import asyncio
from functools import lru_cache
from typing import Dict, Any, Optional
import json
import hashlib
from datetime import datetime, timedelta

# Cach√© en memoria para respuestas frecuentes
@lru_cache(maxsize=1000)
def cached_analysis(content_hash: str) -> Optional[Dict[str, Any]]:
    """Cach√© LRU para an√°lisis frecuentes"""
    return None

def get_content_hash(content: str) -> str:
    """Generar hash √∫nico para el contenido"""
    return hashlib.sha256(content.encode()).hexdigest()

class PerformanceOptimizer:
    """Optimizador de performance real"""
    
    def __init__(self):
        self.request_count = 0
        self.cache_hits = 0
        self.cache_misses = 0
        self.avg_response_time = 0.0
        
    async def optimize_analysis(self, content: str, analysis_func) -> Dict[str, Any]:
        """Optimizar an√°lisis con cach√© y m√©tricas"""
        start_time = time.time()
        content_hash = get_content_hash(content)
        
        # Verificar cach√© primero
        cached_result = cached_analysis(content_hash)
        if cached_result:
            self.cache_hits += 1
            return {
                **cached_result,
                "cached": True,
                "response_time": time.time() - start_time
            }
        
        # Realizar an√°lisis si no est√° en cach√©
        self.cache_misses += 1
        result = await analysis_func(content)
        
        # Guardar en cach√©
        cached_analysis.cache_clear()  # Limpiar cach√© viejo
        cached_analysis(content_hash)  # Agregar nuevo resultado
        
        response_time = time.time() - start_time
        self.request_count += 1
        self.avg_response_time = (self.avg_response_time + response_time) / 2
        
        return {
            **result,
            "cached": False,
            "response_time": response_time,
            "cache_hit_rate": self.cache_hits / (self.cache_hits + self.cache_misses) * 100
        }
    
    def get_metrics(self) -> Dict[str, Any]:
        """Obtener m√©tricas de performance"""
        return {
            "total_requests": self.request_count,
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "cache_hit_rate": f"{self.cache_hits / (self.cache_hits + self.cache_misses) * 100:.2f}%" if (self.cache_hits + self.cache_misses) > 0 else "0%",
            "avg_response_time": f"{self.avg_response_time:.3f}s",
            "cache_size": cached_analysis.cache_info().currsize,
            "cache_max_size": cached_analysis.cache_info().maxsize
        }

class RealTimeAnalyzer:
    """Analizador en tiempo real con optimizaciones"""
    
    def __init__(self):
        self.optimizer = PerformanceOptimizer()
        self.analysis_history = []
        
    async def analyze_content(self, content: str) -> Dict[str, Any]:
        """An√°lisis optimizado de contenido"""
        
        # Funci√≥n de an√°lisis real
        async def perform_analysis(text: str) -> Dict[str, Any]:
            # Simular an√°lisis real (reemplazar con tu l√≥gica)
            await asyncio.sleep(0.1)  # Simular procesamiento
            
            return {
                "content_length": len(text),
                "word_count": len(text.split()),
                "sentiment": "positive" if "good" in text.lower() else "neutral",
                "language": "es" if any(char in text for char in "√±√°√©√≠√≥√∫") else "en",
                "timestamp": datetime.now().isoformat(),
                "analysis_id": f"analysis_{int(time.time())}"
            }
        
        # Usar optimizador
        result = await self.optimizer.optimize_analysis(content, perform_analysis)
        
        # Guardar en historial
        self.analysis_history.append({
            "timestamp": datetime.now(),
            "content_hash": get_content_hash(content),
            "response_time": result.get("response_time", 0)
        })
        
        # Limpiar historial viejo (mantener solo √∫ltimos 100)
        if len(self.analysis_history) > 100:
            self.analysis_history = self.analysis_history[-100:]
        
        return result
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Obtener m√©tricas de performance del sistema"""
        metrics = self.optimizer.get_metrics()
        
        # A√±adir m√©tricas adicionales
        if self.analysis_history:
            recent_times = [h["response_time"] for h in self.analysis_history[-10:]]
            metrics.update({
                "recent_avg_response_time": f"{sum(recent_times) / len(recent_times):.3f}s",
                "total_analyses": len(self.analysis_history),
                "system_uptime": f"{(datetime.now() - self.analysis_history[0]['timestamp']).total_seconds():.0f}s" if self.analysis_history else "0s"
            })
        
        return metrics

# Ejemplo de uso real
async def main():
    """Ejemplo de uso del optimizador"""
    analyzer = RealTimeAnalyzer()
    
    # Simular an√°lisis de contenido
    test_content = "Este es un contenido de prueba para an√°lisis de IA"
    
    print("üöÄ Iniciando an√°lisis optimizado...")
    
    # Primer an√°lisis (sin cach√©)
    result1 = await analyzer.analyze_content(test_content)
    print(f"‚úÖ Primer an√°lisis: {result1['response_time']:.3f}s")
    
    # Segundo an√°lisis (con cach√©)
    result2 = await analyzer.analyze_content(test_content)
    print(f"‚ö° Segundo an√°lisis (cach√©): {result2['response_time']:.3f}s")
    
    # Mostrar m√©tricas
    metrics = analyzer.get_performance_metrics()
    print(f"üìä M√©tricas: {json.dumps(metrics, indent=2)}")

if __name__ == "__main__":
    asyncio.run(main())