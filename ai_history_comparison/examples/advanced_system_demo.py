"""
Advanced System Demo for AI History Comparison
Demostraci√≥n completa del sistema avanzado de an√°lisis de historial de IA
"""

import asyncio
import json
import logging
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import sys
import os

# Agregar el directorio padre al path para importar los m√≥dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Importar todos los sistemas avanzados
from ai_optimizer import AIOptimizer, ModelType, OptimizationGoal
from emotion_analyzer import AdvancedEmotionAnalyzer, EmotionType
from temporal_analyzer import AdvancedTemporalAnalyzer, TrendType
from content_quality_analyzer import AdvancedContentQualityAnalyzer, ContentType, QualityLevel
from behavior_pattern_analyzer import AdvancedBehaviorPatternAnalyzer, BehaviorType
from performance_optimizer import AdvancedPerformanceOptimizer, PerformanceLevel
from security_analyzer import AdvancedSecurityAnalyzer, SecurityLevel
from advanced_orchestrator import AdvancedOrchestrator, AnalysisType, IntegrationLevel

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AdvancedSystemDemo:
    """
    Demostraci√≥n completa del sistema avanzado
    """
    
    def __init__(self):
        self.orchestrator = AdvancedOrchestrator(
            enable_parallel_processing=True,
            enable_auto_optimization=True,
            enable_real_time_monitoring=True,
            max_concurrent_analyses=3
        )
        
        # Datos de ejemplo
        self.sample_documents = self._create_sample_documents()
        self.sample_temporal_data = self._create_sample_temporal_data()
        self.sample_behavior_data = self._create_sample_behavior_data()
    
    def _create_sample_documents(self) -> List[Dict[str, Any]]:
        """Crear documentos de ejemplo"""
        return [
            {
                "id": "doc_001",
                "text": """
                # An√°lisis de Tendencias en IA 2024
                
                La inteligencia artificial ha experimentado un crecimiento exponencial en los √∫ltimos a√±os. 
                Los modelos de lenguaje como GPT-4 y Claude han revolucionado la forma en que interactuamos 
                con la tecnolog√≠a.
                
                ## Principales Avances
                
                - **Procesamiento de lenguaje natural**: Mejoras significativas en comprensi√≥n y generaci√≥n
                - **Visi√≥n por computadora**: Detecci√≥n de objetos m√°s precisa
                - **Rob√≥tica**: Mayor autonom√≠a en tareas complejas
                
                ## Impacto en la Sociedad
                
                La IA est√° transformando m√∫ltiples industrias, desde la salud hasta la educaci√≥n. 
                Sin embargo, tambi√©n plantea desaf√≠os √©ticos importantes que debemos abordar.
                
                ### Consideraciones √âticas
                
                1. Privacidad de datos
                2. Sesgos algor√≠tmicos
                3. Transparencia en decisiones automatizadas
                
                En conclusi√≥n, la IA representa tanto oportunidades como desaf√≠os que requieren 
                una aproximaci√≥n cuidadosa y responsable.
                """,
                "metadata": {
                    "author": "Dr. Jane Smith",
                    "date": "2024-01-15",
                    "category": "technology",
                    "word_count": 150
                }
            },
            {
                "id": "doc_002",
                "text": """
                # Reporte de Rendimiento del Sistema
                
                ## Resumen Ejecutivo
                
                El sistema ha mostrado un rendimiento excepcional durante el √∫ltimo trimestre. 
                Los indicadores clave han superado las expectativas establecidas.
                
                ### M√©tricas Principales
                
                - **Tiempo de respuesta**: 1.2 segundos (objetivo: <2s) ‚úÖ
                - **Disponibilidad**: 99.9% (objetivo: >99.5%) ‚úÖ
                - **Satisfacci√≥n del usuario**: 4.8/5 (objetivo: >4.5) ‚úÖ
                
                ## An√°lisis Detallado
                
                ### Fortalezas Identificadas
                
                1. **Escalabilidad**: El sistema maneja eficientemente picos de tr√°fico
                2. **Confiabilidad**: M√≠nimos tiempos de inactividad
                3. **Usabilidad**: Interfaz intuitiva y f√°cil de usar
                
                ### √Åreas de Mejora
                
                1. **Optimizaci√≥n de consultas**: Reducir latencia en operaciones complejas
                2. **Cach√© inteligente**: Implementar estrategias de cach√© m√°s sofisticadas
                3. **Monitoreo proactivo**: Mejorar detecci√≥n temprana de problemas
                
                ## Recomendaciones
                
                Para mantener el alto rendimiento, recomendamos:
                
                - Implementar an√°lisis predictivo
                - Expandir capacidades de monitoreo
                - Invertir en optimizaci√≥n de algoritmos
                
                El futuro se ve prometedor con estas mejoras planificadas.
                """,
                "metadata": {
                    "author": "Ing. Carlos Rodriguez",
                    "date": "2024-01-20",
                    "category": "performance",
                    "word_count": 200
                }
            },
            {
                "id": "doc_003",
                "text": """
                # Investigaci√≥n sobre Patrones de Comportamiento
                
                ## Introducci√≥n
                
                Este estudio examina los patrones de comportamiento de usuarios en plataformas digitales. 
                Los resultados son fascinantes y reveladores.
                
                ## Metodolog√≠a
                
                Utilizamos t√©cnicas avanzadas de an√°lisis de datos y machine learning para identificar 
                patrones complejos en el comportamiento de los usuarios.
                
                ### Datos Analizados
                
                - 1,000,000 de interacciones de usuarios
                - 50,000 usuarios √∫nicos
                - Per√≠odo de estudio: 6 meses
                
                ## Hallazgos Principales
                
                ### Patrones Identificados
                
                1. **Comportamiento Circadiano**: Los usuarios muestran patrones claros de actividad
                2. **Influencia Social**: Las interacciones grupales afectan el comportamiento individual
                3. **Adaptaci√≥n Temporal**: Los usuarios se adaptan a nuevas funcionalidades r√°pidamente
                
                ### Implicaciones
                
                Estos hallazgos tienen implicaciones significativas para:
                
                - Dise√±o de interfaces de usuario
                - Estrategias de engagement
                - Personalizaci√≥n de experiencias
                
                ## Conclusiones
                
                El comportamiento humano en entornos digitales sigue patrones predecibles pero complejos. 
                Comprender estos patrones es crucial para crear experiencias m√°s efectivas.
                
                ### Pr√≥ximos Pasos
                
                1. Validar hallazgos con estudios adicionales
                2. Desarrollar modelos predictivos
                3. Implementar mejoras basadas en insights
                """,
                "metadata": {
                    "author": "Dra. Maria Gonzalez",
                    "date": "2024-01-25",
                    "category": "research",
                    "word_count": 180
                }
            }
        ]
    
    def _create_sample_temporal_data(self) -> Dict[str, List]:
        """Crear datos temporales de ejemplo"""
        from temporal_analyzer import TemporalPoint
        
        # Generar datos de ejemplo para diferentes m√©tricas
        base_time = datetime.now() - timedelta(days=30)
        
        # M√©trica 1: Calidad de contenido
        quality_data = []
        for i in range(30):
            timestamp = base_time + timedelta(days=i)
            # Simular tendencia creciente con variaci√≥n
            value = 0.6 + (i * 0.01) + np.random.normal(0, 0.05)
            quality_data.append(TemporalPoint(
                timestamp=timestamp,
                value=max(0, min(1, value)),
                confidence=0.9
            ))
        
        # M√©trica 2: Tiempo de respuesta
        response_time_data = []
        for i in range(30):
            timestamp = base_time + timedelta(days=i)
            # Simular tendencia decreciente (mejora)
            value = 3.0 - (i * 0.05) + np.random.normal(0, 0.2)
            response_time_data.append(TemporalPoint(
                timestamp=timestamp,
                value=max(0.1, value),
                confidence=0.8
            ))
        
        # M√©trica 3: Satisfacci√≥n del usuario
        satisfaction_data = []
        for i in range(30):
            timestamp = base_time + timedelta(days=i)
            # Simular estabilidad con peque√±as variaciones
            value = 4.5 + np.random.normal(0, 0.3)
            satisfaction_data.append(TemporalPoint(
                timestamp=timestamp,
                value=max(1, min(5, value)),
                confidence=0.85
            ))
        
        return {
            "content_quality": quality_data,
            "response_time": response_time_data,
            "user_satisfaction": satisfaction_data
        }
    
    def _create_sample_behavior_data(self) -> Dict[str, List]:
        """Crear datos de comportamiento de ejemplo"""
        from behavior_pattern_analyzer import BehaviorMetric
        
        # Generar datos de comportamiento para diferentes entidades
        base_time = datetime.now() - timedelta(hours=24)
        
        # Entidad 1: Usuario tipo A
        user_a_data = []
        for i in range(50):
            timestamp = base_time + timedelta(minutes=i*30)
            # Simular comportamiento consistente
            value = 0.7 + np.random.normal(0, 0.1)
            user_a_data.append(BehaviorMetric(
                name="engagement_level",
                value=max(0, min(1, value)),
                timestamp=timestamp,
                context={"user_type": "A", "session_id": f"session_{i}"}
            ))
        
        # Entidad 2: Usuario tipo B
        user_b_data = []
        for i in range(50):
            timestamp = base_time + timedelta(minutes=i*30)
            # Simular comportamiento m√°s variable
            value = 0.5 + np.random.normal(0, 0.2)
            user_b_data.append(BehaviorMetric(
                name="engagement_level",
                value=max(0, min(1, value)),
                timestamp=timestamp,
                context={"user_type": "B", "session_id": f"session_{i}"}
            ))
        
        return {
            "user_type_A": user_a_data,
            "user_type_B": user_b_data
        }
    
    async def run_comprehensive_demo(self):
        """Ejecutar demostraci√≥n comprensiva"""
        try:
            logger.info("üöÄ Iniciando demostraci√≥n comprensiva del sistema avanzado")
            
            # 1. An√°lisis comprensivo
            logger.info("\nüìä 1. An√°lisis Comprensivo")
            await self._demo_comprehensive_analysis()
            
            # 2. An√°lisis enfocado en calidad
            logger.info("\nüéØ 2. An√°lisis Enfocado en Calidad")
            await self._demo_quality_focused_analysis()
            
            # 3. An√°lisis enfocado en rendimiento
            logger.info("\n‚ö° 3. An√°lisis Enfocado en Rendimiento")
            await self._demo_performance_focused_analysis()
            
            # 4. An√°lisis enfocado en seguridad
            logger.info("\nüîí 4. An√°lisis Enfocado en Seguridad")
            await self._demo_security_focused_analysis()
            
            # 5. An√°lisis enfocado en emociones
            logger.info("\nüòä 5. An√°lisis Enfocado en Emociones")
            await self._demo_emotion_focused_analysis()
            
            # 6. An√°lisis temporal
            logger.info("\nüìà 6. An√°lisis Temporal")
            await self._demo_temporal_analysis()
            
            # 7. An√°lisis de comportamiento
            logger.info("\nüß† 7. An√°lisis de Comportamiento")
            await self._demo_behavior_analysis()
            
            # 8. Optimizaci√≥n de IA
            logger.info("\nü§ñ 8. Optimizaci√≥n de IA")
            await self._demo_ai_optimization()
            
            # 9. Resumen final
            logger.info("\nüìã 9. Resumen Final")
            await self._demo_final_summary()
            
            logger.info("\n‚úÖ Demostraci√≥n completada exitosamente!")
            
        except Exception as e:
            logger.error(f"‚ùå Error en la demostraci√≥n: {e}")
            raise
    
    async def _demo_comprehensive_analysis(self):
        """Demostrar an√°lisis comprensivo"""
        try:
            result = await self.orchestrator.analyze_documents(
                documents=self.sample_documents,
                analysis_type=AnalysisType.COMPREHENSIVE,
                integration_level=IntegrationLevel.EXPERT
            )
            
            logger.info(f"‚úÖ An√°lisis comprensivo completado en {result.execution_time:.2f} segundos")
            logger.info(f"üìä Componentes analizados: {len(result.results)}")
            logger.info(f"üí° Insights generados: {len(result.insights)}")
            logger.info(f"üéØ Recomendaciones: {len(result.recommendations)}")
            
            # Mostrar insights principales
            for insight in result.insights[:3]:
                logger.info(f"   ‚Ä¢ {insight['title']}: {insight['description']}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis comprensivo: {e}")
    
    async def _demo_quality_focused_analysis(self):
        """Demostrar an√°lisis enfocado en calidad"""
        try:
            result = await self.orchestrator.analyze_documents(
                documents=self.sample_documents,
                analysis_type=AnalysisType.QUALITY_FOCUSED,
                integration_level=IntegrationLevel.ADVANCED
            )
            
            logger.info(f"‚úÖ An√°lisis de calidad completado en {result.execution_time:.2f} segundos")
            
            if "content_quality" in result.results:
                quality_analyses = result.results["content_quality"]
                logger.info(f"üìù Documentos analizados: {len(quality_analyses)}")
                
                for i, analysis in enumerate(quality_analyses):
                    logger.info(f"   Documento {i+1}:")
                    logger.info(f"     ‚Ä¢ Score general: {analysis.overall_score:.2f}")
                    logger.info(f"     ‚Ä¢ Nivel de calidad: {analysis.quality_level.value}")
                    logger.info(f"     ‚Ä¢ Fortalezas: {len(analysis.strengths)}")
                    logger.info(f"     ‚Ä¢ Debilidades: {len(analysis.weaknesses)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis de calidad: {e}")
    
    async def _demo_performance_focused_analysis(self):
        """Demostrar an√°lisis enfocado en rendimiento"""
        try:
            result = await self.orchestrator.analyze_documents(
                documents=self.sample_documents,
                analysis_type=AnalysisType.PERFORMANCE_FOCUSED,
                integration_level=IntegrationLevel.ADVANCED
            )
            
            logger.info(f"‚úÖ An√°lisis de rendimiento completado en {result.execution_time:.2f} segundos")
            
            if "system_performance" in result.results:
                performance = result.results["system_performance"]
                logger.info(f"üìä M√©tricas de rendimiento:")
                logger.info(f"   ‚Ä¢ Alertas activas: {performance.get('active_alerts', 0)}")
                logger.info(f"   ‚Ä¢ Total de alertas: {performance.get('total_alerts', 0)}")
                logger.info(f"   ‚Ä¢ Recomendaciones: {performance.get('total_recommendations', 0)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis de rendimiento: {e}")
    
    async def _demo_security_focused_analysis(self):
        """Demostrar an√°lisis enfocado en seguridad"""
        try:
            result = await self.orchestrator.analyze_documents(
                documents=self.sample_documents,
                analysis_type=AnalysisType.SECURITY_FOCUSED,
                integration_level=IntegrationLevel.ADVANCED
            )
            
            logger.info(f"‚úÖ An√°lisis de seguridad completado en {result.execution_time:.2f} segundos")
            
            if "security_issues" in result.results:
                issues = result.results["security_issues"]
                logger.info(f"üîí Problemas de seguridad detectados: {len(issues)}")
                
                for issue in issues[:3]:
                    logger.info(f"   ‚Ä¢ {issue.issue_type}: {issue.description}")
            
            if "privacy_analyses" in result.results:
                privacy_analyses = result.results["privacy_analyses"]
                logger.info(f"üîê An√°lisis de privacidad: {len(privacy_analyses)}")
                
                for analysis in privacy_analyses:
                    logger.info(f"   ‚Ä¢ PII detectado: {len(analysis.pii_detected)}")
                    logger.info(f"   ‚Ä¢ Score de riesgo: {analysis.risk_score:.2f}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis de seguridad: {e}")
    
    async def _demo_emotion_focused_analysis(self):
        """Demostrar an√°lisis enfocado en emociones"""
        try:
            result = await self.orchestrator.analyze_documents(
                documents=self.sample_documents,
                analysis_type=AnalysisType.EMOTION_FOCUSED,
                integration_level=IntegrationLevel.ADVANCED
            )
            
            logger.info(f"‚úÖ An√°lisis emocional completado en {result.execution_time:.2f} segundos")
            
            if "emotion_analyses" in result.results:
                emotion_analyses = result.results["emotion_analyses"]
                logger.info(f"üòä An√°lisis emocionales: {len(emotion_analyses)}")
                
                for i, analysis in enumerate(emotion_analyses):
                    logger.info(f"   Documento {i+1}:")
                    logger.info(f"     ‚Ä¢ Emoci√≥n dominante: {analysis.dominant_emotion.value}")
                    logger.info(f"     ‚Ä¢ Tono emocional: {analysis.emotional_tone.value}")
                    logger.info(f"     ‚Ä¢ Intensidad: {analysis.intensity.value}")
                    logger.info(f"     ‚Ä¢ Confianza: {analysis.confidence:.2f}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis emocional: {e}")
    
    async def _demo_temporal_analysis(self):
        """Demostrar an√°lisis temporal"""
        try:
            # Agregar datos temporales
            for metric_name, data_points in self.sample_temporal_data.items():
                await self.orchestrator.temporal_analyzer.add_temporal_data(metric_name, data_points)
            
            # Analizar tendencias
            trend_analyses = []
            for metric_name in self.sample_temporal_data.keys():
                analysis = await self.orchestrator.temporal_analyzer.analyze_trends(metric_name)
                trend_analyses.append(analysis)
            
            logger.info(f"‚úÖ An√°lisis temporal completado")
            logger.info(f"üìà M√©tricas analizadas: {len(trend_analyses)}")
            
            for analysis in trend_analyses:
                logger.info(f"   ‚Ä¢ {analysis.metric_name}:")
                logger.info(f"     - Tipo de tendencia: {analysis.trend_type.value}")
                logger.info(f"     - Patr√≥n: {analysis.pattern_type.value}")
                logger.info(f"     - R¬≤: {analysis.r_squared:.3f}")
                logger.info(f"     - Anomal√≠as: {len(analysis.anomalies)}")
            
            # Comparar m√©tricas
            if len(trend_analyses) > 1:
                comparison = await self.orchestrator.temporal_analyzer.compare_temporal_metrics(
                    list(self.sample_temporal_data.keys())
                )
                logger.info(f"üîÑ Comparaci√≥n temporal completada")
                logger.info(f"   ‚Ä¢ Correlaciones: {len(comparison.get('correlations', {}))}")
                logger.info(f"   ‚Ä¢ Diferencias: {len(comparison.get('significant_differences', []))}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis temporal: {e}")
    
    async def _demo_behavior_analysis(self):
        """Demostrar an√°lisis de comportamiento"""
        try:
            # Agregar datos de comportamiento
            for entity_id, metrics in self.sample_behavior_data.items():
                await self.orchestrator.behavior_analyzer.add_behavior_metrics(entity_id, metrics)
            
            # Analizar patrones de comportamiento
            all_patterns = []
            for entity_id in self.sample_behavior_data.keys():
                patterns = await self.orchestrator.behavior_analyzer.analyze_behavior_patterns(entity_id)
                all_patterns.extend(patterns)
            
            logger.info(f"‚úÖ An√°lisis de comportamiento completado")
            logger.info(f"üß† Patrones identificados: {len(all_patterns)}")
            
            for pattern in all_patterns:
                logger.info(f"   ‚Ä¢ {pattern.id}:")
                logger.info(f"     - Tipo: {pattern.pattern_type.value}")
                logger.info(f"     - Complejidad: {pattern.complexity.value}")
                logger.info(f"     - Fuerza: {pattern.strength:.2f}")
                logger.info(f"     - Confianza: {pattern.confidence:.2f}")
            
            # Comparar patrones
            if len(self.sample_behavior_data) > 1:
                comparison = await self.orchestrator.behavior_analyzer.compare_behavior_patterns(
                    list(self.sample_behavior_data.keys())
                )
                logger.info(f"üîÑ Comparaci√≥n de comportamiento completada")
                logger.info(f"   ‚Ä¢ Similitudes: {len(comparison.get('similarities', {}))}")
                logger.info(f"   ‚Ä¢ Diferencias: {len(comparison.get('significant_differences', []))}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis de comportamiento: {e}")
    
    async def _demo_ai_optimization(self):
        """Demostrar optimizaci√≥n de IA"""
        try:
            # Crear datos de ejemplo para optimizaci√≥n
            sample_data = pd.DataFrame({
                'feature1': np.random.randn(100),
                'feature2': np.random.randn(100),
                'feature3': np.random.randn(100),
                'target': np.random.randn(100)
            })
            
            # Preparar datos de entrenamiento
            await self.orchestrator.ai_optimizer.prepare_training_data(
                data=sample_data,
                feature_columns=['feature1', 'feature2', 'feature3'],
                target_columns=['target']
            )
            
            # Entrenar modelos
            models_to_train = [
                ModelType.LINEAR_REGRESSION,
                ModelType.RANDOM_FOREST,
                ModelType.XGBOOST
            ]
            
            trained_models = []
            for model_type in models_to_train:
                performance = await self.orchestrator.ai_optimizer.train_model(model_type)
                trained_models.append(performance)
                logger.info(f"   ‚Ä¢ {model_type.value}: R¬≤ = {performance.r_squared:.3f}")
            
            # Optimizar modelos
            optimization_result = await self.orchestrator.ai_optimizer.optimize_models(
                OptimizationGoal.MAXIMIZE_QUALITY
            )
            
            logger.info(f"‚úÖ Optimizaci√≥n de IA completada")
            logger.info(f"ü§ñ Mejor modelo: {optimization_result.best_model}")
            logger.info(f"üìà Mejora de rendimiento: {optimization_result.performance_improvement:.1%}")
            logger.info(f"üí∞ Reducci√≥n de costo: {optimization_result.cost_reduction:.1%}")
            logger.info(f"‚ö° Mejora de velocidad: {optimization_result.speed_improvement:.1%}")
            
            # Generar insights de aprendizaje
            insights = await self.orchestrator.ai_optimizer.generate_learning_insights()
            logger.info(f"üí° Insights de aprendizaje: {len(insights)}")
            
            for insight in insights[:3]:
                logger.info(f"   ‚Ä¢ {insight.description}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en optimizaci√≥n de IA: {e}")
    
    async def _demo_final_summary(self):
        """Demostrar resumen final"""
        try:
            # Obtener resumen del orquestador
            summary = await self.orchestrator.get_orchestrator_summary()
            
            logger.info("üìã RESUMEN FINAL DEL SISTEMA")
            logger.info("=" * 50)
            logger.info(f"üìä Total de solicitudes: {summary['total_requests']}")
            logger.info(f"‚úÖ An√°lisis exitosos: {summary['successful_analyses']}")
            logger.info(f"‚ùå An√°lisis fallidos: {summary['failed_analyses']}")
            logger.info(f"‚è±Ô∏è Tiempo promedio de ejecuci√≥n: {summary['average_execution_time']:.2f}s")
            
            # Estado de los sistemas
            logger.info("\nüîß ESTADO DE LOS SISTEMAS:")
            system_status = summary['system_status']
            for system_name, status in system_status.items():
                logger.info(f"   ‚Ä¢ {status.system_name}: {status.status} (Health: {status.health_score:.1f})")
            
            # Configuraci√≥n
            logger.info("\n‚öôÔ∏è CONFIGURACI√ìN:")
            config = summary['configuration']
            logger.info(f"   ‚Ä¢ Procesamiento paralelo: {config['parallel_processing']}")
            logger.info(f"   ‚Ä¢ Optimizaci√≥n autom√°tica: {config['auto_optimization']}")
            logger.info(f"   ‚Ä¢ Monitoreo en tiempo real: {config['real_time_monitoring']}")
            logger.info(f"   ‚Ä¢ An√°lisis concurrentes m√°ximos: {config['max_concurrent_analyses']}")
            
            # Exportar datos
            logger.info("\nüíæ EXPORTANDO DATOS...")
            export_path = await self.orchestrator.export_orchestrator_data()
            logger.info(f"‚úÖ Datos exportados a: {export_path}")
            
            # Exportar datos de sistemas individuales
            systems_to_export = [
                ("emotion_analyzer", self.orchestrator.emotion_analyzer),
                ("temporal_analyzer", self.orchestrator.temporal_analyzer),
                ("content_quality_analyzer", self.orchestrator.content_quality_analyzer),
                ("behavior_analyzer", self.orchestrator.behavior_analyzer),
                ("performance_optimizer", self.orchestrator.performance_optimizer),
                ("security_analyzer", self.orchestrator.security_analyzer),
                ("ai_optimizer", self.orchestrator.ai_optimizer)
            ]
            
            for system_name, system in systems_to_export:
                try:
                    if hasattr(system, 'export_emotion_analysis'):
                        export_path = await system.export_emotion_analysis()
                    elif hasattr(system, 'export_temporal_analysis'):
                        export_path = await system.export_temporal_analysis()
                    elif hasattr(system, 'export_quality_analysis'):
                        export_path = await system.export_quality_analysis()
                    elif hasattr(system, 'export_behavior_analysis'):
                        export_path = await system.export_behavior_analysis()
                    elif hasattr(system, 'export_performance_data'):
                        export_path = await system.export_performance_data()
                    elif hasattr(system, 'export_security_data'):
                        export_path = await system.export_security_data()
                    elif hasattr(system, 'export_optimization_data'):
                        export_path = await system.export_optimization_data()
                    else:
                        continue
                    
                    logger.info(f"   ‚Ä¢ {system_name}: {export_path}")
                except Exception as e:
                    logger.warning(f"   ‚Ä¢ {system_name}: Error en exportaci√≥n - {e}")
            
            logger.info("\nüéâ DEMOSTRACI√ìN COMPLETADA EXITOSAMENTE!")
            logger.info("El sistema avanzado de an√°lisis de historial de IA est√° funcionando correctamente.")
            
        except Exception as e:
            logger.error(f"‚ùå Error en resumen final: {e}")

async def main():
    """Funci√≥n principal"""
    try:
        demo = AdvancedSystemDemo()
        await demo.run_comprehensive_demo()
    except Exception as e:
        logger.error(f"‚ùå Error en la demostraci√≥n: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
























