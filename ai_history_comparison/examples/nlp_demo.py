"""
NLP System Demo for AI History Comparison
Demo del sistema NLP para an√°lisis de historial de IA
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def demo_nlp_system():
    """
    Demostraci√≥n completa del sistema NLP
    """
    print("üöÄ Demo del Sistema NLP Avanzado")
    print("=" * 60)
    
    # Textos de ejemplo
    sample_texts = [
        {
            "id": "doc_001",
            "content": """
            La inteligencia artificial est√° revolucionando la forma en que trabajamos y vivimos. 
            Los algoritmos de machine learning pueden procesar grandes cantidades de datos y 
            encontrar patrones que los humanos no podr√≠an detectar f√°cilmente. 
            
            Sin embargo, es importante considerar las implicaciones √©ticas de estas tecnolog√≠as. 
            Debemos asegurarnos de que la IA se use de manera responsable y justa.
            """,
            "query": "Escribe sobre inteligencia artificial y √©tica",
            "timestamp": datetime.now().isoformat()
        },
        {
            "id": "doc_002", 
            "content": """
            Artificial Intelligence is transforming industries across the globe. 
            From healthcare to finance, AI applications are becoming increasingly sophisticated.
            
            The key to successful AI implementation lies in understanding the data, 
            choosing the right algorithms, and ensuring proper validation of results.
            
            Companies that embrace AI early will have a significant competitive advantage.
            """,
            "query": "Write about AI transformation in industries",
            "timestamp": datetime.now().isoformat()
        },
        {
            "id": "doc_003",
            "content": """
            El machine learning es una rama de la inteligencia artificial que permite a las 
            computadoras aprender sin ser programadas expl√≠citamente. Los modelos pueden 
            mejorar su rendimiento a trav√©s de la experiencia.
            
            Existen diferentes tipos de aprendizaje: supervisado, no supervisado y por refuerzo. 
            Cada uno tiene sus propias aplicaciones y ventajas.
            """,
            "query": "Explica qu√© es machine learning",
            "timestamp": datetime.now().isoformat()
        },
        {
            "id": "doc_004",
            "content": """
            Data science combines statistics, programming, and domain expertise to extract 
            insights from data. It's a multidisciplinary field that requires both technical 
            and analytical skills.
            
            The data science process typically involves: data collection, cleaning, 
            exploration, modeling, and interpretation of results.
            """,
            "query": "Describe the data science process",
            "timestamp": datetime.now().isoformat()
        },
        {
            "id": "doc_005",
            "content": """
            La calidad de los datos es fundamental para el √©xito de cualquier proyecto de 
            an√°lisis. Datos de mala calidad pueden llevar a conclusiones incorrectas y 
            decisiones empresariales err√≥neas.
            
            Es crucial implementar procesos de validaci√≥n y limpieza de datos desde el 
            inicio del proyecto para garantizar la integridad de los resultados.
            """,
            "query": "Habla sobre la importancia de la calidad de datos",
            "timestamp": datetime.now().isoformat()
        }
    ]
    
    print(f"üìù Analizando {len(sample_texts)} documentos de ejemplo...")
    
    # ============================================================================
    # DEMO 1: An√°lisis NLP B√°sico
    # ============================================================================
    print(f"\nüîç Demo 1: An√°lisis NLP B√°sico")
    print("-" * 40)
    
    try:
        from nlp_engine import AdvancedNLPEngine, AnalysisType, LanguageType
        
        # Inicializar motor NLP
        nlp_engine = AdvancedNLPEngine(language=LanguageType.AUTO)
        
        # Analizar cada documento
        analyses = []
        for doc in sample_texts:
            print(f"  üìÑ Analizando documento: {doc['id']}")
            
            analysis = await nlp_engine.analyze_text(
                text=doc["content"],
                document_id=doc["id"],
                analysis_types=[
                    AnalysisType.TOKENIZATION,
                    AnalysisType.POS_TAGGING,
                    AnalysisType.SENTIMENT,
                    AnalysisType.KEYWORD_EXTRACTION
                ]
            )
            
            analyses.append(analysis)
            
            # Mostrar resultados b√°sicos
            print(f"    ‚Ä¢ Idioma detectado: {analysis.language}")
            print(f"    ‚Ä¢ Tokens: {len(analysis.tokens)}")
            print(f"    ‚Ä¢ Entidades: {len(analysis.entities)}")
            if analysis.sentiment:
                print(f"    ‚Ä¢ Sentimiento: {analysis.sentiment.sentiment_type.value} (confianza: {analysis.sentiment.confidence:.2f})")
            print(f"    ‚Ä¢ Palabras clave: {len(analysis.keywords)}")
            print(f"    ‚Ä¢ M√©tricas: {analysis.metrics.word_count} palabras, legibilidad: {analysis.metrics.readability_score:.2f}")
        
        print(f"\n‚úÖ An√°lisis NLP completado para {len(analyses)} documentos")
        
    except Exception as e:
        print(f"‚ùå Error en an√°lisis NLP: {e}")
    
    # ============================================================================
    # DEMO 2: Procesamiento en Tiempo Real
    # ============================================================================
    print(f"\n‚ö° Demo 2: Procesamiento en Tiempo Real")
    print("-" * 40)
    
    try:
        from text_processor import RealTimeTextProcessor, ProcessingPriority
        
        # Inicializar procesador
        processor = RealTimeTextProcessor(max_workers=2)
        await processor.start()
        
        print("  üöÄ Procesador iniciado")
        
        # Enviar tareas con diferentes prioridades
        task_ids = []
        for i, doc in enumerate(sample_texts):
            priority = ProcessingPriority.HIGH if i < 2 else ProcessingPriority.NORMAL
            
            task_id = await processor.submit_task(
                text=doc["content"],
                document_id=doc["id"],
                priority=priority
            )
            task_ids.append(task_id)
            print(f"  üì§ Tarea enviada: {task_id} (prioridad: {priority.name})")
        
        # Esperar completaci√≥n
        print("  ‚è≥ Esperando completaci√≥n...")
        results = await processor.wait_for_completion(task_ids, timeout=60)
        
        # Mostrar resultados
        for task_id, task in results.items():
            if task.status.value == "completed":
                print(f"  ‚úÖ Tarea completada: {task_id} en {task.completed_at - task.started_at}")
            else:
                print(f"  ‚ùå Tarea fallida: {task_id} - {task.error}")
        
        # Obtener estad√≠sticas
        stats = await processor.get_processing_statistics()
        print(f"  üìä Estad√≠sticas:")
        print(f"    ‚Ä¢ Total tareas: {stats['metrics']['total_tasks']}")
        print(f"    ‚Ä¢ Completadas: {stats['metrics']['completed_tasks']}")
        print(f"    ‚Ä¢ Fallidas: {stats['metrics']['failed_tasks']}")
        print(f"    ‚Ä¢ Tiempo promedio: {stats['metrics']['avg_processing_time']:.2f}s")
        
        await processor.stop()
        print("  üõë Procesador detenido")
        
    except Exception as e:
        print(f"‚ùå Error en procesamiento en tiempo real: {e}")
    
    # ============================================================================
    # DEMO 3: An√°lisis de Patrones
    # ============================================================================
    print(f"\nüîç Demo 3: An√°lisis de Patrones")
    print("-" * 40)
    
    try:
        from pattern_analyzer import TextPatternAnalyzer, PatternType
        
        # Inicializar analizador de patrones
        pattern_analyzer = TextPatternAnalyzer()
        
        # Analizar patrones
        pattern_results = await pattern_analyzer.analyze_documents(
            documents=sample_texts,
            pattern_types=[
                PatternType.LINGUISTIC,
                PatternType.STRUCTURAL,
                PatternType.QUALITY,
                PatternType.SEMANTIC
            ]
        )
        
        # Mostrar resultados por tipo
        for pattern_type, results in pattern_results.items():
            if isinstance(results, dict) and "patterns" in results:
                print(f"  üìã {pattern_type.title()} Patterns:")
                for pattern in results["patterns"][:3]:  # Mostrar solo los primeros 3
                    print(f"    ‚Ä¢ {pattern['name']}: {pattern['frequency']} ocurrencias")
                    print(f"      Ejemplo: {pattern['examples'][0] if pattern['examples'] else 'N/A'}")
        
        # Obtener resumen
        summary = await pattern_analyzer.get_pattern_summary()
        print(f"\n  üìä Resumen de Patrones:")
        print(f"    ‚Ä¢ Total patrones: {summary.get('total_patterns', 0)}")
        print(f"    ‚Ä¢ Distribuci√≥n por tipo: {summary.get('type_distribution', {})}")
        print(f"    ‚Ä¢ Distribuci√≥n por categor√≠a: {summary.get('category_distribution', {})}")
        
    except Exception as e:
        print(f"‚ùå Error en an√°lisis de patrones: {e}")
    
    # ============================================================================
    # DEMO 4: Comparaci√≥n de Textos
    # ============================================================================
    print(f"\nüîÑ Demo 4: Comparaci√≥n de Textos")
    print("-" * 40)
    
    try:
        from nlp_engine import AdvancedNLPEngine, LanguageType
        
        nlp_engine = AdvancedNLPEngine(language=LanguageType.AUTO)
        
        # Comparar textos similares
        text1 = sample_texts[0]["content"]
        text2 = sample_texts[2]["content"]  # Ambos en espa√±ol sobre IA
        
        print("  üîç Comparando documentos sobre IA en espa√±ol...")
        
        comparison = await nlp_engine.compare_texts(text1, text2)
        
        if "overall_similarity" in comparison:
            print(f"  üìä Similitud general: {comparison['overall_similarity']:.2f}")
            print(f"  üìà Desglose de similitud:")
            for sim_type, score in comparison.get("similarity_breakdown", {}).items():
                print(f"    ‚Ä¢ {sim_type}: {score:.2f}")
        
    except Exception as e:
        print(f"‚ùå Error en comparaci√≥n de textos: {e}")
    
    # ============================================================================
    # DEMO 5: An√°lisis de Sentimientos
    # ============================================================================
    print(f"\nüòä Demo 5: An√°lisis de Sentimientos")
    print("-" * 40)
    
    try:
        from nlp_engine import AdvancedNLPEngine, AnalysisType, LanguageType
        
        nlp_engine = AdvancedNLPEngine(language=LanguageType.AUTO)
        
        # Analizar sentimientos de todos los documentos
        sentiments = []
        for doc in sample_texts:
            analysis = await nlp_engine.analyze_text(
                text=doc["content"],
                document_id=f"sentiment_{doc['id']}",
                analysis_types=[AnalysisType.SENTIMENT]
            )
            
            if analysis.sentiment:
                sentiments.append({
                    "document_id": doc["id"],
                    "sentiment": analysis.sentiment.sentiment_type.value,
                    "polarity": analysis.sentiment.polarity,
                    "confidence": analysis.sentiment.confidence,
                    "emotional_tone": analysis.sentiment.emotional_tone
                })
        
        # Mostrar resultados
        print("  üìä An√°lisis de Sentimientos:")
        for sent in sentiments:
            print(f"    ‚Ä¢ {sent['document_id']}: {sent['sentiment']} "
                  f"(polaridad: {sent['polarity']:.2f}, confianza: {sent['confidence']:.2f})")
            print(f"      Tono emocional: {sent['emotional_tone']}")
        
        # Estad√≠sticas generales
        sentiment_counts = {}
        for sent in sentiments:
            sentiment_counts[sent['sentiment']] = sentiment_counts.get(sent['sentiment'], 0) + 1
        
        print(f"\n  üìà Distribuci√≥n de sentimientos: {sentiment_counts}")
        
    except Exception as e:
        print(f"‚ùå Error en an√°lisis de sentimientos: {e}")
    
    # ============================================================================
    # DEMO 6: Extracci√≥n de Palabras Clave
    # ============================================================================
    print(f"\nüîë Demo 6: Extracci√≥n de Palabras Clave")
    print("-" * 40)
    
    try:
        from nlp_engine import AdvancedNLPEngine, AnalysisType, LanguageType
        
        nlp_engine = AdvancedNLPEngine(language=LanguageType.AUTO)
        
        # Extraer palabras clave de cada documento
        all_keywords = []
        for doc in sample_texts:
            analysis = await nlp_engine.analyze_text(
                text=doc["content"],
                document_id=f"keywords_{doc['id']}",
                analysis_types=[AnalysisType.KEYWORD_EXTRACTION]
            )
            
            print(f"  üìÑ {doc['id']} - Top 5 palabras clave:")
            for i, kw in enumerate(analysis.keywords[:5]):
                print(f"    {i+1}. {kw.text} (score: {kw.score:.2f}, frecuencia: {kw.frequency})")
                all_keywords.append(kw.text)
        
        # Palabras clave m√°s comunes
        keyword_counts = {}
        for kw in all_keywords:
            keyword_counts[kw] = keyword_counts.get(kw, 0) + 1
        
        top_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        print(f"\n  üèÜ Top 10 palabras clave m√°s comunes:")
        for i, (kw, count) in enumerate(top_keywords):
            print(f"    {i+1}. {kw}: {count} documentos")
        
    except Exception as e:
        print(f"‚ùå Error en extracci√≥n de palabras clave: {e}")
    
    # ============================================================================
    # DEMO 7: Exportaci√≥n de Resultados
    # ============================================================================
    print(f"\nüíæ Demo 7: Exportaci√≥n de Resultados")
    print("-" * 40)
    
    try:
        from pattern_analyzer import TextPatternAnalyzer
        
        # Exportar patrones
        pattern_analyzer = TextPatternAnalyzer()
        pattern_file = await pattern_analyzer.export_patterns()
        print(f"  üìÅ Patrones exportados a: {pattern_file}")
        
        # Exportar an√°lisis NLP
        from nlp_engine import AdvancedNLPEngine
        
        nlp_engine = AdvancedNLPEngine()
        for doc in sample_texts[:2]:  # Exportar solo los primeros 2
            analysis_file = await nlp_engine.save_analysis(doc["id"])
            print(f"  üìÅ An√°lisis de {doc['id']} exportado a: {analysis_file}")
        
    except Exception as e:
        print(f"‚ùå Error en exportaci√≥n: {e}")
    
    # ============================================================================
    # RESUMEN FINAL
    # ============================================================================
    print(f"\nüéâ Demo Completado Exitosamente!")
    print("=" * 60)
    
    print(f"üìä Resumen del Demo:")
    print(f"  ‚Ä¢ Documentos analizados: {len(sample_texts)}")
    print(f"  ‚Ä¢ An√°lisis NLP: ‚úÖ Completado")
    print(f"  ‚Ä¢ Procesamiento en tiempo real: ‚úÖ Completado")
    print(f"  ‚Ä¢ An√°lisis de patrones: ‚úÖ Completado")
    print(f"  ‚Ä¢ Comparaci√≥n de textos: ‚úÖ Completado")
    print(f"  ‚Ä¢ An√°lisis de sentimientos: ‚úÖ Completado")
    print(f"  ‚Ä¢ Extracci√≥n de palabras clave: ‚úÖ Completado")
    print(f"  ‚Ä¢ Exportaci√≥n de resultados: ‚úÖ Completado")
    
    print(f"\nüöÄ El sistema NLP est√° listo para uso en producci√≥n!")
    print(f"   - Motor NLP avanzado con m√∫ltiples an√°lisis")
    print(f"   - Procesamiento en tiempo real con colas de prioridad")
    print(f"   - An√°lisis de patrones con clustering y evoluci√≥n")
    print(f"   - API completa con endpoints REST")
    print(f"   - Soporte para m√∫ltiples idiomas")
    print(f"   - Exportaci√≥n de resultados en m√∫ltiples formatos")

async def demo_api_usage():
    """
    Demo de uso de la API NLP
    """
    print("\nüåê Demo de Uso de API NLP")
    print("=" * 40)
    
    import httpx
    
    base_url = "http://localhost:8000/nlp"
    
    # Ejemplo de uso de la API
    async with httpx.AsyncClient() as client:
        try:
            # Health check
            response = await client.get(f"{base_url}/health")
            print(f"‚úÖ Health check: {response.status_code}")
            
            # Detectar idioma
            response = await client.post(
                f"{base_url}/language/detect",
                json={"text": "La inteligencia artificial es fascinante"}
            )
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ Idioma detectado: {result['language']}")
            
            # Analizar sentimiento
            response = await client.post(
                f"{base_url}/sentiment/analyze",
                json={"text": "Este es un texto excelente y muy bien escrito"}
            )
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ Sentimiento: {result['sentiment']['sentiment_type']}")
            
            # Extraer palabras clave
            response = await client.post(
                f"{base_url}/keywords/extract",
                json={"text": "Machine learning y deep learning son tecnolog√≠as avanzadas de inteligencia artificial"}
            )
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ Palabras clave extra√≠das: {len(result['keywords'])}")
            
        except Exception as e:
            print(f"‚ùå Error en demo de API: {e}")
            print("   Aseg√∫rate de que el servidor est√© ejecut√°ndose en localhost:8000")

if __name__ == "__main__":
    # Ejecutar demo principal
    asyncio.run(demo_nlp_system())
    
    # Ejecutar demo de API (opcional)
    # asyncio.run(demo_api_usage())



























